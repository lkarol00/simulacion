{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import ShuffleSplit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Número de muestras:  12330\n",
      "Número de características:  18\n"
     ]
    }
   ],
   "source": [
    "import pandas\n",
    "filename = 'online_shoppers_intention.csv'\n",
    "data = pandas.read_csv(filename, header=0)\n",
    "\n",
    "print(\"Número de muestras: \", data.shape[0])\n",
    "print(\"Número de características: \", data.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Administrative</th>\n",
       "      <th>Administrative_Duration</th>\n",
       "      <th>Informational</th>\n",
       "      <th>Informational_Duration</th>\n",
       "      <th>ProductRelated</th>\n",
       "      <th>ProductRelated_Duration</th>\n",
       "      <th>BounceRates</th>\n",
       "      <th>ExitRates</th>\n",
       "      <th>PageValues</th>\n",
       "      <th>SpecialDay</th>\n",
       "      <th>Month</th>\n",
       "      <th>OperatingSystems</th>\n",
       "      <th>Browser</th>\n",
       "      <th>Region</th>\n",
       "      <th>TrafficType</th>\n",
       "      <th>VisitorType</th>\n",
       "      <th>Weekend</th>\n",
       "      <th>Revenue</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Feb</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Returning_Visitor</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>64.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Feb</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>Returning_Visitor</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Feb</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>3</td>\n",
       "      <td>Returning_Visitor</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2.666667</td>\n",
       "      <td>0.050000</td>\n",
       "      <td>0.140000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Feb</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>Returning_Visitor</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10</td>\n",
       "      <td>627.500000</td>\n",
       "      <td>0.020000</td>\n",
       "      <td>0.050000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Feb</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>Returning_Visitor</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>19</td>\n",
       "      <td>154.216667</td>\n",
       "      <td>0.015789</td>\n",
       "      <td>0.024561</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Feb</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Returning_Visitor</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.4</td>\n",
       "      <td>Feb</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>Returning_Visitor</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Feb</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>Returning_Visitor</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>37.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>Feb</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>Returning_Visitor</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "      <td>738.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.022222</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.4</td>\n",
       "      <td>Feb</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>Returning_Visitor</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Administrative  Administrative_Duration  Informational  \\\n",
       "0               0                      0.0              0   \n",
       "1               0                      0.0              0   \n",
       "2               0                      0.0              0   \n",
       "3               0                      0.0              0   \n",
       "4               0                      0.0              0   \n",
       "5               0                      0.0              0   \n",
       "6               0                      0.0              0   \n",
       "7               1                      0.0              0   \n",
       "8               0                      0.0              0   \n",
       "9               0                      0.0              0   \n",
       "\n",
       "   Informational_Duration  ProductRelated  ProductRelated_Duration  \\\n",
       "0                     0.0               1                 0.000000   \n",
       "1                     0.0               2                64.000000   \n",
       "2                     0.0               1                 0.000000   \n",
       "3                     0.0               2                 2.666667   \n",
       "4                     0.0              10               627.500000   \n",
       "5                     0.0              19               154.216667   \n",
       "6                     0.0               1                 0.000000   \n",
       "7                     0.0               0                 0.000000   \n",
       "8                     0.0               2                37.000000   \n",
       "9                     0.0               3               738.000000   \n",
       "\n",
       "   BounceRates  ExitRates  PageValues  SpecialDay Month  OperatingSystems  \\\n",
       "0     0.200000   0.200000         0.0         0.0   Feb                 1   \n",
       "1     0.000000   0.100000         0.0         0.0   Feb                 2   \n",
       "2     0.200000   0.200000         0.0         0.0   Feb                 4   \n",
       "3     0.050000   0.140000         0.0         0.0   Feb                 3   \n",
       "4     0.020000   0.050000         0.0         0.0   Feb                 3   \n",
       "5     0.015789   0.024561         0.0         0.0   Feb                 2   \n",
       "6     0.200000   0.200000         0.0         0.4   Feb                 2   \n",
       "7     0.200000   0.200000         0.0         0.0   Feb                 1   \n",
       "8     0.000000   0.100000         0.0         0.8   Feb                 2   \n",
       "9     0.000000   0.022222         0.0         0.4   Feb                 2   \n",
       "\n",
       "   Browser  Region  TrafficType        VisitorType  Weekend  Revenue  \n",
       "0        1       1            1  Returning_Visitor    False    False  \n",
       "1        2       1            2  Returning_Visitor    False    False  \n",
       "2        1       9            3  Returning_Visitor    False    False  \n",
       "3        2       2            4  Returning_Visitor    False    False  \n",
       "4        3       1            4  Returning_Visitor     True    False  \n",
       "5        2       1            3  Returning_Visitor    False    False  \n",
       "6        4       3            3  Returning_Visitor    False    False  \n",
       "7        2       1            5  Returning_Visitor     True    False  \n",
       "8        2       2            3  Returning_Visitor    False    False  \n",
       "9        4       1            2  Returning_Visitor    False    False  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Administrative               int64\n",
       "Administrative_Duration    float64\n",
       "Informational                int64\n",
       "Informational_Duration     float64\n",
       "ProductRelated               int64\n",
       "ProductRelated_Duration    float64\n",
       "BounceRates                float64\n",
       "ExitRates                  float64\n",
       "PageValues                 float64\n",
       "SpecialDay                 float64\n",
       "Month                       object\n",
       "OperatingSystems             int64\n",
       "Browser                      int64\n",
       "Region                       int64\n",
       "TrafficType                  int64\n",
       "VisitorType                 object\n",
       "Weekend                       bool\n",
       "Revenue                       bool\n",
       "dtype: object"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False    9462\n",
       "True     2868\n",
       "Name: Weekend, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['Weekend'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False    10422\n",
       "True      1908\n",
       "Name: Revenue, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['Revenue'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "May     3364\n",
       "Nov     2998\n",
       "Mar     1907\n",
       "Dec     1727\n",
       "Oct      549\n",
       "Sep      448\n",
       "Aug      433\n",
       "Jul      432\n",
       "June     288\n",
       "Feb      184\n",
       "Name: Month, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['Month'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Returning_Visitor    10551\n",
       "New_Visitor           1694\n",
       "Other                   85\n",
       "Name: VisitorType, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['VisitorType'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Administrative             0\n",
       "Administrative_Duration    0\n",
       "Informational              0\n",
       "Informational_Duration     0\n",
       "ProductRelated             0\n",
       "ProductRelated_Duration    0\n",
       "BounceRates                0\n",
       "ExitRates                  0\n",
       "PageValues                 0\n",
       "SpecialDay                 0\n",
       "Month                      0\n",
       "OperatingSystems           0\n",
       "Browser                    0\n",
       "Region                     0\n",
       "TrafficType                0\n",
       "VisitorType                0\n",
       "Weekend                    0\n",
       "Revenue                    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"Weekend\"] = data[\"Weekend\"].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    9462\n",
       "1    2868\n",
       "Name: Weekend, dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['Weekend'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['Revenue'] = data[\"Revenue\"].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    10422\n",
       "1     1908\n",
       "Name: Revenue, dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['Revenue'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['Month'] = data['Month'].astype('str')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['Month'] = np.where(data['Month']==\"Feb\", 0, data['Month'])\n",
    "data['Month'] = np.where(data['Month']==\"Mar\", 1, data['Month'])\n",
    "data['Month'] = np.where(data['Month']==\"May\", 2, data['Month'])\n",
    "data['Month'] = np.where(data['Month']==\"June\", 3, data['Month'])\n",
    "data['Month'] = np.where(data['Month']==\"Jul\", 4, data['Month'])\n",
    "data['Month'] = np.where(data['Month']==\"Aug\", 5, data['Month'])\n",
    "data['Month'] = np.where(data['Month']==\"Sep\", 6, data['Month'])\n",
    "data['Month'] = np.where(data['Month']==\"Oct\", 7, data['Month'])\n",
    "data['Month'] = np.where(data['Month']==\"Nov\", 8, data['Month'])\n",
    "data['Month'] = np.where(data['Month']==\"Dec\", 9, data['Month'])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2    3364\n",
       "8    2998\n",
       "1    1907\n",
       "9    1727\n",
       "7     549\n",
       "6     448\n",
       "5     433\n",
       "4     432\n",
       "3     288\n",
       "0     184\n",
       "Name: Month, dtype: int64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['Month'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['VisitorType'] = np.where(data['VisitorType']==\"Returning_Visitor\", 0, data['VisitorType'])\n",
    "data['VisitorType'] = np.where(data['VisitorType']==\"New_Visitor\", 1, data['VisitorType'])\n",
    "data['VisitorType'] = np.where(data['VisitorType']==\"Other\", 2, data['VisitorType'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    10551\n",
       "1     1694\n",
       "2       85\n",
       "Name: VisitorType, dtype: int64"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['VisitorType'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Administrative</th>\n",
       "      <th>Administrative_Duration</th>\n",
       "      <th>Informational</th>\n",
       "      <th>Informational_Duration</th>\n",
       "      <th>ProductRelated</th>\n",
       "      <th>ProductRelated_Duration</th>\n",
       "      <th>BounceRates</th>\n",
       "      <th>ExitRates</th>\n",
       "      <th>PageValues</th>\n",
       "      <th>SpecialDay</th>\n",
       "      <th>Month</th>\n",
       "      <th>OperatingSystems</th>\n",
       "      <th>Browser</th>\n",
       "      <th>Region</th>\n",
       "      <th>TrafficType</th>\n",
       "      <th>VisitorType</th>\n",
       "      <th>Weekend</th>\n",
       "      <th>Revenue</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>64.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2.666667</td>\n",
       "      <td>0.050000</td>\n",
       "      <td>0.140000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10</td>\n",
       "      <td>627.500000</td>\n",
       "      <td>0.020000</td>\n",
       "      <td>0.050000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>19</td>\n",
       "      <td>154.216667</td>\n",
       "      <td>0.015789</td>\n",
       "      <td>0.024561</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>37.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "      <td>738.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.022222</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Administrative  Administrative_Duration  Informational  \\\n",
       "0               0                      0.0              0   \n",
       "1               0                      0.0              0   \n",
       "2               0                      0.0              0   \n",
       "3               0                      0.0              0   \n",
       "4               0                      0.0              0   \n",
       "5               0                      0.0              0   \n",
       "6               0                      0.0              0   \n",
       "7               1                      0.0              0   \n",
       "8               0                      0.0              0   \n",
       "9               0                      0.0              0   \n",
       "\n",
       "   Informational_Duration  ProductRelated  ProductRelated_Duration  \\\n",
       "0                     0.0               1                 0.000000   \n",
       "1                     0.0               2                64.000000   \n",
       "2                     0.0               1                 0.000000   \n",
       "3                     0.0               2                 2.666667   \n",
       "4                     0.0              10               627.500000   \n",
       "5                     0.0              19               154.216667   \n",
       "6                     0.0               1                 0.000000   \n",
       "7                     0.0               0                 0.000000   \n",
       "8                     0.0               2                37.000000   \n",
       "9                     0.0               3               738.000000   \n",
       "\n",
       "   BounceRates  ExitRates  PageValues  SpecialDay Month  OperatingSystems  \\\n",
       "0     0.200000   0.200000         0.0         0.0     0                 1   \n",
       "1     0.000000   0.100000         0.0         0.0     0                 2   \n",
       "2     0.200000   0.200000         0.0         0.0     0                 4   \n",
       "3     0.050000   0.140000         0.0         0.0     0                 3   \n",
       "4     0.020000   0.050000         0.0         0.0     0                 3   \n",
       "5     0.015789   0.024561         0.0         0.0     0                 2   \n",
       "6     0.200000   0.200000         0.0         0.4     0                 2   \n",
       "7     0.200000   0.200000         0.0         0.0     0                 1   \n",
       "8     0.000000   0.100000         0.0         0.8     0                 2   \n",
       "9     0.000000   0.022222         0.0         0.4     0                 2   \n",
       "\n",
       "   Browser  Region  TrafficType VisitorType  Weekend  Revenue  \n",
       "0        1       1            1           0        0        0  \n",
       "1        2       1            2           0        0        0  \n",
       "2        1       9            3           0        0        0  \n",
       "3        2       2            4           0        0        0  \n",
       "4        3       1            4           0        1        0  \n",
       "5        2       1            3           0        0        0  \n",
       "6        4       3            3           0        0        0  \n",
       "7        2       1            5           0        1        0  \n",
       "8        2       2            3           0        0        0  \n",
       "9        4       1            2           0        0        0  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['Month'] = data['Month'].astype('int')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['VisitorType'] = data['VisitorType'].astype('str').astype('int')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Administrative               int64\n",
       "Administrative_Duration    float64\n",
       "Informational                int64\n",
       "Informational_Duration     float64\n",
       "ProductRelated               int64\n",
       "ProductRelated_Duration    float64\n",
       "BounceRates                float64\n",
       "ExitRates                  float64\n",
       "PageValues                 float64\n",
       "SpecialDay                 float64\n",
       "Month                        int32\n",
       "OperatingSystems             int64\n",
       "Browser                      int64\n",
       "Region                       int64\n",
       "TrafficType                  int64\n",
       "VisitorType                  int32\n",
       "Weekend                      int32\n",
       "Revenue                      int32\n",
       "dtype: object"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(12330, 17) (12330,)\n"
     ]
    }
   ],
   "source": [
    "X = data.drop('Revenue', axis=1)\n",
    "Y = data[\"Revenue\"]\n",
    "print(X.shape, Y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Validación"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "scaler = StandardScaler()\n",
    "Xtrain = scaler.fit_transform(X)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(10,5))\n",
    "plt.subplot(1,2,1)\n",
    "plt.bar(0,np.sum(Y==0)/Y.shape[0])\n",
    "plt.bar(1,np.sum(Y==1)/Y.shape[0])\n",
    "plt.title('Distribución de clases original')\n",
    "for i in range(2):\n",
    "    plt.text(i, np.sum(Y==i)/Y.shape[0], str(round(np.sum(Y==i)/Y.shape[0],3)), color='black', fontweight='bold')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "def calculateAUC(clf):\n",
    "    prob_y_0 = clf.predict_proba(X_test)\n",
    "    \n",
    "    prob_y_0 = [p[1] for p in prob_y_0]\n",
    "\n",
    "    print( roc_auc_score(y_test, prob_y_0) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.neighbors import KernelDensity\n",
    "from sklearn.metrics import make_scorer\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.model_selection import StratifiedKFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8798976997517861\n"
     ]
    }
   ],
   "source": [
    "#calculateAUC(clf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modelos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "skf = StratifiedKFold(n_splits=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_table(data):\n",
    "    df = pandas.DataFrame()\n",
    "    df = df.assign(mean_fit_time = data[\"mean_fit_time\"])\n",
    "\n",
    "    df = df.assign(params = data[\"params\"])\n",
    "\n",
    "    df = df.assign(mean_test_AUC = data[\"mean_test_AUC\"])\n",
    "    df = df.assign(mean_test_F_score = data[\"mean_test_F-score\"])\n",
    "    df = df.assign(mean_test_Sensitivity = data[\"mean_test_Sensitivity\"])\n",
    "    df = df.assign(rank_test_AUC = data[\"rank_test_AUC\"])\n",
    "    df = df.assign(rank_test_F_score = data[\"rank_test_F-score\"])\n",
    "    df = df.assign(rank_test_Sensitivity = data[\"rank_test_Sensitivity\"])\n",
    "\n",
    "    df = df.assign(mean_train_AUC = data[\"mean_train_AUC\"])\n",
    "    df = df.assign(mean_train_F_score = data[\"mean_train_F-score\"])\n",
    "    df = df.assign(mean_train_Sensitivity = data[\"mean_train_Sensitivity\"])\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Este tiene como medida de desempeño AUC y el accuracy, sólo puse el accuracy como para ver algo, pero en sí se usa sin el accuracy, sólo con el AUC, esa es la prueba que está después de esta."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 4 folds for each of 12 candidates, totalling 48 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   5 tasks      | elapsed:  1.7min\n",
      "[Parallel(n_jobs=-1)]: Done  10 tasks      | elapsed:  2.7min\n",
      "[Parallel(n_jobs=-1)]: Done  17 tasks      | elapsed:  4.3min\n",
      "[Parallel(n_jobs=-1)]: Done  24 tasks      | elapsed:  5.4min\n",
      "[Parallel(n_jobs=-1)]: Done  33 tasks      | elapsed:  8.3min\n",
      "[Parallel(n_jobs=-1)]: Done  46 out of  48 | elapsed: 16.9min remaining:   43.9s\n",
      "[Parallel(n_jobs=-1)]: Done  48 out of  48 | elapsed: 17.1min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=StratifiedKFold(n_splits=4, random_state=None, shuffle=False),\n",
       "             error_score='raise-deprecating',\n",
       "             estimator=Pipeline(memory=None,\n",
       "                                steps=[('standardscaler',\n",
       "                                        StandardScaler(copy=True,\n",
       "                                                       with_mean=True,\n",
       "                                                       with_std=True)),\n",
       "                                       ('svc',\n",
       "                                        SVC(C=1.0, cache_size=200,\n",
       "                                            class_weight=None, coef0=0.0,\n",
       "                                            decision_function_shape='ovr',\n",
       "                                            degree=3, gamma='auto_deprecated',\n",
       "                                            kernel=...\n",
       "                                            probability=True, random_state=None,\n",
       "                                            shrinking=True, tol=0.001,\n",
       "                                            verbose=False))],\n",
       "                                verbose=False),\n",
       "             iid='warn', n_jobs=-1,\n",
       "             param_grid={'svc__C': (0.001, 0.01, 1, 10),\n",
       "                         'svc__gamma': ['scale'],\n",
       "                         'svc__kernel': ('linear', 'poly', 'sigmoid')},\n",
       "             pre_dispatch='2*n_jobs', refit='F-score', return_train_score=True,\n",
       "             scoring={'AUC': 'roc_auc', 'F-score': 'f1',\n",
       "                      'Sensitivity': make_scorer(recall_score)},\n",
       "             verbose=10)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scoring = {'AUC': 'roc_auc', 'F-score': 'f1', 'Sensitivity': make_scorer(recall_score)} \n",
    "parameters = {'svc__kernel':('linear', 'poly', 'sigmoid'),\n",
    "              'svc__gamma':['scale'],\n",
    "              'svc__C':(0.001, 0.01, 1, 10)}\n",
    "\n",
    "pp = make_pipeline(StandardScaler(), SVC(probability = True))\n",
    "\n",
    "gs = GridSearchCV(pp, parameters, cv=skf, scoring=scoring, refit='F-score', return_train_score=True, n_jobs=-1, verbose=10)\n",
    "\n",
    "gs.fit(X, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_svc__C</th>\n",
       "      <th>param_svc__gamma</th>\n",
       "      <th>param_svc__kernel</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_AUC</th>\n",
       "      <th>split1_test_AUC</th>\n",
       "      <th>...</th>\n",
       "      <th>split3_test_Sensitivity</th>\n",
       "      <th>mean_test_Sensitivity</th>\n",
       "      <th>std_test_Sensitivity</th>\n",
       "      <th>rank_test_Sensitivity</th>\n",
       "      <th>split0_train_Sensitivity</th>\n",
       "      <th>split1_train_Sensitivity</th>\n",
       "      <th>split2_train_Sensitivity</th>\n",
       "      <th>split3_train_Sensitivity</th>\n",
       "      <th>mean_train_Sensitivity</th>\n",
       "      <th>std_train_Sensitivity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>40.011196</td>\n",
       "      <td>1.434184</td>\n",
       "      <td>1.213589</td>\n",
       "      <td>0.198066</td>\n",
       "      <td>0.001</td>\n",
       "      <td>scale</td>\n",
       "      <td>linear</td>\n",
       "      <td>{'svc__C': 0.001, 'svc__gamma': 'scale', 'svc_...</td>\n",
       "      <td>0.970697</td>\n",
       "      <td>0.839589</td>\n",
       "      <td>...</td>\n",
       "      <td>0.253669</td>\n",
       "      <td>0.268344</td>\n",
       "      <td>0.009720</td>\n",
       "      <td>8</td>\n",
       "      <td>0.208945</td>\n",
       "      <td>0.274633</td>\n",
       "      <td>0.334032</td>\n",
       "      <td>0.315164</td>\n",
       "      <td>0.283194</td>\n",
       "      <td>0.047940</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>46.010588</td>\n",
       "      <td>0.406227</td>\n",
       "      <td>1.262536</td>\n",
       "      <td>0.079116</td>\n",
       "      <td>0.001</td>\n",
       "      <td>scale</td>\n",
       "      <td>poly</td>\n",
       "      <td>{'svc__C': 0.001, 'svc__gamma': 'scale', 'svc_...</td>\n",
       "      <td>0.903156</td>\n",
       "      <td>0.851529</td>\n",
       "      <td>...</td>\n",
       "      <td>0.029350</td>\n",
       "      <td>0.022011</td>\n",
       "      <td>0.007338</td>\n",
       "      <td>11</td>\n",
       "      <td>0.017470</td>\n",
       "      <td>0.020266</td>\n",
       "      <td>0.024458</td>\n",
       "      <td>0.020266</td>\n",
       "      <td>0.020615</td>\n",
       "      <td>0.002495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>48.948824</td>\n",
       "      <td>1.096042</td>\n",
       "      <td>2.343567</td>\n",
       "      <td>0.225114</td>\n",
       "      <td>0.001</td>\n",
       "      <td>scale</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>{'svc__C': 0.001, 'svc__gamma': 'scale', 'svc_...</td>\n",
       "      <td>0.952383</td>\n",
       "      <td>0.853107</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>12</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>39.745382</td>\n",
       "      <td>2.080913</td>\n",
       "      <td>1.057702</td>\n",
       "      <td>0.241812</td>\n",
       "      <td>0.01</td>\n",
       "      <td>scale</td>\n",
       "      <td>linear</td>\n",
       "      <td>{'svc__C': 0.01, 'svc__gamma': 'scale', 'svc__...</td>\n",
       "      <td>0.966250</td>\n",
       "      <td>0.835507</td>\n",
       "      <td>...</td>\n",
       "      <td>0.327044</td>\n",
       "      <td>0.364260</td>\n",
       "      <td>0.027589</td>\n",
       "      <td>6</td>\n",
       "      <td>0.308176</td>\n",
       "      <td>0.375961</td>\n",
       "      <td>0.433263</td>\n",
       "      <td>0.433962</td>\n",
       "      <td>0.387841</td>\n",
       "      <td>0.051667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>50.130707</td>\n",
       "      <td>1.595418</td>\n",
       "      <td>1.520653</td>\n",
       "      <td>0.163336</td>\n",
       "      <td>0.01</td>\n",
       "      <td>scale</td>\n",
       "      <td>poly</td>\n",
       "      <td>{'svc__C': 0.01, 'svc__gamma': 'scale', 'svc__...</td>\n",
       "      <td>0.885291</td>\n",
       "      <td>0.848628</td>\n",
       "      <td>...</td>\n",
       "      <td>0.115304</td>\n",
       "      <td>0.074420</td>\n",
       "      <td>0.025525</td>\n",
       "      <td>10</td>\n",
       "      <td>0.061495</td>\n",
       "      <td>0.077568</td>\n",
       "      <td>0.097834</td>\n",
       "      <td>0.088749</td>\n",
       "      <td>0.081412</td>\n",
       "      <td>0.013555</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>51.219475</td>\n",
       "      <td>0.815531</td>\n",
       "      <td>2.683069</td>\n",
       "      <td>0.207297</td>\n",
       "      <td>0.01</td>\n",
       "      <td>scale</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>{'svc__C': 0.01, 'svc__gamma': 'scale', 'svc__...</td>\n",
       "      <td>0.931649</td>\n",
       "      <td>0.847148</td>\n",
       "      <td>...</td>\n",
       "      <td>0.218029</td>\n",
       "      <td>0.219601</td>\n",
       "      <td>0.007756</td>\n",
       "      <td>9</td>\n",
       "      <td>0.160028</td>\n",
       "      <td>0.214535</td>\n",
       "      <td>0.255066</td>\n",
       "      <td>0.244584</td>\n",
       "      <td>0.218553</td>\n",
       "      <td>0.036919</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>96.269707</td>\n",
       "      <td>22.889794</td>\n",
       "      <td>1.068824</td>\n",
       "      <td>0.191393</td>\n",
       "      <td>1</td>\n",
       "      <td>scale</td>\n",
       "      <td>linear</td>\n",
       "      <td>{'svc__C': 1, 'svc__gamma': 'scale', 'svc__ker...</td>\n",
       "      <td>0.965817</td>\n",
       "      <td>0.835809</td>\n",
       "      <td>...</td>\n",
       "      <td>0.339623</td>\n",
       "      <td>0.391514</td>\n",
       "      <td>0.033126</td>\n",
       "      <td>4</td>\n",
       "      <td>0.322851</td>\n",
       "      <td>0.394829</td>\n",
       "      <td>0.464710</td>\n",
       "      <td>0.452131</td>\n",
       "      <td>0.408630</td>\n",
       "      <td>0.056093</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>51.326718</td>\n",
       "      <td>2.224108</td>\n",
       "      <td>1.194457</td>\n",
       "      <td>0.209341</td>\n",
       "      <td>1</td>\n",
       "      <td>scale</td>\n",
       "      <td>poly</td>\n",
       "      <td>{'svc__C': 1, 'svc__gamma': 'scale', 'svc__ker...</td>\n",
       "      <td>0.852108</td>\n",
       "      <td>0.843723</td>\n",
       "      <td>...</td>\n",
       "      <td>0.425577</td>\n",
       "      <td>0.346431</td>\n",
       "      <td>0.047721</td>\n",
       "      <td>7</td>\n",
       "      <td>0.330538</td>\n",
       "      <td>0.410203</td>\n",
       "      <td>0.438155</td>\n",
       "      <td>0.484277</td>\n",
       "      <td>0.415793</td>\n",
       "      <td>0.055879</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>24.178688</td>\n",
       "      <td>2.981318</td>\n",
       "      <td>1.260144</td>\n",
       "      <td>0.039451</td>\n",
       "      <td>1</td>\n",
       "      <td>scale</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>{'svc__C': 1, 'svc__gamma': 'scale', 'svc__ker...</td>\n",
       "      <td>0.625320</td>\n",
       "      <td>0.683358</td>\n",
       "      <td>...</td>\n",
       "      <td>0.448637</td>\n",
       "      <td>0.434485</td>\n",
       "      <td>0.021038</td>\n",
       "      <td>1</td>\n",
       "      <td>0.390636</td>\n",
       "      <td>0.418588</td>\n",
       "      <td>0.447939</td>\n",
       "      <td>0.450734</td>\n",
       "      <td>0.426974</td>\n",
       "      <td>0.024468</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>389.273173</td>\n",
       "      <td>124.027194</td>\n",
       "      <td>1.003884</td>\n",
       "      <td>0.213332</td>\n",
       "      <td>10</td>\n",
       "      <td>scale</td>\n",
       "      <td>linear</td>\n",
       "      <td>{'svc__C': 10, 'svc__gamma': 'scale', 'svc__ke...</td>\n",
       "      <td>0.965871</td>\n",
       "      <td>0.836233</td>\n",
       "      <td>...</td>\n",
       "      <td>0.339623</td>\n",
       "      <td>0.391514</td>\n",
       "      <td>0.033126</td>\n",
       "      <td>4</td>\n",
       "      <td>0.322851</td>\n",
       "      <td>0.394829</td>\n",
       "      <td>0.465409</td>\n",
       "      <td>0.452830</td>\n",
       "      <td>0.408980</td>\n",
       "      <td>0.056404</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>86.258530</td>\n",
       "      <td>11.832461</td>\n",
       "      <td>1.031252</td>\n",
       "      <td>0.064425</td>\n",
       "      <td>10</td>\n",
       "      <td>scale</td>\n",
       "      <td>poly</td>\n",
       "      <td>{'svc__C': 10, 'svc__gamma': 'scale', 'svc__ke...</td>\n",
       "      <td>0.796524</td>\n",
       "      <td>0.818780</td>\n",
       "      <td>...</td>\n",
       "      <td>0.486373</td>\n",
       "      <td>0.410371</td>\n",
       "      <td>0.048453</td>\n",
       "      <td>3</td>\n",
       "      <td>0.445143</td>\n",
       "      <td>0.535290</td>\n",
       "      <td>0.563242</td>\n",
       "      <td>0.586303</td>\n",
       "      <td>0.532495</td>\n",
       "      <td>0.053570</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>16.129594</td>\n",
       "      <td>2.312611</td>\n",
       "      <td>1.246092</td>\n",
       "      <td>0.111782</td>\n",
       "      <td>10</td>\n",
       "      <td>scale</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>{'svc__C': 10, 'svc__gamma': 'scale', 'svc__ke...</td>\n",
       "      <td>0.825978</td>\n",
       "      <td>0.679914</td>\n",
       "      <td>...</td>\n",
       "      <td>0.452830</td>\n",
       "      <td>0.431863</td>\n",
       "      <td>0.032917</td>\n",
       "      <td>2</td>\n",
       "      <td>0.376660</td>\n",
       "      <td>0.423480</td>\n",
       "      <td>0.459818</td>\n",
       "      <td>0.452131</td>\n",
       "      <td>0.428022</td>\n",
       "      <td>0.032600</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>12 rows × 47 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    mean_fit_time  std_fit_time  mean_score_time  std_score_time param_svc__C  \\\n",
       "0       40.011196      1.434184         1.213589        0.198066        0.001   \n",
       "1       46.010588      0.406227         1.262536        0.079116        0.001   \n",
       "2       48.948824      1.096042         2.343567        0.225114        0.001   \n",
       "3       39.745382      2.080913         1.057702        0.241812         0.01   \n",
       "4       50.130707      1.595418         1.520653        0.163336         0.01   \n",
       "5       51.219475      0.815531         2.683069        0.207297         0.01   \n",
       "6       96.269707     22.889794         1.068824        0.191393            1   \n",
       "7       51.326718      2.224108         1.194457        0.209341            1   \n",
       "8       24.178688      2.981318         1.260144        0.039451            1   \n",
       "9      389.273173    124.027194         1.003884        0.213332           10   \n",
       "10      86.258530     11.832461         1.031252        0.064425           10   \n",
       "11      16.129594      2.312611         1.246092        0.111782           10   \n",
       "\n",
       "   param_svc__gamma param_svc__kernel  \\\n",
       "0             scale            linear   \n",
       "1             scale              poly   \n",
       "2             scale           sigmoid   \n",
       "3             scale            linear   \n",
       "4             scale              poly   \n",
       "5             scale           sigmoid   \n",
       "6             scale            linear   \n",
       "7             scale              poly   \n",
       "8             scale           sigmoid   \n",
       "9             scale            linear   \n",
       "10            scale              poly   \n",
       "11            scale           sigmoid   \n",
       "\n",
       "                                               params  split0_test_AUC  \\\n",
       "0   {'svc__C': 0.001, 'svc__gamma': 'scale', 'svc_...         0.970697   \n",
       "1   {'svc__C': 0.001, 'svc__gamma': 'scale', 'svc_...         0.903156   \n",
       "2   {'svc__C': 0.001, 'svc__gamma': 'scale', 'svc_...         0.952383   \n",
       "3   {'svc__C': 0.01, 'svc__gamma': 'scale', 'svc__...         0.966250   \n",
       "4   {'svc__C': 0.01, 'svc__gamma': 'scale', 'svc__...         0.885291   \n",
       "5   {'svc__C': 0.01, 'svc__gamma': 'scale', 'svc__...         0.931649   \n",
       "6   {'svc__C': 1, 'svc__gamma': 'scale', 'svc__ker...         0.965817   \n",
       "7   {'svc__C': 1, 'svc__gamma': 'scale', 'svc__ker...         0.852108   \n",
       "8   {'svc__C': 1, 'svc__gamma': 'scale', 'svc__ker...         0.625320   \n",
       "9   {'svc__C': 10, 'svc__gamma': 'scale', 'svc__ke...         0.965871   \n",
       "10  {'svc__C': 10, 'svc__gamma': 'scale', 'svc__ke...         0.796524   \n",
       "11  {'svc__C': 10, 'svc__gamma': 'scale', 'svc__ke...         0.825978   \n",
       "\n",
       "    split1_test_AUC  ...  split3_test_Sensitivity  mean_test_Sensitivity  \\\n",
       "0          0.839589  ...                 0.253669               0.268344   \n",
       "1          0.851529  ...                 0.029350               0.022011   \n",
       "2          0.853107  ...                 0.000000               0.000000   \n",
       "3          0.835507  ...                 0.327044               0.364260   \n",
       "4          0.848628  ...                 0.115304               0.074420   \n",
       "5          0.847148  ...                 0.218029               0.219601   \n",
       "6          0.835809  ...                 0.339623               0.391514   \n",
       "7          0.843723  ...                 0.425577               0.346431   \n",
       "8          0.683358  ...                 0.448637               0.434485   \n",
       "9          0.836233  ...                 0.339623               0.391514   \n",
       "10         0.818780  ...                 0.486373               0.410371   \n",
       "11         0.679914  ...                 0.452830               0.431863   \n",
       "\n",
       "    std_test_Sensitivity  rank_test_Sensitivity  split0_train_Sensitivity  \\\n",
       "0               0.009720                      8                  0.208945   \n",
       "1               0.007338                     11                  0.017470   \n",
       "2               0.000000                     12                  0.000000   \n",
       "3               0.027589                      6                  0.308176   \n",
       "4               0.025525                     10                  0.061495   \n",
       "5               0.007756                      9                  0.160028   \n",
       "6               0.033126                      4                  0.322851   \n",
       "7               0.047721                      7                  0.330538   \n",
       "8               0.021038                      1                  0.390636   \n",
       "9               0.033126                      4                  0.322851   \n",
       "10              0.048453                      3                  0.445143   \n",
       "11              0.032917                      2                  0.376660   \n",
       "\n",
       "    split1_train_Sensitivity  split2_train_Sensitivity  \\\n",
       "0                   0.274633                  0.334032   \n",
       "1                   0.020266                  0.024458   \n",
       "2                   0.000000                  0.000000   \n",
       "3                   0.375961                  0.433263   \n",
       "4                   0.077568                  0.097834   \n",
       "5                   0.214535                  0.255066   \n",
       "6                   0.394829                  0.464710   \n",
       "7                   0.410203                  0.438155   \n",
       "8                   0.418588                  0.447939   \n",
       "9                   0.394829                  0.465409   \n",
       "10                  0.535290                  0.563242   \n",
       "11                  0.423480                  0.459818   \n",
       "\n",
       "    split3_train_Sensitivity  mean_train_Sensitivity  std_train_Sensitivity  \n",
       "0                   0.315164                0.283194               0.047940  \n",
       "1                   0.020266                0.020615               0.002495  \n",
       "2                   0.000000                0.000000               0.000000  \n",
       "3                   0.433962                0.387841               0.051667  \n",
       "4                   0.088749                0.081412               0.013555  \n",
       "5                   0.244584                0.218553               0.036919  \n",
       "6                   0.452131                0.408630               0.056093  \n",
       "7                   0.484277                0.415793               0.055879  \n",
       "8                   0.450734                0.426974               0.024468  \n",
       "9                   0.452830                0.408980               0.056404  \n",
       "10                  0.586303                0.532495               0.053570  \n",
       "11                  0.452131                0.428022               0.032600  \n",
       "\n",
       "[12 rows x 47 columns]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_svc = gs.cv_results_\n",
    "data = pandas.DataFrame(results_svc)\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>params</th>\n",
       "      <th>mean_test_AUC</th>\n",
       "      <th>mean_test_F_score</th>\n",
       "      <th>mean_test_Sensitivity</th>\n",
       "      <th>rank_test_AUC</th>\n",
       "      <th>rank_test_F_score</th>\n",
       "      <th>rank_test_Sensitivity</th>\n",
       "      <th>mean_train_AUC</th>\n",
       "      <th>mean_train_F_score</th>\n",
       "      <th>mean_train_Sensitivity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>40.011196</td>\n",
       "      <td>{'svc__C': 0.001, 'svc__gamma': 'scale', 'svc_...</td>\n",
       "      <td>0.849134</td>\n",
       "      <td>0.399287</td>\n",
       "      <td>0.268344</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>0.873948</td>\n",
       "      <td>0.414885</td>\n",
       "      <td>0.283194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>46.010588</td>\n",
       "      <td>{'svc__C': 0.001, 'svc__gamma': 'scale', 'svc_...</td>\n",
       "      <td>0.839221</td>\n",
       "      <td>0.042729</td>\n",
       "      <td>0.022011</td>\n",
       "      <td>6</td>\n",
       "      <td>11</td>\n",
       "      <td>11</td>\n",
       "      <td>0.883681</td>\n",
       "      <td>0.040283</td>\n",
       "      <td>0.020615</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>48.948824</td>\n",
       "      <td>{'svc__C': 0.001, 'svc__gamma': 'scale', 'svc_...</td>\n",
       "      <td>0.842535</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5</td>\n",
       "      <td>12</td>\n",
       "      <td>12</td>\n",
       "      <td>0.853601</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>39.745382</td>\n",
       "      <td>{'svc__C': 0.01, 'svc__gamma': 'scale', 'svc__...</td>\n",
       "      <td>0.844399</td>\n",
       "      <td>0.487738</td>\n",
       "      <td>0.364260</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>0.868839</td>\n",
       "      <td>0.510337</td>\n",
       "      <td>0.387841</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>50.130707</td>\n",
       "      <td>{'svc__C': 0.01, 'svc__gamma': 'scale', 'svc__...</td>\n",
       "      <td>0.832056</td>\n",
       "      <td>0.135121</td>\n",
       "      <td>0.074420</td>\n",
       "      <td>7</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>0.884842</td>\n",
       "      <td>0.149338</td>\n",
       "      <td>0.081412</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>51.219475</td>\n",
       "      <td>{'svc__C': 0.01, 'svc__gamma': 'scale', 'svc__...</td>\n",
       "      <td>0.831313</td>\n",
       "      <td>0.342604</td>\n",
       "      <td>0.219601</td>\n",
       "      <td>8</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>0.839334</td>\n",
       "      <td>0.339956</td>\n",
       "      <td>0.218553</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>96.269707</td>\n",
       "      <td>{'svc__C': 1, 'svc__gamma': 'scale', 'svc__ker...</td>\n",
       "      <td>0.844004</td>\n",
       "      <td>0.510040</td>\n",
       "      <td>0.391514</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0.867881</td>\n",
       "      <td>0.525761</td>\n",
       "      <td>0.408630</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>51.326718</td>\n",
       "      <td>{'svc__C': 1, 'svc__gamma': 'scale', 'svc__ker...</td>\n",
       "      <td>0.812497</td>\n",
       "      <td>0.459162</td>\n",
       "      <td>0.346431</td>\n",
       "      <td>9</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>0.906362</td>\n",
       "      <td>0.559482</td>\n",
       "      <td>0.415793</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>24.178688</td>\n",
       "      <td>{'svc__C': 1, 'svc__gamma': 'scale', 'svc__ker...</td>\n",
       "      <td>0.644190</td>\n",
       "      <td>0.448139</td>\n",
       "      <td>0.434485</td>\n",
       "      <td>12</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>0.642793</td>\n",
       "      <td>0.453644</td>\n",
       "      <td>0.426974</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>389.273173</td>\n",
       "      <td>{'svc__C': 10, 'svc__gamma': 'scale', 'svc__ke...</td>\n",
       "      <td>0.843949</td>\n",
       "      <td>0.510040</td>\n",
       "      <td>0.391514</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0.867898</td>\n",
       "      <td>0.526133</td>\n",
       "      <td>0.408980</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>86.258530</td>\n",
       "      <td>{'svc__C': 10, 'svc__gamma': 'scale', 'svc__ke...</td>\n",
       "      <td>0.782387</td>\n",
       "      <td>0.496160</td>\n",
       "      <td>0.410371</td>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0.917496</td>\n",
       "      <td>0.658020</td>\n",
       "      <td>0.532495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>16.129594</td>\n",
       "      <td>{'svc__C': 10, 'svc__gamma': 'scale', 'svc__ke...</td>\n",
       "      <td>0.688934</td>\n",
       "      <td>0.426242</td>\n",
       "      <td>0.431863</td>\n",
       "      <td>11</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>0.653024</td>\n",
       "      <td>0.430286</td>\n",
       "      <td>0.428022</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    mean_fit_time                                             params  \\\n",
       "0       40.011196  {'svc__C': 0.001, 'svc__gamma': 'scale', 'svc_...   \n",
       "1       46.010588  {'svc__C': 0.001, 'svc__gamma': 'scale', 'svc_...   \n",
       "2       48.948824  {'svc__C': 0.001, 'svc__gamma': 'scale', 'svc_...   \n",
       "3       39.745382  {'svc__C': 0.01, 'svc__gamma': 'scale', 'svc__...   \n",
       "4       50.130707  {'svc__C': 0.01, 'svc__gamma': 'scale', 'svc__...   \n",
       "5       51.219475  {'svc__C': 0.01, 'svc__gamma': 'scale', 'svc__...   \n",
       "6       96.269707  {'svc__C': 1, 'svc__gamma': 'scale', 'svc__ker...   \n",
       "7       51.326718  {'svc__C': 1, 'svc__gamma': 'scale', 'svc__ker...   \n",
       "8       24.178688  {'svc__C': 1, 'svc__gamma': 'scale', 'svc__ker...   \n",
       "9      389.273173  {'svc__C': 10, 'svc__gamma': 'scale', 'svc__ke...   \n",
       "10      86.258530  {'svc__C': 10, 'svc__gamma': 'scale', 'svc__ke...   \n",
       "11      16.129594  {'svc__C': 10, 'svc__gamma': 'scale', 'svc__ke...   \n",
       "\n",
       "    mean_test_AUC  mean_test_F_score  mean_test_Sensitivity  rank_test_AUC  \\\n",
       "0        0.849134           0.399287               0.268344              1   \n",
       "1        0.839221           0.042729               0.022011              6   \n",
       "2        0.842535           0.000000               0.000000              5   \n",
       "3        0.844399           0.487738               0.364260              2   \n",
       "4        0.832056           0.135121               0.074420              7   \n",
       "5        0.831313           0.342604               0.219601              8   \n",
       "6        0.844004           0.510040               0.391514              3   \n",
       "7        0.812497           0.459162               0.346431              9   \n",
       "8        0.644190           0.448139               0.434485             12   \n",
       "9        0.843949           0.510040               0.391514              4   \n",
       "10       0.782387           0.496160               0.410371             10   \n",
       "11       0.688934           0.426242               0.431863             11   \n",
       "\n",
       "    rank_test_F_score  rank_test_Sensitivity  mean_train_AUC  \\\n",
       "0                   8                      8        0.873948   \n",
       "1                  11                     11        0.883681   \n",
       "2                  12                     12        0.853601   \n",
       "3                   4                      6        0.868839   \n",
       "4                  10                     10        0.884842   \n",
       "5                   9                      9        0.839334   \n",
       "6                   1                      4        0.867881   \n",
       "7                   5                      7        0.906362   \n",
       "8                   6                      1        0.642793   \n",
       "9                   1                      4        0.867898   \n",
       "10                  3                      3        0.917496   \n",
       "11                  7                      2        0.653024   \n",
       "\n",
       "    mean_train_F_score  mean_train_Sensitivity  \n",
       "0             0.414885                0.283194  \n",
       "1             0.040283                0.020615  \n",
       "2             0.000000                0.000000  \n",
       "3             0.510337                0.387841  \n",
       "4             0.149338                0.081412  \n",
       "5             0.339956                0.218553  \n",
       "6             0.525761                0.408630  \n",
       "7             0.559482                0.415793  \n",
       "8             0.453644                0.426974  \n",
       "9             0.526133                0.408980  \n",
       "10            0.658020                0.532495  \n",
       "11            0.430286                0.428022  "
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "table_svc = make_table(data)\n",
    "table_svc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'svc__C': 1, 'svc__gamma': 'scale', 'svc__kernel': 'linear'}"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 4 folds for each of 32 candidates, totalling 128 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   5 tasks      | elapsed:    3.5s\n",
      "[Parallel(n_jobs=-1)]: Done  10 tasks      | elapsed:    8.2s\n",
      "[Parallel(n_jobs=-1)]: Done  17 tasks      | elapsed:   16.6s\n",
      "[Parallel(n_jobs=-1)]: Done  24 tasks      | elapsed:   18.9s\n",
      "[Parallel(n_jobs=-1)]: Done  33 tasks      | elapsed:   29.9s\n",
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:   36.0s\n",
      "[Parallel(n_jobs=-1)]: Done  53 tasks      | elapsed:   45.3s\n",
      "[Parallel(n_jobs=-1)]: Done  64 tasks      | elapsed:   55.9s\n",
      "[Parallel(n_jobs=-1)]: Done  77 tasks      | elapsed:  1.2min\n",
      "[Parallel(n_jobs=-1)]: Done  90 tasks      | elapsed:  1.3min\n",
      "[Parallel(n_jobs=-1)]: Done 105 tasks      | elapsed:  1.5min\n",
      "[Parallel(n_jobs=-1)]: Done 120 tasks      | elapsed:  1.7min\n",
      "[Parallel(n_jobs=-1)]: Done 128 out of 128 | elapsed:  1.9min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=StratifiedKFold(n_splits=4, random_state=None, shuffle=False),\n",
       "             error_score='raise-deprecating',\n",
       "             estimator=Pipeline(memory=None,\n",
       "                                steps=[('standardscaler',\n",
       "                                        StandardScaler(copy=True,\n",
       "                                                       with_mean=True,\n",
       "                                                       with_std=True)),\n",
       "                                       ('gradientboostingclassifier',\n",
       "                                        GradientBoostingClassifier(criterion='friedman_mse',\n",
       "                                                                   init=None,\n",
       "                                                                   learning_rate=0.1,\n",
       "                                                                   loss='deviance',\n",
       "                                                                   max_...\n",
       "             param_grid={'gradientboostingclassifier__learning_rate': [0.3, 0.2,\n",
       "                                                                       0.1,\n",
       "                                                                       0.01],\n",
       "                         'gradientboostingclassifier__loss': ('deviance',\n",
       "                                                              'exponential'),\n",
       "                         'gradientboostingclassifier__n_estimators': [50, 100,\n",
       "                                                                      200,\n",
       "                                                                      300]},\n",
       "             pre_dispatch='2*n_jobs', refit='F-score', return_train_score=True,\n",
       "             scoring={'AUC': 'roc_auc', 'F-score': 'f1',\n",
       "                      'Sensitivity': make_scorer(recall_score)},\n",
       "             verbose=10)"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "scoring = {'AUC': 'roc_auc', 'F-score': 'f1', 'Sensitivity': make_scorer(recall_score)} \n",
    "parameters = {'gradientboostingclassifier__loss':('deviance', 'exponential'), \n",
    "              'gradientboostingclassifier__learning_rate':([0.3, 0.2, 0.1, 0.01]), \n",
    "              'gradientboostingclassifier__n_estimators':([50, 100, 200, 300]),\n",
    "             }\n",
    "\n",
    "pp = make_pipeline(StandardScaler(), GradientBoostingClassifier())\n",
    "\n",
    "gs = GridSearchCV(pp, parameters, cv=skf, scoring=scoring, refit='F-score', return_train_score=True, n_jobs=-1, verbose=10)\n",
    "\n",
    "gs.fit(X, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_gradientboostingclassifier__learning_rate</th>\n",
       "      <th>param_gradientboostingclassifier__loss</th>\n",
       "      <th>param_gradientboostingclassifier__n_estimators</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_AUC</th>\n",
       "      <th>split1_test_AUC</th>\n",
       "      <th>...</th>\n",
       "      <th>split3_test_Sensitivity</th>\n",
       "      <th>mean_test_Sensitivity</th>\n",
       "      <th>std_test_Sensitivity</th>\n",
       "      <th>rank_test_Sensitivity</th>\n",
       "      <th>split0_train_Sensitivity</th>\n",
       "      <th>split1_train_Sensitivity</th>\n",
       "      <th>split2_train_Sensitivity</th>\n",
       "      <th>split3_train_Sensitivity</th>\n",
       "      <th>mean_train_Sensitivity</th>\n",
       "      <th>std_train_Sensitivity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.018934</td>\n",
       "      <td>0.034350</td>\n",
       "      <td>0.051197</td>\n",
       "      <td>7.218690e-03</td>\n",
       "      <td>0.3</td>\n",
       "      <td>deviance</td>\n",
       "      <td>50</td>\n",
       "      <td>{'gradientboostingclassifier__learning_rate': ...</td>\n",
       "      <td>0.980061</td>\n",
       "      <td>0.893875</td>\n",
       "      <td>...</td>\n",
       "      <td>0.626834</td>\n",
       "      <td>0.522001</td>\n",
       "      <td>0.080801</td>\n",
       "      <td>16</td>\n",
       "      <td>0.629630</td>\n",
       "      <td>0.711391</td>\n",
       "      <td>0.742138</td>\n",
       "      <td>0.735150</td>\n",
       "      <td>0.704577</td>\n",
       "      <td>0.044747</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.908934</td>\n",
       "      <td>0.034056</td>\n",
       "      <td>0.058595</td>\n",
       "      <td>6.763725e-03</td>\n",
       "      <td>0.3</td>\n",
       "      <td>deviance</td>\n",
       "      <td>100</td>\n",
       "      <td>{'gradientboostingclassifier__learning_rate': ...</td>\n",
       "      <td>0.978085</td>\n",
       "      <td>0.888735</td>\n",
       "      <td>...</td>\n",
       "      <td>0.612159</td>\n",
       "      <td>0.517809</td>\n",
       "      <td>0.071062</td>\n",
       "      <td>22</td>\n",
       "      <td>0.697414</td>\n",
       "      <td>0.780573</td>\n",
       "      <td>0.791055</td>\n",
       "      <td>0.785465</td>\n",
       "      <td>0.763627</td>\n",
       "      <td>0.038407</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.236166</td>\n",
       "      <td>0.119706</td>\n",
       "      <td>0.074007</td>\n",
       "      <td>1.589358e-03</td>\n",
       "      <td>0.3</td>\n",
       "      <td>deviance</td>\n",
       "      <td>200</td>\n",
       "      <td>{'gradientboostingclassifier__learning_rate': ...</td>\n",
       "      <td>0.975819</td>\n",
       "      <td>0.890047</td>\n",
       "      <td>...</td>\n",
       "      <td>0.603774</td>\n",
       "      <td>0.514666</td>\n",
       "      <td>0.063907</td>\n",
       "      <td>23</td>\n",
       "      <td>0.773585</td>\n",
       "      <td>0.835779</td>\n",
       "      <td>0.867925</td>\n",
       "      <td>0.862334</td>\n",
       "      <td>0.834906</td>\n",
       "      <td>0.037428</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6.784479</td>\n",
       "      <td>0.107923</td>\n",
       "      <td>0.109123</td>\n",
       "      <td>1.981880e-02</td>\n",
       "      <td>0.3</td>\n",
       "      <td>deviance</td>\n",
       "      <td>300</td>\n",
       "      <td>{'gradientboostingclassifier__learning_rate': ...</td>\n",
       "      <td>0.972247</td>\n",
       "      <td>0.890363</td>\n",
       "      <td>...</td>\n",
       "      <td>0.612159</td>\n",
       "      <td>0.511520</td>\n",
       "      <td>0.071401</td>\n",
       "      <td>25</td>\n",
       "      <td>0.835779</td>\n",
       "      <td>0.891684</td>\n",
       "      <td>0.916841</td>\n",
       "      <td>0.907757</td>\n",
       "      <td>0.888015</td>\n",
       "      <td>0.031475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.942293</td>\n",
       "      <td>0.037418</td>\n",
       "      <td>0.046877</td>\n",
       "      <td>6.344746e-06</td>\n",
       "      <td>0.3</td>\n",
       "      <td>exponential</td>\n",
       "      <td>50</td>\n",
       "      <td>{'gradientboostingclassifier__learning_rate': ...</td>\n",
       "      <td>0.981410</td>\n",
       "      <td>0.920846</td>\n",
       "      <td>...</td>\n",
       "      <td>0.624738</td>\n",
       "      <td>0.537726</td>\n",
       "      <td>0.063562</td>\n",
       "      <td>3</td>\n",
       "      <td>0.606569</td>\n",
       "      <td>0.685535</td>\n",
       "      <td>0.714885</td>\n",
       "      <td>0.689727</td>\n",
       "      <td>0.674179</td>\n",
       "      <td>0.040616</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1.797441</td>\n",
       "      <td>0.053532</td>\n",
       "      <td>0.058597</td>\n",
       "      <td>2.030439e-02</td>\n",
       "      <td>0.3</td>\n",
       "      <td>exponential</td>\n",
       "      <td>100</td>\n",
       "      <td>{'gradientboostingclassifier__learning_rate': ...</td>\n",
       "      <td>0.981878</td>\n",
       "      <td>0.919125</td>\n",
       "      <td>...</td>\n",
       "      <td>0.597484</td>\n",
       "      <td>0.527771</td>\n",
       "      <td>0.047975</td>\n",
       "      <td>12</td>\n",
       "      <td>0.635919</td>\n",
       "      <td>0.723270</td>\n",
       "      <td>0.759609</td>\n",
       "      <td>0.732355</td>\n",
       "      <td>0.712788</td>\n",
       "      <td>0.046351</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>4.030110</td>\n",
       "      <td>0.064890</td>\n",
       "      <td>0.062490</td>\n",
       "      <td>1.030919e-05</td>\n",
       "      <td>0.3</td>\n",
       "      <td>exponential</td>\n",
       "      <td>200</td>\n",
       "      <td>{'gradientboostingclassifier__learning_rate': ...</td>\n",
       "      <td>0.981495</td>\n",
       "      <td>0.913181</td>\n",
       "      <td>...</td>\n",
       "      <td>0.593291</td>\n",
       "      <td>0.520433</td>\n",
       "      <td>0.048657</td>\n",
       "      <td>19</td>\n",
       "      <td>0.696716</td>\n",
       "      <td>0.776380</td>\n",
       "      <td>0.819008</td>\n",
       "      <td>0.801537</td>\n",
       "      <td>0.773410</td>\n",
       "      <td>0.046801</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>5.160142</td>\n",
       "      <td>0.111802</td>\n",
       "      <td>0.093746</td>\n",
       "      <td>2.787433e-06</td>\n",
       "      <td>0.3</td>\n",
       "      <td>exponential</td>\n",
       "      <td>300</td>\n",
       "      <td>{'gradientboostingclassifier__learning_rate': ...</td>\n",
       "      <td>0.980849</td>\n",
       "      <td>0.902096</td>\n",
       "      <td>...</td>\n",
       "      <td>0.587002</td>\n",
       "      <td>0.510474</td>\n",
       "      <td>0.055337</td>\n",
       "      <td>26</td>\n",
       "      <td>0.747030</td>\n",
       "      <td>0.822502</td>\n",
       "      <td>0.865129</td>\n",
       "      <td>0.850454</td>\n",
       "      <td>0.821279</td>\n",
       "      <td>0.045520</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.949221</td>\n",
       "      <td>0.020303</td>\n",
       "      <td>0.054682</td>\n",
       "      <td>1.354142e-02</td>\n",
       "      <td>0.2</td>\n",
       "      <td>deviance</td>\n",
       "      <td>50</td>\n",
       "      <td>{'gradientboostingclassifier__learning_rate': ...</td>\n",
       "      <td>0.979664</td>\n",
       "      <td>0.895185</td>\n",
       "      <td>...</td>\n",
       "      <td>0.624738</td>\n",
       "      <td>0.528290</td>\n",
       "      <td>0.072939</td>\n",
       "      <td>11</td>\n",
       "      <td>0.607966</td>\n",
       "      <td>0.686233</td>\n",
       "      <td>0.725367</td>\n",
       "      <td>0.701607</td>\n",
       "      <td>0.680294</td>\n",
       "      <td>0.044024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1.831514</td>\n",
       "      <td>0.033565</td>\n",
       "      <td>0.058592</td>\n",
       "      <td>2.029400e-02</td>\n",
       "      <td>0.2</td>\n",
       "      <td>deviance</td>\n",
       "      <td>100</td>\n",
       "      <td>{'gradientboostingclassifier__learning_rate': ...</td>\n",
       "      <td>0.979098</td>\n",
       "      <td>0.896087</td>\n",
       "      <td>...</td>\n",
       "      <td>0.612159</td>\n",
       "      <td>0.521479</td>\n",
       "      <td>0.063265</td>\n",
       "      <td>17</td>\n",
       "      <td>0.655486</td>\n",
       "      <td>0.730259</td>\n",
       "      <td>0.767994</td>\n",
       "      <td>0.741440</td>\n",
       "      <td>0.723795</td>\n",
       "      <td>0.041752</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>3.472657</td>\n",
       "      <td>0.043318</td>\n",
       "      <td>0.066403</td>\n",
       "      <td>6.763003e-03</td>\n",
       "      <td>0.2</td>\n",
       "      <td>deviance</td>\n",
       "      <td>200</td>\n",
       "      <td>{'gradientboostingclassifier__learning_rate': ...</td>\n",
       "      <td>0.978551</td>\n",
       "      <td>0.896703</td>\n",
       "      <td>...</td>\n",
       "      <td>0.622642</td>\n",
       "      <td>0.523576</td>\n",
       "      <td>0.065315</td>\n",
       "      <td>14</td>\n",
       "      <td>0.716282</td>\n",
       "      <td>0.796646</td>\n",
       "      <td>0.823201</td>\n",
       "      <td>0.809224</td>\n",
       "      <td>0.786338</td>\n",
       "      <td>0.041523</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>5.641785</td>\n",
       "      <td>0.118673</td>\n",
       "      <td>0.089843</td>\n",
       "      <td>6.767442e-03</td>\n",
       "      <td>0.2</td>\n",
       "      <td>deviance</td>\n",
       "      <td>300</td>\n",
       "      <td>{'gradientboostingclassifier__learning_rate': ...</td>\n",
       "      <td>0.978074</td>\n",
       "      <td>0.894272</td>\n",
       "      <td>...</td>\n",
       "      <td>0.616352</td>\n",
       "      <td>0.519907</td>\n",
       "      <td>0.064565</td>\n",
       "      <td>21</td>\n",
       "      <td>0.766597</td>\n",
       "      <td>0.832285</td>\n",
       "      <td>0.862334</td>\n",
       "      <td>0.854647</td>\n",
       "      <td>0.828966</td>\n",
       "      <td>0.037663</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.964845</td>\n",
       "      <td>0.023105</td>\n",
       "      <td>0.046870</td>\n",
       "      <td>1.104779e-02</td>\n",
       "      <td>0.2</td>\n",
       "      <td>exponential</td>\n",
       "      <td>50</td>\n",
       "      <td>{'gradientboostingclassifier__learning_rate': ...</td>\n",
       "      <td>0.980877</td>\n",
       "      <td>0.919508</td>\n",
       "      <td>...</td>\n",
       "      <td>0.624738</td>\n",
       "      <td>0.533008</td>\n",
       "      <td>0.071561</td>\n",
       "      <td>7</td>\n",
       "      <td>0.591894</td>\n",
       "      <td>0.676450</td>\n",
       "      <td>0.700210</td>\n",
       "      <td>0.682041</td>\n",
       "      <td>0.662648</td>\n",
       "      <td>0.041784</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>1.789047</td>\n",
       "      <td>0.056867</td>\n",
       "      <td>0.054681</td>\n",
       "      <td>7.812859e-03</td>\n",
       "      <td>0.2</td>\n",
       "      <td>exponential</td>\n",
       "      <td>100</td>\n",
       "      <td>{'gradientboostingclassifier__learning_rate': ...</td>\n",
       "      <td>0.981155</td>\n",
       "      <td>0.918554</td>\n",
       "      <td>...</td>\n",
       "      <td>0.633124</td>\n",
       "      <td>0.536677</td>\n",
       "      <td>0.068431</td>\n",
       "      <td>4</td>\n",
       "      <td>0.614256</td>\n",
       "      <td>0.700210</td>\n",
       "      <td>0.721873</td>\n",
       "      <td>0.704403</td>\n",
       "      <td>0.685185</td>\n",
       "      <td>0.041749</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>3.590663</td>\n",
       "      <td>0.104142</td>\n",
       "      <td>0.089025</td>\n",
       "      <td>3.004021e-02</td>\n",
       "      <td>0.2</td>\n",
       "      <td>exponential</td>\n",
       "      <td>200</td>\n",
       "      <td>{'gradientboostingclassifier__learning_rate': ...</td>\n",
       "      <td>0.981408</td>\n",
       "      <td>0.909749</td>\n",
       "      <td>...</td>\n",
       "      <td>0.616352</td>\n",
       "      <td>0.525148</td>\n",
       "      <td>0.065251</td>\n",
       "      <td>13</td>\n",
       "      <td>0.662474</td>\n",
       "      <td>0.747030</td>\n",
       "      <td>0.786862</td>\n",
       "      <td>0.759609</td>\n",
       "      <td>0.738994</td>\n",
       "      <td>0.046466</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>5.865595</td>\n",
       "      <td>0.084518</td>\n",
       "      <td>0.093749</td>\n",
       "      <td>3.576279e-07</td>\n",
       "      <td>0.2</td>\n",
       "      <td>exponential</td>\n",
       "      <td>300</td>\n",
       "      <td>{'gradientboostingclassifier__learning_rate': ...</td>\n",
       "      <td>0.981014</td>\n",
       "      <td>0.905370</td>\n",
       "      <td>...</td>\n",
       "      <td>0.614256</td>\n",
       "      <td>0.522527</td>\n",
       "      <td>0.064724</td>\n",
       "      <td>15</td>\n",
       "      <td>0.700210</td>\n",
       "      <td>0.777079</td>\n",
       "      <td>0.824598</td>\n",
       "      <td>0.803634</td>\n",
       "      <td>0.776380</td>\n",
       "      <td>0.047091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>1.010746</td>\n",
       "      <td>0.017026</td>\n",
       "      <td>0.046872</td>\n",
       "      <td>8.066691e-06</td>\n",
       "      <td>0.1</td>\n",
       "      <td>deviance</td>\n",
       "      <td>50</td>\n",
       "      <td>{'gradientboostingclassifier__learning_rate': ...</td>\n",
       "      <td>0.980584</td>\n",
       "      <td>0.898009</td>\n",
       "      <td>...</td>\n",
       "      <td>0.654088</td>\n",
       "      <td>0.539296</td>\n",
       "      <td>0.080232</td>\n",
       "      <td>1</td>\n",
       "      <td>0.575821</td>\n",
       "      <td>0.662474</td>\n",
       "      <td>0.696017</td>\n",
       "      <td>0.668064</td>\n",
       "      <td>0.650594</td>\n",
       "      <td>0.045002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>2.466631</td>\n",
       "      <td>0.041158</td>\n",
       "      <td>0.064034</td>\n",
       "      <td>1.625492e-02</td>\n",
       "      <td>0.1</td>\n",
       "      <td>deviance</td>\n",
       "      <td>100</td>\n",
       "      <td>{'gradientboostingclassifier__learning_rate': ...</td>\n",
       "      <td>0.980691</td>\n",
       "      <td>0.901120</td>\n",
       "      <td>...</td>\n",
       "      <td>0.631027</td>\n",
       "      <td>0.534579</td>\n",
       "      <td>0.076037</td>\n",
       "      <td>5</td>\n",
       "      <td>0.607966</td>\n",
       "      <td>0.691125</td>\n",
       "      <td>0.710692</td>\n",
       "      <td>0.693920</td>\n",
       "      <td>0.675926</td>\n",
       "      <td>0.039944</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>4.073749</td>\n",
       "      <td>0.107715</td>\n",
       "      <td>0.066402</td>\n",
       "      <td>6.753197e-03</td>\n",
       "      <td>0.1</td>\n",
       "      <td>deviance</td>\n",
       "      <td>200</td>\n",
       "      <td>{'gradientboostingclassifier__learning_rate': ...</td>\n",
       "      <td>0.980072</td>\n",
       "      <td>0.888999</td>\n",
       "      <td>...</td>\n",
       "      <td>0.612159</td>\n",
       "      <td>0.529341</td>\n",
       "      <td>0.060334</td>\n",
       "      <td>10</td>\n",
       "      <td>0.642907</td>\n",
       "      <td>0.723270</td>\n",
       "      <td>0.756813</td>\n",
       "      <td>0.734451</td>\n",
       "      <td>0.714361</td>\n",
       "      <td>0.042985</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>6.876342</td>\n",
       "      <td>0.161335</td>\n",
       "      <td>0.104995</td>\n",
       "      <td>2.080029e-02</td>\n",
       "      <td>0.1</td>\n",
       "      <td>deviance</td>\n",
       "      <td>300</td>\n",
       "      <td>{'gradientboostingclassifier__learning_rate': ...</td>\n",
       "      <td>0.980126</td>\n",
       "      <td>0.890811</td>\n",
       "      <td>...</td>\n",
       "      <td>0.605870</td>\n",
       "      <td>0.520432</td>\n",
       "      <td>0.057093</td>\n",
       "      <td>20</td>\n",
       "      <td>0.679245</td>\n",
       "      <td>0.756115</td>\n",
       "      <td>0.793152</td>\n",
       "      <td>0.768693</td>\n",
       "      <td>0.749301</td>\n",
       "      <td>0.042583</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>1.144039</td>\n",
       "      <td>0.017098</td>\n",
       "      <td>0.042977</td>\n",
       "      <td>6.761799e-03</td>\n",
       "      <td>0.1</td>\n",
       "      <td>exponential</td>\n",
       "      <td>50</td>\n",
       "      <td>{'gradientboostingclassifier__learning_rate': ...</td>\n",
       "      <td>0.981005</td>\n",
       "      <td>0.922730</td>\n",
       "      <td>...</td>\n",
       "      <td>0.645702</td>\n",
       "      <td>0.534055</td>\n",
       "      <td>0.079531</td>\n",
       "      <td>6</td>\n",
       "      <td>0.577219</td>\n",
       "      <td>0.654088</td>\n",
       "      <td>0.680643</td>\n",
       "      <td>0.657582</td>\n",
       "      <td>0.642383</td>\n",
       "      <td>0.038981</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>1.836223</td>\n",
       "      <td>0.027213</td>\n",
       "      <td>0.058596</td>\n",
       "      <td>6.764688e-03</td>\n",
       "      <td>0.1</td>\n",
       "      <td>exponential</td>\n",
       "      <td>100</td>\n",
       "      <td>{'gradientboostingclassifier__learning_rate': ...</td>\n",
       "      <td>0.981278</td>\n",
       "      <td>0.919517</td>\n",
       "      <td>...</td>\n",
       "      <td>0.641509</td>\n",
       "      <td>0.538248</td>\n",
       "      <td>0.076013</td>\n",
       "      <td>2</td>\n",
       "      <td>0.592593</td>\n",
       "      <td>0.676450</td>\n",
       "      <td>0.701607</td>\n",
       "      <td>0.679944</td>\n",
       "      <td>0.662648</td>\n",
       "      <td>0.041579</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>3.563814</td>\n",
       "      <td>0.087699</td>\n",
       "      <td>0.078122</td>\n",
       "      <td>2.016012e-06</td>\n",
       "      <td>0.1</td>\n",
       "      <td>exponential</td>\n",
       "      <td>200</td>\n",
       "      <td>{'gradientboostingclassifier__learning_rate': ...</td>\n",
       "      <td>0.981661</td>\n",
       "      <td>0.916248</td>\n",
       "      <td>...</td>\n",
       "      <td>0.622642</td>\n",
       "      <td>0.529864</td>\n",
       "      <td>0.065332</td>\n",
       "      <td>9</td>\n",
       "      <td>0.615653</td>\n",
       "      <td>0.697414</td>\n",
       "      <td>0.734451</td>\n",
       "      <td>0.707897</td>\n",
       "      <td>0.688854</td>\n",
       "      <td>0.044366</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>5.525891</td>\n",
       "      <td>0.050021</td>\n",
       "      <td>0.109373</td>\n",
       "      <td>1.913932e-02</td>\n",
       "      <td>0.1</td>\n",
       "      <td>exponential</td>\n",
       "      <td>300</td>\n",
       "      <td>{'gradientboostingclassifier__learning_rate': ...</td>\n",
       "      <td>0.981686</td>\n",
       "      <td>0.913524</td>\n",
       "      <td>...</td>\n",
       "      <td>0.631027</td>\n",
       "      <td>0.530913</td>\n",
       "      <td>0.065332</td>\n",
       "      <td>8</td>\n",
       "      <td>0.640112</td>\n",
       "      <td>0.719776</td>\n",
       "      <td>0.759609</td>\n",
       "      <td>0.733753</td>\n",
       "      <td>0.713312</td>\n",
       "      <td>0.044613</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>1.140621</td>\n",
       "      <td>0.067201</td>\n",
       "      <td>0.050788</td>\n",
       "      <td>6.766239e-03</td>\n",
       "      <td>0.01</td>\n",
       "      <td>deviance</td>\n",
       "      <td>50</td>\n",
       "      <td>{'gradientboostingclassifier__learning_rate': ...</td>\n",
       "      <td>0.978728</td>\n",
       "      <td>0.876318</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>31</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>1.957033</td>\n",
       "      <td>0.072777</td>\n",
       "      <td>0.062491</td>\n",
       "      <td>1.105006e-02</td>\n",
       "      <td>0.01</td>\n",
       "      <td>deviance</td>\n",
       "      <td>100</td>\n",
       "      <td>{'gradientboostingclassifier__learning_rate': ...</td>\n",
       "      <td>0.980022</td>\n",
       "      <td>0.883821</td>\n",
       "      <td>...</td>\n",
       "      <td>0.266247</td>\n",
       "      <td>0.288263</td>\n",
       "      <td>0.037811</td>\n",
       "      <td>29</td>\n",
       "      <td>0.252271</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.436059</td>\n",
       "      <td>0.387841</td>\n",
       "      <td>0.352376</td>\n",
       "      <td>0.068272</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>3.874999</td>\n",
       "      <td>0.094398</td>\n",
       "      <td>0.078121</td>\n",
       "      <td>2.227013e-06</td>\n",
       "      <td>0.01</td>\n",
       "      <td>deviance</td>\n",
       "      <td>200</td>\n",
       "      <td>{'gradientboostingclassifier__learning_rate': ...</td>\n",
       "      <td>0.980583</td>\n",
       "      <td>0.906263</td>\n",
       "      <td>...</td>\n",
       "      <td>0.607966</td>\n",
       "      <td>0.479030</td>\n",
       "      <td>0.076458</td>\n",
       "      <td>27</td>\n",
       "      <td>0.439553</td>\n",
       "      <td>0.547170</td>\n",
       "      <td>0.596785</td>\n",
       "      <td>0.623340</td>\n",
       "      <td>0.551712</td>\n",
       "      <td>0.070290</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>6.025265</td>\n",
       "      <td>0.139256</td>\n",
       "      <td>0.109373</td>\n",
       "      <td>3.573794e-06</td>\n",
       "      <td>0.01</td>\n",
       "      <td>deviance</td>\n",
       "      <td>300</td>\n",
       "      <td>{'gradientboostingclassifier__learning_rate': ...</td>\n",
       "      <td>0.981053</td>\n",
       "      <td>0.913476</td>\n",
       "      <td>...</td>\n",
       "      <td>0.637317</td>\n",
       "      <td>0.521479</td>\n",
       "      <td>0.072187</td>\n",
       "      <td>18</td>\n",
       "      <td>0.539483</td>\n",
       "      <td>0.629630</td>\n",
       "      <td>0.664570</td>\n",
       "      <td>0.663871</td>\n",
       "      <td>0.624389</td>\n",
       "      <td>0.051014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>1.214842</td>\n",
       "      <td>0.090005</td>\n",
       "      <td>0.058594</td>\n",
       "      <td>6.762728e-03</td>\n",
       "      <td>0.01</td>\n",
       "      <td>exponential</td>\n",
       "      <td>50</td>\n",
       "      <td>{'gradientboostingclassifier__learning_rate': ...</td>\n",
       "      <td>0.978594</td>\n",
       "      <td>0.875114</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>31</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>2.228589</td>\n",
       "      <td>0.120521</td>\n",
       "      <td>0.056160</td>\n",
       "      <td>5.716732e-03</td>\n",
       "      <td>0.01</td>\n",
       "      <td>exponential</td>\n",
       "      <td>100</td>\n",
       "      <td>{'gradientboostingclassifier__learning_rate': ...</td>\n",
       "      <td>0.979367</td>\n",
       "      <td>0.920586</td>\n",
       "      <td>...</td>\n",
       "      <td>0.064990</td>\n",
       "      <td>0.077044</td>\n",
       "      <td>0.009182</td>\n",
       "      <td>30</td>\n",
       "      <td>0.065688</td>\n",
       "      <td>0.069881</td>\n",
       "      <td>0.154437</td>\n",
       "      <td>0.101328</td>\n",
       "      <td>0.097834</td>\n",
       "      <td>0.035464</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>3.855266</td>\n",
       "      <td>0.109932</td>\n",
       "      <td>0.070322</td>\n",
       "      <td>7.806734e-03</td>\n",
       "      <td>0.01</td>\n",
       "      <td>exponential</td>\n",
       "      <td>200</td>\n",
       "      <td>{'gradientboostingclassifier__learning_rate': ...</td>\n",
       "      <td>0.980562</td>\n",
       "      <td>0.928645</td>\n",
       "      <td>...</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>0.448633</td>\n",
       "      <td>0.066407</td>\n",
       "      <td>28</td>\n",
       "      <td>0.386443</td>\n",
       "      <td>0.484277</td>\n",
       "      <td>0.572327</td>\n",
       "      <td>0.583508</td>\n",
       "      <td>0.506639</td>\n",
       "      <td>0.079327</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>5.734383</td>\n",
       "      <td>0.147604</td>\n",
       "      <td>0.105469</td>\n",
       "      <td>6.766168e-03</td>\n",
       "      <td>0.01</td>\n",
       "      <td>exponential</td>\n",
       "      <td>300</td>\n",
       "      <td>{'gradientboostingclassifier__learning_rate': ...</td>\n",
       "      <td>0.981024</td>\n",
       "      <td>0.926110</td>\n",
       "      <td>...</td>\n",
       "      <td>0.643606</td>\n",
       "      <td>0.512571</td>\n",
       "      <td>0.076128</td>\n",
       "      <td>24</td>\n",
       "      <td>0.509434</td>\n",
       "      <td>0.609364</td>\n",
       "      <td>0.632425</td>\n",
       "      <td>0.645003</td>\n",
       "      <td>0.599057</td>\n",
       "      <td>0.053299</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>32 rows × 47 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "0        1.018934      0.034350         0.051197    7.218690e-03   \n",
       "1        1.908934      0.034056         0.058595    6.763725e-03   \n",
       "2        4.236166      0.119706         0.074007    1.589358e-03   \n",
       "3        6.784479      0.107923         0.109123    1.981880e-02   \n",
       "4        0.942293      0.037418         0.046877    6.344746e-06   \n",
       "5        1.797441      0.053532         0.058597    2.030439e-02   \n",
       "6        4.030110      0.064890         0.062490    1.030919e-05   \n",
       "7        5.160142      0.111802         0.093746    2.787433e-06   \n",
       "8        0.949221      0.020303         0.054682    1.354142e-02   \n",
       "9        1.831514      0.033565         0.058592    2.029400e-02   \n",
       "10       3.472657      0.043318         0.066403    6.763003e-03   \n",
       "11       5.641785      0.118673         0.089843    6.767442e-03   \n",
       "12       0.964845      0.023105         0.046870    1.104779e-02   \n",
       "13       1.789047      0.056867         0.054681    7.812859e-03   \n",
       "14       3.590663      0.104142         0.089025    3.004021e-02   \n",
       "15       5.865595      0.084518         0.093749    3.576279e-07   \n",
       "16       1.010746      0.017026         0.046872    8.066691e-06   \n",
       "17       2.466631      0.041158         0.064034    1.625492e-02   \n",
       "18       4.073749      0.107715         0.066402    6.753197e-03   \n",
       "19       6.876342      0.161335         0.104995    2.080029e-02   \n",
       "20       1.144039      0.017098         0.042977    6.761799e-03   \n",
       "21       1.836223      0.027213         0.058596    6.764688e-03   \n",
       "22       3.563814      0.087699         0.078122    2.016012e-06   \n",
       "23       5.525891      0.050021         0.109373    1.913932e-02   \n",
       "24       1.140621      0.067201         0.050788    6.766239e-03   \n",
       "25       1.957033      0.072777         0.062491    1.105006e-02   \n",
       "26       3.874999      0.094398         0.078121    2.227013e-06   \n",
       "27       6.025265      0.139256         0.109373    3.573794e-06   \n",
       "28       1.214842      0.090005         0.058594    6.762728e-03   \n",
       "29       2.228589      0.120521         0.056160    5.716732e-03   \n",
       "30       3.855266      0.109932         0.070322    7.806734e-03   \n",
       "31       5.734383      0.147604         0.105469    6.766168e-03   \n",
       "\n",
       "   param_gradientboostingclassifier__learning_rate  \\\n",
       "0                                              0.3   \n",
       "1                                              0.3   \n",
       "2                                              0.3   \n",
       "3                                              0.3   \n",
       "4                                              0.3   \n",
       "5                                              0.3   \n",
       "6                                              0.3   \n",
       "7                                              0.3   \n",
       "8                                              0.2   \n",
       "9                                              0.2   \n",
       "10                                             0.2   \n",
       "11                                             0.2   \n",
       "12                                             0.2   \n",
       "13                                             0.2   \n",
       "14                                             0.2   \n",
       "15                                             0.2   \n",
       "16                                             0.1   \n",
       "17                                             0.1   \n",
       "18                                             0.1   \n",
       "19                                             0.1   \n",
       "20                                             0.1   \n",
       "21                                             0.1   \n",
       "22                                             0.1   \n",
       "23                                             0.1   \n",
       "24                                            0.01   \n",
       "25                                            0.01   \n",
       "26                                            0.01   \n",
       "27                                            0.01   \n",
       "28                                            0.01   \n",
       "29                                            0.01   \n",
       "30                                            0.01   \n",
       "31                                            0.01   \n",
       "\n",
       "   param_gradientboostingclassifier__loss  \\\n",
       "0                                deviance   \n",
       "1                                deviance   \n",
       "2                                deviance   \n",
       "3                                deviance   \n",
       "4                             exponential   \n",
       "5                             exponential   \n",
       "6                             exponential   \n",
       "7                             exponential   \n",
       "8                                deviance   \n",
       "9                                deviance   \n",
       "10                               deviance   \n",
       "11                               deviance   \n",
       "12                            exponential   \n",
       "13                            exponential   \n",
       "14                            exponential   \n",
       "15                            exponential   \n",
       "16                               deviance   \n",
       "17                               deviance   \n",
       "18                               deviance   \n",
       "19                               deviance   \n",
       "20                            exponential   \n",
       "21                            exponential   \n",
       "22                            exponential   \n",
       "23                            exponential   \n",
       "24                               deviance   \n",
       "25                               deviance   \n",
       "26                               deviance   \n",
       "27                               deviance   \n",
       "28                            exponential   \n",
       "29                            exponential   \n",
       "30                            exponential   \n",
       "31                            exponential   \n",
       "\n",
       "   param_gradientboostingclassifier__n_estimators  \\\n",
       "0                                              50   \n",
       "1                                             100   \n",
       "2                                             200   \n",
       "3                                             300   \n",
       "4                                              50   \n",
       "5                                             100   \n",
       "6                                             200   \n",
       "7                                             300   \n",
       "8                                              50   \n",
       "9                                             100   \n",
       "10                                            200   \n",
       "11                                            300   \n",
       "12                                             50   \n",
       "13                                            100   \n",
       "14                                            200   \n",
       "15                                            300   \n",
       "16                                             50   \n",
       "17                                            100   \n",
       "18                                            200   \n",
       "19                                            300   \n",
       "20                                             50   \n",
       "21                                            100   \n",
       "22                                            200   \n",
       "23                                            300   \n",
       "24                                             50   \n",
       "25                                            100   \n",
       "26                                            200   \n",
       "27                                            300   \n",
       "28                                             50   \n",
       "29                                            100   \n",
       "30                                            200   \n",
       "31                                            300   \n",
       "\n",
       "                                               params  split0_test_AUC  \\\n",
       "0   {'gradientboostingclassifier__learning_rate': ...         0.980061   \n",
       "1   {'gradientboostingclassifier__learning_rate': ...         0.978085   \n",
       "2   {'gradientboostingclassifier__learning_rate': ...         0.975819   \n",
       "3   {'gradientboostingclassifier__learning_rate': ...         0.972247   \n",
       "4   {'gradientboostingclassifier__learning_rate': ...         0.981410   \n",
       "5   {'gradientboostingclassifier__learning_rate': ...         0.981878   \n",
       "6   {'gradientboostingclassifier__learning_rate': ...         0.981495   \n",
       "7   {'gradientboostingclassifier__learning_rate': ...         0.980849   \n",
       "8   {'gradientboostingclassifier__learning_rate': ...         0.979664   \n",
       "9   {'gradientboostingclassifier__learning_rate': ...         0.979098   \n",
       "10  {'gradientboostingclassifier__learning_rate': ...         0.978551   \n",
       "11  {'gradientboostingclassifier__learning_rate': ...         0.978074   \n",
       "12  {'gradientboostingclassifier__learning_rate': ...         0.980877   \n",
       "13  {'gradientboostingclassifier__learning_rate': ...         0.981155   \n",
       "14  {'gradientboostingclassifier__learning_rate': ...         0.981408   \n",
       "15  {'gradientboostingclassifier__learning_rate': ...         0.981014   \n",
       "16  {'gradientboostingclassifier__learning_rate': ...         0.980584   \n",
       "17  {'gradientboostingclassifier__learning_rate': ...         0.980691   \n",
       "18  {'gradientboostingclassifier__learning_rate': ...         0.980072   \n",
       "19  {'gradientboostingclassifier__learning_rate': ...         0.980126   \n",
       "20  {'gradientboostingclassifier__learning_rate': ...         0.981005   \n",
       "21  {'gradientboostingclassifier__learning_rate': ...         0.981278   \n",
       "22  {'gradientboostingclassifier__learning_rate': ...         0.981661   \n",
       "23  {'gradientboostingclassifier__learning_rate': ...         0.981686   \n",
       "24  {'gradientboostingclassifier__learning_rate': ...         0.978728   \n",
       "25  {'gradientboostingclassifier__learning_rate': ...         0.980022   \n",
       "26  {'gradientboostingclassifier__learning_rate': ...         0.980583   \n",
       "27  {'gradientboostingclassifier__learning_rate': ...         0.981053   \n",
       "28  {'gradientboostingclassifier__learning_rate': ...         0.978594   \n",
       "29  {'gradientboostingclassifier__learning_rate': ...         0.979367   \n",
       "30  {'gradientboostingclassifier__learning_rate': ...         0.980562   \n",
       "31  {'gradientboostingclassifier__learning_rate': ...         0.981024   \n",
       "\n",
       "    split1_test_AUC  ...  split3_test_Sensitivity  mean_test_Sensitivity  \\\n",
       "0          0.893875  ...                 0.626834               0.522001   \n",
       "1          0.888735  ...                 0.612159               0.517809   \n",
       "2          0.890047  ...                 0.603774               0.514666   \n",
       "3          0.890363  ...                 0.612159               0.511520   \n",
       "4          0.920846  ...                 0.624738               0.537726   \n",
       "5          0.919125  ...                 0.597484               0.527771   \n",
       "6          0.913181  ...                 0.593291               0.520433   \n",
       "7          0.902096  ...                 0.587002               0.510474   \n",
       "8          0.895185  ...                 0.624738               0.528290   \n",
       "9          0.896087  ...                 0.612159               0.521479   \n",
       "10         0.896703  ...                 0.622642               0.523576   \n",
       "11         0.894272  ...                 0.616352               0.519907   \n",
       "12         0.919508  ...                 0.624738               0.533008   \n",
       "13         0.918554  ...                 0.633124               0.536677   \n",
       "14         0.909749  ...                 0.616352               0.525148   \n",
       "15         0.905370  ...                 0.614256               0.522527   \n",
       "16         0.898009  ...                 0.654088               0.539296   \n",
       "17         0.901120  ...                 0.631027               0.534579   \n",
       "18         0.888999  ...                 0.612159               0.529341   \n",
       "19         0.890811  ...                 0.605870               0.520432   \n",
       "20         0.922730  ...                 0.645702               0.534055   \n",
       "21         0.919517  ...                 0.641509               0.538248   \n",
       "22         0.916248  ...                 0.622642               0.529864   \n",
       "23         0.913524  ...                 0.631027               0.530913   \n",
       "24         0.876318  ...                 0.000000               0.000000   \n",
       "25         0.883821  ...                 0.266247               0.288263   \n",
       "26         0.906263  ...                 0.607966               0.479030   \n",
       "27         0.913476  ...                 0.637317               0.521479   \n",
       "28         0.875114  ...                 0.000000               0.000000   \n",
       "29         0.920586  ...                 0.064990               0.077044   \n",
       "30         0.928645  ...                 0.555556               0.448633   \n",
       "31         0.926110  ...                 0.643606               0.512571   \n",
       "\n",
       "    std_test_Sensitivity  rank_test_Sensitivity  split0_train_Sensitivity  \\\n",
       "0               0.080801                     16                  0.629630   \n",
       "1               0.071062                     22                  0.697414   \n",
       "2               0.063907                     23                  0.773585   \n",
       "3               0.071401                     25                  0.835779   \n",
       "4               0.063562                      3                  0.606569   \n",
       "5               0.047975                     12                  0.635919   \n",
       "6               0.048657                     19                  0.696716   \n",
       "7               0.055337                     26                  0.747030   \n",
       "8               0.072939                     11                  0.607966   \n",
       "9               0.063265                     17                  0.655486   \n",
       "10              0.065315                     14                  0.716282   \n",
       "11              0.064565                     21                  0.766597   \n",
       "12              0.071561                      7                  0.591894   \n",
       "13              0.068431                      4                  0.614256   \n",
       "14              0.065251                     13                  0.662474   \n",
       "15              0.064724                     15                  0.700210   \n",
       "16              0.080232                      1                  0.575821   \n",
       "17              0.076037                      5                  0.607966   \n",
       "18              0.060334                     10                  0.642907   \n",
       "19              0.057093                     20                  0.679245   \n",
       "20              0.079531                      6                  0.577219   \n",
       "21              0.076013                      2                  0.592593   \n",
       "22              0.065332                      9                  0.615653   \n",
       "23              0.065332                      8                  0.640112   \n",
       "24              0.000000                     31                  0.000000   \n",
       "25              0.037811                     29                  0.252271   \n",
       "26              0.076458                     27                  0.439553   \n",
       "27              0.072187                     18                  0.539483   \n",
       "28              0.000000                     31                  0.000000   \n",
       "29              0.009182                     30                  0.065688   \n",
       "30              0.066407                     28                  0.386443   \n",
       "31              0.076128                     24                  0.509434   \n",
       "\n",
       "    split1_train_Sensitivity  split2_train_Sensitivity  \\\n",
       "0                   0.711391                  0.742138   \n",
       "1                   0.780573                  0.791055   \n",
       "2                   0.835779                  0.867925   \n",
       "3                   0.891684                  0.916841   \n",
       "4                   0.685535                  0.714885   \n",
       "5                   0.723270                  0.759609   \n",
       "6                   0.776380                  0.819008   \n",
       "7                   0.822502                  0.865129   \n",
       "8                   0.686233                  0.725367   \n",
       "9                   0.730259                  0.767994   \n",
       "10                  0.796646                  0.823201   \n",
       "11                  0.832285                  0.862334   \n",
       "12                  0.676450                  0.700210   \n",
       "13                  0.700210                  0.721873   \n",
       "14                  0.747030                  0.786862   \n",
       "15                  0.777079                  0.824598   \n",
       "16                  0.662474                  0.696017   \n",
       "17                  0.691125                  0.710692   \n",
       "18                  0.723270                  0.756813   \n",
       "19                  0.756115                  0.793152   \n",
       "20                  0.654088                  0.680643   \n",
       "21                  0.676450                  0.701607   \n",
       "22                  0.697414                  0.734451   \n",
       "23                  0.719776                  0.759609   \n",
       "24                  0.000000                  0.000000   \n",
       "25                  0.333333                  0.436059   \n",
       "26                  0.547170                  0.596785   \n",
       "27                  0.629630                  0.664570   \n",
       "28                  0.000000                  0.000000   \n",
       "29                  0.069881                  0.154437   \n",
       "30                  0.484277                  0.572327   \n",
       "31                  0.609364                  0.632425   \n",
       "\n",
       "    split3_train_Sensitivity  mean_train_Sensitivity  std_train_Sensitivity  \n",
       "0                   0.735150                0.704577               0.044747  \n",
       "1                   0.785465                0.763627               0.038407  \n",
       "2                   0.862334                0.834906               0.037428  \n",
       "3                   0.907757                0.888015               0.031475  \n",
       "4                   0.689727                0.674179               0.040616  \n",
       "5                   0.732355                0.712788               0.046351  \n",
       "6                   0.801537                0.773410               0.046801  \n",
       "7                   0.850454                0.821279               0.045520  \n",
       "8                   0.701607                0.680294               0.044024  \n",
       "9                   0.741440                0.723795               0.041752  \n",
       "10                  0.809224                0.786338               0.041523  \n",
       "11                  0.854647                0.828966               0.037663  \n",
       "12                  0.682041                0.662648               0.041784  \n",
       "13                  0.704403                0.685185               0.041749  \n",
       "14                  0.759609                0.738994               0.046466  \n",
       "15                  0.803634                0.776380               0.047091  \n",
       "16                  0.668064                0.650594               0.045002  \n",
       "17                  0.693920                0.675926               0.039944  \n",
       "18                  0.734451                0.714361               0.042985  \n",
       "19                  0.768693                0.749301               0.042583  \n",
       "20                  0.657582                0.642383               0.038981  \n",
       "21                  0.679944                0.662648               0.041579  \n",
       "22                  0.707897                0.688854               0.044366  \n",
       "23                  0.733753                0.713312               0.044613  \n",
       "24                  0.000000                0.000000               0.000000  \n",
       "25                  0.387841                0.352376               0.068272  \n",
       "26                  0.623340                0.551712               0.070290  \n",
       "27                  0.663871                0.624389               0.051014  \n",
       "28                  0.000000                0.000000               0.000000  \n",
       "29                  0.101328                0.097834               0.035464  \n",
       "30                  0.583508                0.506639               0.079327  \n",
       "31                  0.645003                0.599057               0.053299  \n",
       "\n",
       "[32 rows x 47 columns]"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_gbt = gs.cv_results_\n",
    "data = pandas.DataFrame(results_gbt)\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>params</th>\n",
       "      <th>mean_test_AUC</th>\n",
       "      <th>mean_test_F_score</th>\n",
       "      <th>mean_test_Sensitivity</th>\n",
       "      <th>rank_test_AUC</th>\n",
       "      <th>rank_test_F_score</th>\n",
       "      <th>rank_test_Sensitivity</th>\n",
       "      <th>mean_train_AUC</th>\n",
       "      <th>mean_train_F_score</th>\n",
       "      <th>mean_train_Sensitivity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.018934</td>\n",
       "      <td>{'gradientboostingclassifier__learning_rate': ...</td>\n",
       "      <td>0.872946</td>\n",
       "      <td>0.544303</td>\n",
       "      <td>0.522001</td>\n",
       "      <td>25</td>\n",
       "      <td>21</td>\n",
       "      <td>16</td>\n",
       "      <td>0.957320</td>\n",
       "      <td>0.758080</td>\n",
       "      <td>0.704577</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.908934</td>\n",
       "      <td>{'gradientboostingclassifier__learning_rate': ...</td>\n",
       "      <td>0.870756</td>\n",
       "      <td>0.540353</td>\n",
       "      <td>0.517809</td>\n",
       "      <td>27</td>\n",
       "      <td>24</td>\n",
       "      <td>22</td>\n",
       "      <td>0.969131</td>\n",
       "      <td>0.815212</td>\n",
       "      <td>0.763627</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.236166</td>\n",
       "      <td>{'gradientboostingclassifier__learning_rate': ...</td>\n",
       "      <td>0.868728</td>\n",
       "      <td>0.534473</td>\n",
       "      <td>0.514666</td>\n",
       "      <td>28</td>\n",
       "      <td>26</td>\n",
       "      <td>23</td>\n",
       "      <td>0.983424</td>\n",
       "      <td>0.880818</td>\n",
       "      <td>0.834906</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6.784479</td>\n",
       "      <td>{'gradientboostingclassifier__learning_rate': ...</td>\n",
       "      <td>0.865349</td>\n",
       "      <td>0.528994</td>\n",
       "      <td>0.511520</td>\n",
       "      <td>29</td>\n",
       "      <td>28</td>\n",
       "      <td>25</td>\n",
       "      <td>0.990853</td>\n",
       "      <td>0.926336</td>\n",
       "      <td>0.888015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.942293</td>\n",
       "      <td>{'gradientboostingclassifier__learning_rate': ...</td>\n",
       "      <td>0.888167</td>\n",
       "      <td>0.564358</td>\n",
       "      <td>0.537726</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0.957226</td>\n",
       "      <td>0.726937</td>\n",
       "      <td>0.674179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1.797441</td>\n",
       "      <td>{'gradientboostingclassifier__learning_rate': ...</td>\n",
       "      <td>0.884061</td>\n",
       "      <td>0.556206</td>\n",
       "      <td>0.527771</td>\n",
       "      <td>10</td>\n",
       "      <td>11</td>\n",
       "      <td>12</td>\n",
       "      <td>0.968761</td>\n",
       "      <td>0.769530</td>\n",
       "      <td>0.712788</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>4.030110</td>\n",
       "      <td>{'gradientboostingclassifier__learning_rate': ...</td>\n",
       "      <td>0.878462</td>\n",
       "      <td>0.546526</td>\n",
       "      <td>0.520433</td>\n",
       "      <td>17</td>\n",
       "      <td>20</td>\n",
       "      <td>19</td>\n",
       "      <td>0.982480</td>\n",
       "      <td>0.827539</td>\n",
       "      <td>0.773410</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>5.160142</td>\n",
       "      <td>{'gradientboostingclassifier__learning_rate': ...</td>\n",
       "      <td>0.873521</td>\n",
       "      <td>0.537298</td>\n",
       "      <td>0.510474</td>\n",
       "      <td>24</td>\n",
       "      <td>25</td>\n",
       "      <td>26</td>\n",
       "      <td>0.990113</td>\n",
       "      <td>0.872008</td>\n",
       "      <td>0.821279</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.949221</td>\n",
       "      <td>{'gradientboostingclassifier__learning_rate': ...</td>\n",
       "      <td>0.876137</td>\n",
       "      <td>0.554978</td>\n",
       "      <td>0.528290</td>\n",
       "      <td>19</td>\n",
       "      <td>13</td>\n",
       "      <td>11</td>\n",
       "      <td>0.952377</td>\n",
       "      <td>0.734608</td>\n",
       "      <td>0.680294</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1.831514</td>\n",
       "      <td>{'gradientboostingclassifier__learning_rate': ...</td>\n",
       "      <td>0.875376</td>\n",
       "      <td>0.548371</td>\n",
       "      <td>0.521479</td>\n",
       "      <td>20</td>\n",
       "      <td>18</td>\n",
       "      <td>17</td>\n",
       "      <td>0.962328</td>\n",
       "      <td>0.778154</td>\n",
       "      <td>0.723795</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>3.472657</td>\n",
       "      <td>{'gradientboostingclassifier__learning_rate': ...</td>\n",
       "      <td>0.873858</td>\n",
       "      <td>0.549199</td>\n",
       "      <td>0.523576</td>\n",
       "      <td>23</td>\n",
       "      <td>16</td>\n",
       "      <td>14</td>\n",
       "      <td>0.975941</td>\n",
       "      <td>0.837674</td>\n",
       "      <td>0.786338</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>5.641785</td>\n",
       "      <td>{'gradientboostingclassifier__learning_rate': ...</td>\n",
       "      <td>0.871421</td>\n",
       "      <td>0.543803</td>\n",
       "      <td>0.519907</td>\n",
       "      <td>26</td>\n",
       "      <td>22</td>\n",
       "      <td>21</td>\n",
       "      <td>0.984011</td>\n",
       "      <td>0.876723</td>\n",
       "      <td>0.828966</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.964845</td>\n",
       "      <td>{'gradientboostingclassifier__learning_rate': ...</td>\n",
       "      <td>0.888308</td>\n",
       "      <td>0.560044</td>\n",
       "      <td>0.533008</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>0.952037</td>\n",
       "      <td>0.716416</td>\n",
       "      <td>0.662648</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>1.789047</td>\n",
       "      <td>{'gradientboostingclassifier__learning_rate': ...</td>\n",
       "      <td>0.888604</td>\n",
       "      <td>0.564260</td>\n",
       "      <td>0.536677</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>0.961848</td>\n",
       "      <td>0.742433</td>\n",
       "      <td>0.685185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>3.590663</td>\n",
       "      <td>{'gradientboostingclassifier__learning_rate': ...</td>\n",
       "      <td>0.882644</td>\n",
       "      <td>0.553299</td>\n",
       "      <td>0.525148</td>\n",
       "      <td>12</td>\n",
       "      <td>15</td>\n",
       "      <td>13</td>\n",
       "      <td>0.974691</td>\n",
       "      <td>0.794916</td>\n",
       "      <td>0.738994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>5.865595</td>\n",
       "      <td>{'gradientboostingclassifier__learning_rate': ...</td>\n",
       "      <td>0.878666</td>\n",
       "      <td>0.548506</td>\n",
       "      <td>0.522527</td>\n",
       "      <td>16</td>\n",
       "      <td>17</td>\n",
       "      <td>15</td>\n",
       "      <td>0.982918</td>\n",
       "      <td>0.832414</td>\n",
       "      <td>0.776380</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>1.010746</td>\n",
       "      <td>{'gradientboostingclassifier__learning_rate': ...</td>\n",
       "      <td>0.879321</td>\n",
       "      <td>0.563918</td>\n",
       "      <td>0.539296</td>\n",
       "      <td>13</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0.945533</td>\n",
       "      <td>0.706109</td>\n",
       "      <td>0.650594</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>2.466631</td>\n",
       "      <td>{'gradientboostingclassifier__learning_rate': ...</td>\n",
       "      <td>0.878823</td>\n",
       "      <td>0.558759</td>\n",
       "      <td>0.534579</td>\n",
       "      <td>14</td>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "      <td>0.952546</td>\n",
       "      <td>0.731256</td>\n",
       "      <td>0.675926</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>4.073749</td>\n",
       "      <td>{'gradientboostingclassifier__learning_rate': ...</td>\n",
       "      <td>0.874902</td>\n",
       "      <td>0.554668</td>\n",
       "      <td>0.529341</td>\n",
       "      <td>21</td>\n",
       "      <td>14</td>\n",
       "      <td>10</td>\n",
       "      <td>0.962220</td>\n",
       "      <td>0.771219</td>\n",
       "      <td>0.714361</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>6.876342</td>\n",
       "      <td>{'gradientboostingclassifier__learning_rate': ...</td>\n",
       "      <td>0.874559</td>\n",
       "      <td>0.547532</td>\n",
       "      <td>0.520432</td>\n",
       "      <td>22</td>\n",
       "      <td>19</td>\n",
       "      <td>20</td>\n",
       "      <td>0.969629</td>\n",
       "      <td>0.805357</td>\n",
       "      <td>0.749301</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>1.144039</td>\n",
       "      <td>{'gradientboostingclassifier__learning_rate': ...</td>\n",
       "      <td>0.887300</td>\n",
       "      <td>0.564191</td>\n",
       "      <td>0.534055</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>0.945660</td>\n",
       "      <td>0.700368</td>\n",
       "      <td>0.642383</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>1.836223</td>\n",
       "      <td>{'gradientboostingclassifier__learning_rate': ...</td>\n",
       "      <td>0.888507</td>\n",
       "      <td>0.564609</td>\n",
       "      <td>0.538248</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.952666</td>\n",
       "      <td>0.715934</td>\n",
       "      <td>0.662648</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>3.563814</td>\n",
       "      <td>{'gradientboostingclassifier__learning_rate': ...</td>\n",
       "      <td>0.887299</td>\n",
       "      <td>0.558405</td>\n",
       "      <td>0.529864</td>\n",
       "      <td>6</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>0.962348</td>\n",
       "      <td>0.745064</td>\n",
       "      <td>0.688854</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>5.525891</td>\n",
       "      <td>{'gradientboostingclassifier__learning_rate': ...</td>\n",
       "      <td>0.884334</td>\n",
       "      <td>0.555391</td>\n",
       "      <td>0.530913</td>\n",
       "      <td>9</td>\n",
       "      <td>12</td>\n",
       "      <td>8</td>\n",
       "      <td>0.969423</td>\n",
       "      <td>0.771530</td>\n",
       "      <td>0.713312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>1.140621</td>\n",
       "      <td>{'gradientboostingclassifier__learning_rate': ...</td>\n",
       "      <td>0.860386</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>32</td>\n",
       "      <td>31</td>\n",
       "      <td>31</td>\n",
       "      <td>0.925091</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>1.957033</td>\n",
       "      <td>{'gradientboostingclassifier__learning_rate': ...</td>\n",
       "      <td>0.865128</td>\n",
       "      <td>0.423044</td>\n",
       "      <td>0.288263</td>\n",
       "      <td>30</td>\n",
       "      <td>29</td>\n",
       "      <td>29</td>\n",
       "      <td>0.931197</td>\n",
       "      <td>0.499943</td>\n",
       "      <td>0.352376</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>3.874999</td>\n",
       "      <td>{'gradientboostingclassifier__learning_rate': ...</td>\n",
       "      <td>0.878733</td>\n",
       "      <td>0.542255</td>\n",
       "      <td>0.479030</td>\n",
       "      <td>15</td>\n",
       "      <td>23</td>\n",
       "      <td>27</td>\n",
       "      <td>0.936753</td>\n",
       "      <td>0.650173</td>\n",
       "      <td>0.551712</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>6.025265</td>\n",
       "      <td>{'gradientboostingclassifier__learning_rate': ...</td>\n",
       "      <td>0.883566</td>\n",
       "      <td>0.558328</td>\n",
       "      <td>0.521479</td>\n",
       "      <td>11</td>\n",
       "      <td>10</td>\n",
       "      <td>18</td>\n",
       "      <td>0.939973</td>\n",
       "      <td>0.691046</td>\n",
       "      <td>0.624389</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>1.214842</td>\n",
       "      <td>{'gradientboostingclassifier__learning_rate': ...</td>\n",
       "      <td>0.863905</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>31</td>\n",
       "      <td>31</td>\n",
       "      <td>31</td>\n",
       "      <td>0.928807</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>2.228589</td>\n",
       "      <td>{'gradientboostingclassifier__learning_rate': ...</td>\n",
       "      <td>0.876798</td>\n",
       "      <td>0.141746</td>\n",
       "      <td>0.077044</td>\n",
       "      <td>18</td>\n",
       "      <td>30</td>\n",
       "      <td>30</td>\n",
       "      <td>0.932455</td>\n",
       "      <td>0.175823</td>\n",
       "      <td>0.097834</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>3.855266</td>\n",
       "      <td>{'gradientboostingclassifier__learning_rate': ...</td>\n",
       "      <td>0.884999</td>\n",
       "      <td>0.533070</td>\n",
       "      <td>0.448633</td>\n",
       "      <td>8</td>\n",
       "      <td>27</td>\n",
       "      <td>28</td>\n",
       "      <td>0.937284</td>\n",
       "      <td>0.621062</td>\n",
       "      <td>0.506639</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>5.734383</td>\n",
       "      <td>{'gradientboostingclassifier__learning_rate': ...</td>\n",
       "      <td>0.886453</td>\n",
       "      <td>0.561638</td>\n",
       "      <td>0.512571</td>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "      <td>24</td>\n",
       "      <td>0.940853</td>\n",
       "      <td>0.676696</td>\n",
       "      <td>0.599057</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    mean_fit_time                                             params  \\\n",
       "0        1.018934  {'gradientboostingclassifier__learning_rate': ...   \n",
       "1        1.908934  {'gradientboostingclassifier__learning_rate': ...   \n",
       "2        4.236166  {'gradientboostingclassifier__learning_rate': ...   \n",
       "3        6.784479  {'gradientboostingclassifier__learning_rate': ...   \n",
       "4        0.942293  {'gradientboostingclassifier__learning_rate': ...   \n",
       "5        1.797441  {'gradientboostingclassifier__learning_rate': ...   \n",
       "6        4.030110  {'gradientboostingclassifier__learning_rate': ...   \n",
       "7        5.160142  {'gradientboostingclassifier__learning_rate': ...   \n",
       "8        0.949221  {'gradientboostingclassifier__learning_rate': ...   \n",
       "9        1.831514  {'gradientboostingclassifier__learning_rate': ...   \n",
       "10       3.472657  {'gradientboostingclassifier__learning_rate': ...   \n",
       "11       5.641785  {'gradientboostingclassifier__learning_rate': ...   \n",
       "12       0.964845  {'gradientboostingclassifier__learning_rate': ...   \n",
       "13       1.789047  {'gradientboostingclassifier__learning_rate': ...   \n",
       "14       3.590663  {'gradientboostingclassifier__learning_rate': ...   \n",
       "15       5.865595  {'gradientboostingclassifier__learning_rate': ...   \n",
       "16       1.010746  {'gradientboostingclassifier__learning_rate': ...   \n",
       "17       2.466631  {'gradientboostingclassifier__learning_rate': ...   \n",
       "18       4.073749  {'gradientboostingclassifier__learning_rate': ...   \n",
       "19       6.876342  {'gradientboostingclassifier__learning_rate': ...   \n",
       "20       1.144039  {'gradientboostingclassifier__learning_rate': ...   \n",
       "21       1.836223  {'gradientboostingclassifier__learning_rate': ...   \n",
       "22       3.563814  {'gradientboostingclassifier__learning_rate': ...   \n",
       "23       5.525891  {'gradientboostingclassifier__learning_rate': ...   \n",
       "24       1.140621  {'gradientboostingclassifier__learning_rate': ...   \n",
       "25       1.957033  {'gradientboostingclassifier__learning_rate': ...   \n",
       "26       3.874999  {'gradientboostingclassifier__learning_rate': ...   \n",
       "27       6.025265  {'gradientboostingclassifier__learning_rate': ...   \n",
       "28       1.214842  {'gradientboostingclassifier__learning_rate': ...   \n",
       "29       2.228589  {'gradientboostingclassifier__learning_rate': ...   \n",
       "30       3.855266  {'gradientboostingclassifier__learning_rate': ...   \n",
       "31       5.734383  {'gradientboostingclassifier__learning_rate': ...   \n",
       "\n",
       "    mean_test_AUC  mean_test_F_score  mean_test_Sensitivity  rank_test_AUC  \\\n",
       "0        0.872946           0.544303               0.522001             25   \n",
       "1        0.870756           0.540353               0.517809             27   \n",
       "2        0.868728           0.534473               0.514666             28   \n",
       "3        0.865349           0.528994               0.511520             29   \n",
       "4        0.888167           0.564358               0.537726              4   \n",
       "5        0.884061           0.556206               0.527771             10   \n",
       "6        0.878462           0.546526               0.520433             17   \n",
       "7        0.873521           0.537298               0.510474             24   \n",
       "8        0.876137           0.554978               0.528290             19   \n",
       "9        0.875376           0.548371               0.521479             20   \n",
       "10       0.873858           0.549199               0.523576             23   \n",
       "11       0.871421           0.543803               0.519907             26   \n",
       "12       0.888308           0.560044               0.533008              3   \n",
       "13       0.888604           0.564260               0.536677              1   \n",
       "14       0.882644           0.553299               0.525148             12   \n",
       "15       0.878666           0.548506               0.522527             16   \n",
       "16       0.879321           0.563918               0.539296             13   \n",
       "17       0.878823           0.558759               0.534579             14   \n",
       "18       0.874902           0.554668               0.529341             21   \n",
       "19       0.874559           0.547532               0.520432             22   \n",
       "20       0.887300           0.564191               0.534055              5   \n",
       "21       0.888507           0.564609               0.538248              2   \n",
       "22       0.887299           0.558405               0.529864              6   \n",
       "23       0.884334           0.555391               0.530913              9   \n",
       "24       0.860386           0.000000               0.000000             32   \n",
       "25       0.865128           0.423044               0.288263             30   \n",
       "26       0.878733           0.542255               0.479030             15   \n",
       "27       0.883566           0.558328               0.521479             11   \n",
       "28       0.863905           0.000000               0.000000             31   \n",
       "29       0.876798           0.141746               0.077044             18   \n",
       "30       0.884999           0.533070               0.448633              8   \n",
       "31       0.886453           0.561638               0.512571              7   \n",
       "\n",
       "    rank_test_F_score  rank_test_Sensitivity  mean_train_AUC  \\\n",
       "0                  21                     16        0.957320   \n",
       "1                  24                     22        0.969131   \n",
       "2                  26                     23        0.983424   \n",
       "3                  28                     25        0.990853   \n",
       "4                   2                      3        0.957226   \n",
       "5                  11                     12        0.968761   \n",
       "6                  20                     19        0.982480   \n",
       "7                  25                     26        0.990113   \n",
       "8                  13                     11        0.952377   \n",
       "9                  18                     17        0.962328   \n",
       "10                 16                     14        0.975941   \n",
       "11                 22                     21        0.984011   \n",
       "12                  7                      7        0.952037   \n",
       "13                  3                      4        0.961848   \n",
       "14                 15                     13        0.974691   \n",
       "15                 17                     15        0.982918   \n",
       "16                  5                      1        0.945533   \n",
       "17                  8                      5        0.952546   \n",
       "18                 14                     10        0.962220   \n",
       "19                 19                     20        0.969629   \n",
       "20                  4                      6        0.945660   \n",
       "21                  1                      2        0.952666   \n",
       "22                  9                      9        0.962348   \n",
       "23                 12                      8        0.969423   \n",
       "24                 31                     31        0.925091   \n",
       "25                 29                     29        0.931197   \n",
       "26                 23                     27        0.936753   \n",
       "27                 10                     18        0.939973   \n",
       "28                 31                     31        0.928807   \n",
       "29                 30                     30        0.932455   \n",
       "30                 27                     28        0.937284   \n",
       "31                  6                     24        0.940853   \n",
       "\n",
       "    mean_train_F_score  mean_train_Sensitivity  \n",
       "0             0.758080                0.704577  \n",
       "1             0.815212                0.763627  \n",
       "2             0.880818                0.834906  \n",
       "3             0.926336                0.888015  \n",
       "4             0.726937                0.674179  \n",
       "5             0.769530                0.712788  \n",
       "6             0.827539                0.773410  \n",
       "7             0.872008                0.821279  \n",
       "8             0.734608                0.680294  \n",
       "9             0.778154                0.723795  \n",
       "10            0.837674                0.786338  \n",
       "11            0.876723                0.828966  \n",
       "12            0.716416                0.662648  \n",
       "13            0.742433                0.685185  \n",
       "14            0.794916                0.738994  \n",
       "15            0.832414                0.776380  \n",
       "16            0.706109                0.650594  \n",
       "17            0.731256                0.675926  \n",
       "18            0.771219                0.714361  \n",
       "19            0.805357                0.749301  \n",
       "20            0.700368                0.642383  \n",
       "21            0.715934                0.662648  \n",
       "22            0.745064                0.688854  \n",
       "23            0.771530                0.713312  \n",
       "24            0.000000                0.000000  \n",
       "25            0.499943                0.352376  \n",
       "26            0.650173                0.551712  \n",
       "27            0.691046                0.624389  \n",
       "28            0.000000                0.000000  \n",
       "29            0.175823                0.097834  \n",
       "30            0.621062                0.506639  \n",
       "31            0.676696                0.599057  "
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "table_gbt = make_table(data)\n",
    "table_gbt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'gradientboostingclassifier__learning_rate': 0.1,\n",
       " 'gradientboostingclassifier__loss': 'exponential',\n",
       " 'gradientboostingclassifier__n_estimators': 100}"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 4 folds for each of 12 candidates, totalling 48 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   5 tasks      | elapsed:    0.6s\n",
      "[Parallel(n_jobs=-1)]: Done  10 tasks      | elapsed:    1.0s\n",
      "[Parallel(n_jobs=-1)]: Done  17 tasks      | elapsed:    2.1s\n",
      "[Parallel(n_jobs=-1)]: Done  24 tasks      | elapsed:    2.6s\n",
      "[Parallel(n_jobs=-1)]: Done  33 tasks      | elapsed:    3.6s\n",
      "[Parallel(n_jobs=-1)]: Done  46 out of  48 | elapsed:    4.9s remaining:    0.1s\n",
      "[Parallel(n_jobs=-1)]: Done  48 out of  48 | elapsed:    4.9s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=StratifiedKFold(n_splits=4, random_state=None, shuffle=False),\n",
       "             error_score='raise-deprecating',\n",
       "             estimator=Pipeline(memory=None,\n",
       "                                steps=[('standardscaler',\n",
       "                                        StandardScaler(copy=True,\n",
       "                                                       with_mean=True,\n",
       "                                                       with_std=True)),\n",
       "                                       ('quadraticdiscriminantanalysis',\n",
       "                                        QuadraticDiscriminantAnalysis(priors=None,\n",
       "                                                                      reg_param=0.0,\n",
       "                                                                      store_covariance=False,\n",
       "                                                                      tol=0.0001))],\n",
       "                                verbose=False),\n",
       "             iid='warn', n_jobs=-1,\n",
       "             param_grid={'quadraticdiscriminantanalysis__reg_param': [0, 0.001,\n",
       "                                                                      0.01, 0.1,\n",
       "                                                                      0.6, 1],\n",
       "                         'quadraticdiscriminantanalysis__store_covariance': (True,\n",
       "                                                                             False)},\n",
       "             pre_dispatch='2*n_jobs', refit='F-score', return_train_score=True,\n",
       "             scoring={'AUC': 'roc_auc', 'F-score': 'f1',\n",
       "                      'Sensitivity': make_scorer(recall_score)},\n",
       "             verbose=10)"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
    "\n",
    "scoring = {'AUC': 'roc_auc', 'F-score': 'f1', 'Sensitivity': make_scorer(recall_score)} \n",
    "parameters = {'quadraticdiscriminantanalysis__reg_param':([0, 0.001, 0.01, 0.1, 0.6, 1]), \n",
    "              'quadraticdiscriminantanalysis__store_covariance':(True,False)}\n",
    "\n",
    "pp = make_pipeline(StandardScaler(), QuadraticDiscriminantAnalysis()) \n",
    "\n",
    "gs = GridSearchCV(pp, parameters, cv=skf, scoring=scoring, refit='F-score', return_train_score=True, n_jobs=-1, verbose=10)\n",
    "\n",
    "gs.fit(X, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_quadraticdiscriminantanalysis__reg_param</th>\n",
       "      <th>param_quadraticdiscriminantanalysis__store_covariance</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_AUC</th>\n",
       "      <th>split1_test_AUC</th>\n",
       "      <th>split2_test_AUC</th>\n",
       "      <th>...</th>\n",
       "      <th>split3_test_Sensitivity</th>\n",
       "      <th>mean_test_Sensitivity</th>\n",
       "      <th>std_test_Sensitivity</th>\n",
       "      <th>rank_test_Sensitivity</th>\n",
       "      <th>split0_train_Sensitivity</th>\n",
       "      <th>split1_train_Sensitivity</th>\n",
       "      <th>split2_train_Sensitivity</th>\n",
       "      <th>split3_train_Sensitivity</th>\n",
       "      <th>mean_train_Sensitivity</th>\n",
       "      <th>std_train_Sensitivity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.094181</td>\n",
       "      <td>0.007692</td>\n",
       "      <td>0.082813</td>\n",
       "      <td>0.011657</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td>{'quadraticdiscriminantanalysis__reg_param': 0...</td>\n",
       "      <td>0.848531</td>\n",
       "      <td>0.828068</td>\n",
       "      <td>0.800665</td>\n",
       "      <td>...</td>\n",
       "      <td>0.742138</td>\n",
       "      <td>0.592226</td>\n",
       "      <td>0.115727</td>\n",
       "      <td>1</td>\n",
       "      <td>0.644305</td>\n",
       "      <td>0.591195</td>\n",
       "      <td>0.640112</td>\n",
       "      <td>0.651992</td>\n",
       "      <td>0.631901</td>\n",
       "      <td>0.023885</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.074236</td>\n",
       "      <td>0.006767</td>\n",
       "      <td>0.058588</td>\n",
       "      <td>0.006745</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>{'quadraticdiscriminantanalysis__reg_param': 0...</td>\n",
       "      <td>0.848531</td>\n",
       "      <td>0.828068</td>\n",
       "      <td>0.800665</td>\n",
       "      <td>...</td>\n",
       "      <td>0.742138</td>\n",
       "      <td>0.592226</td>\n",
       "      <td>0.115727</td>\n",
       "      <td>1</td>\n",
       "      <td>0.644305</td>\n",
       "      <td>0.591195</td>\n",
       "      <td>0.640112</td>\n",
       "      <td>0.651992</td>\n",
       "      <td>0.631901</td>\n",
       "      <td>0.023885</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.108742</td>\n",
       "      <td>0.015026</td>\n",
       "      <td>0.083789</td>\n",
       "      <td>0.018004</td>\n",
       "      <td>0.001</td>\n",
       "      <td>True</td>\n",
       "      <td>{'quadraticdiscriminantanalysis__reg_param': 0...</td>\n",
       "      <td>0.848548</td>\n",
       "      <td>0.829036</td>\n",
       "      <td>0.800740</td>\n",
       "      <td>...</td>\n",
       "      <td>0.740042</td>\n",
       "      <td>0.591701</td>\n",
       "      <td>0.115393</td>\n",
       "      <td>3</td>\n",
       "      <td>0.642907</td>\n",
       "      <td>0.589797</td>\n",
       "      <td>0.638714</td>\n",
       "      <td>0.650594</td>\n",
       "      <td>0.630503</td>\n",
       "      <td>0.023885</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.117974</td>\n",
       "      <td>0.017152</td>\n",
       "      <td>0.086623</td>\n",
       "      <td>0.008798</td>\n",
       "      <td>0.001</td>\n",
       "      <td>False</td>\n",
       "      <td>{'quadraticdiscriminantanalysis__reg_param': 0...</td>\n",
       "      <td>0.848548</td>\n",
       "      <td>0.829036</td>\n",
       "      <td>0.800740</td>\n",
       "      <td>...</td>\n",
       "      <td>0.740042</td>\n",
       "      <td>0.591701</td>\n",
       "      <td>0.115393</td>\n",
       "      <td>3</td>\n",
       "      <td>0.642907</td>\n",
       "      <td>0.589797</td>\n",
       "      <td>0.638714</td>\n",
       "      <td>0.650594</td>\n",
       "      <td>0.630503</td>\n",
       "      <td>0.023885</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.158316</td>\n",
       "      <td>0.009123</td>\n",
       "      <td>0.139785</td>\n",
       "      <td>0.023579</td>\n",
       "      <td>0.01</td>\n",
       "      <td>True</td>\n",
       "      <td>{'quadraticdiscriminantanalysis__reg_param': 0...</td>\n",
       "      <td>0.848644</td>\n",
       "      <td>0.834768</td>\n",
       "      <td>0.801243</td>\n",
       "      <td>...</td>\n",
       "      <td>0.708595</td>\n",
       "      <td>0.581745</td>\n",
       "      <td>0.106326</td>\n",
       "      <td>5</td>\n",
       "      <td>0.635220</td>\n",
       "      <td>0.580014</td>\n",
       "      <td>0.628931</td>\n",
       "      <td>0.638714</td>\n",
       "      <td>0.620720</td>\n",
       "      <td>0.023762</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.143254</td>\n",
       "      <td>0.022813</td>\n",
       "      <td>0.080048</td>\n",
       "      <td>0.007533</td>\n",
       "      <td>0.01</td>\n",
       "      <td>False</td>\n",
       "      <td>{'quadraticdiscriminantanalysis__reg_param': 0...</td>\n",
       "      <td>0.848644</td>\n",
       "      <td>0.834768</td>\n",
       "      <td>0.801243</td>\n",
       "      <td>...</td>\n",
       "      <td>0.708595</td>\n",
       "      <td>0.581745</td>\n",
       "      <td>0.106326</td>\n",
       "      <td>5</td>\n",
       "      <td>0.635220</td>\n",
       "      <td>0.580014</td>\n",
       "      <td>0.628931</td>\n",
       "      <td>0.638714</td>\n",
       "      <td>0.620720</td>\n",
       "      <td>0.023762</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.097351</td>\n",
       "      <td>0.015519</td>\n",
       "      <td>0.054680</td>\n",
       "      <td>0.007826</td>\n",
       "      <td>0.1</td>\n",
       "      <td>True</td>\n",
       "      <td>{'quadraticdiscriminantanalysis__reg_param': 0...</td>\n",
       "      <td>0.850243</td>\n",
       "      <td>0.846531</td>\n",
       "      <td>0.801359</td>\n",
       "      <td>...</td>\n",
       "      <td>0.645702</td>\n",
       "      <td>0.521474</td>\n",
       "      <td>0.095190</td>\n",
       "      <td>7</td>\n",
       "      <td>0.558351</td>\n",
       "      <td>0.531796</td>\n",
       "      <td>0.584906</td>\n",
       "      <td>0.580713</td>\n",
       "      <td>0.563941</td>\n",
       "      <td>0.021127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.092275</td>\n",
       "      <td>0.022673</td>\n",
       "      <td>0.064995</td>\n",
       "      <td>0.010410</td>\n",
       "      <td>0.1</td>\n",
       "      <td>False</td>\n",
       "      <td>{'quadraticdiscriminantanalysis__reg_param': 0...</td>\n",
       "      <td>0.850243</td>\n",
       "      <td>0.846531</td>\n",
       "      <td>0.801359</td>\n",
       "      <td>...</td>\n",
       "      <td>0.645702</td>\n",
       "      <td>0.521474</td>\n",
       "      <td>0.095190</td>\n",
       "      <td>7</td>\n",
       "      <td>0.558351</td>\n",
       "      <td>0.531796</td>\n",
       "      <td>0.584906</td>\n",
       "      <td>0.580713</td>\n",
       "      <td>0.563941</td>\n",
       "      <td>0.021127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.097658</td>\n",
       "      <td>0.006776</td>\n",
       "      <td>0.046885</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>0.6</td>\n",
       "      <td>True</td>\n",
       "      <td>{'quadraticdiscriminantanalysis__reg_param': 0...</td>\n",
       "      <td>0.873458</td>\n",
       "      <td>0.851085</td>\n",
       "      <td>0.805555</td>\n",
       "      <td>...</td>\n",
       "      <td>0.574423</td>\n",
       "      <td>0.438139</td>\n",
       "      <td>0.102468</td>\n",
       "      <td>9</td>\n",
       "      <td>0.433962</td>\n",
       "      <td>0.436059</td>\n",
       "      <td>0.461915</td>\n",
       "      <td>0.463312</td>\n",
       "      <td>0.448812</td>\n",
       "      <td>0.013830</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.098202</td>\n",
       "      <td>0.013419</td>\n",
       "      <td>0.067987</td>\n",
       "      <td>0.005269</td>\n",
       "      <td>0.6</td>\n",
       "      <td>False</td>\n",
       "      <td>{'quadraticdiscriminantanalysis__reg_param': 0...</td>\n",
       "      <td>0.873458</td>\n",
       "      <td>0.851085</td>\n",
       "      <td>0.805555</td>\n",
       "      <td>...</td>\n",
       "      <td>0.574423</td>\n",
       "      <td>0.438139</td>\n",
       "      <td>0.102468</td>\n",
       "      <td>9</td>\n",
       "      <td>0.433962</td>\n",
       "      <td>0.436059</td>\n",
       "      <td>0.461915</td>\n",
       "      <td>0.463312</td>\n",
       "      <td>0.448812</td>\n",
       "      <td>0.013830</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.103969</td>\n",
       "      <td>0.004126</td>\n",
       "      <td>0.077572</td>\n",
       "      <td>0.017845</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>{'quadraticdiscriminantanalysis__reg_param': 1...</td>\n",
       "      <td>0.919129</td>\n",
       "      <td>0.845140</td>\n",
       "      <td>0.815510</td>\n",
       "      <td>...</td>\n",
       "      <td>0.572327</td>\n",
       "      <td>0.397778</td>\n",
       "      <td>0.131903</td>\n",
       "      <td>11</td>\n",
       "      <td>0.381551</td>\n",
       "      <td>0.403215</td>\n",
       "      <td>0.438155</td>\n",
       "      <td>0.419986</td>\n",
       "      <td>0.410727</td>\n",
       "      <td>0.020891</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.093759</td>\n",
       "      <td>0.000021</td>\n",
       "      <td>0.070200</td>\n",
       "      <td>0.007679</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>{'quadraticdiscriminantanalysis__reg_param': 1...</td>\n",
       "      <td>0.919129</td>\n",
       "      <td>0.845140</td>\n",
       "      <td>0.815510</td>\n",
       "      <td>...</td>\n",
       "      <td>0.572327</td>\n",
       "      <td>0.397778</td>\n",
       "      <td>0.131903</td>\n",
       "      <td>11</td>\n",
       "      <td>0.381551</td>\n",
       "      <td>0.403215</td>\n",
       "      <td>0.438155</td>\n",
       "      <td>0.419986</td>\n",
       "      <td>0.410727</td>\n",
       "      <td>0.020891</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>12 rows × 46 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "0        0.094181      0.007692         0.082813        0.011657   \n",
       "1        0.074236      0.006767         0.058588        0.006745   \n",
       "2        0.108742      0.015026         0.083789        0.018004   \n",
       "3        0.117974      0.017152         0.086623        0.008798   \n",
       "4        0.158316      0.009123         0.139785        0.023579   \n",
       "5        0.143254      0.022813         0.080048        0.007533   \n",
       "6        0.097351      0.015519         0.054680        0.007826   \n",
       "7        0.092275      0.022673         0.064995        0.010410   \n",
       "8        0.097658      0.006776         0.046885        0.000008   \n",
       "9        0.098202      0.013419         0.067987        0.005269   \n",
       "10       0.103969      0.004126         0.077572        0.017845   \n",
       "11       0.093759      0.000021         0.070200        0.007679   \n",
       "\n",
       "   param_quadraticdiscriminantanalysis__reg_param  \\\n",
       "0                                               0   \n",
       "1                                               0   \n",
       "2                                           0.001   \n",
       "3                                           0.001   \n",
       "4                                            0.01   \n",
       "5                                            0.01   \n",
       "6                                             0.1   \n",
       "7                                             0.1   \n",
       "8                                             0.6   \n",
       "9                                             0.6   \n",
       "10                                              1   \n",
       "11                                              1   \n",
       "\n",
       "   param_quadraticdiscriminantanalysis__store_covariance  \\\n",
       "0                                                True      \n",
       "1                                               False      \n",
       "2                                                True      \n",
       "3                                               False      \n",
       "4                                                True      \n",
       "5                                               False      \n",
       "6                                                True      \n",
       "7                                               False      \n",
       "8                                                True      \n",
       "9                                               False      \n",
       "10                                               True      \n",
       "11                                              False      \n",
       "\n",
       "                                               params  split0_test_AUC  \\\n",
       "0   {'quadraticdiscriminantanalysis__reg_param': 0...         0.848531   \n",
       "1   {'quadraticdiscriminantanalysis__reg_param': 0...         0.848531   \n",
       "2   {'quadraticdiscriminantanalysis__reg_param': 0...         0.848548   \n",
       "3   {'quadraticdiscriminantanalysis__reg_param': 0...         0.848548   \n",
       "4   {'quadraticdiscriminantanalysis__reg_param': 0...         0.848644   \n",
       "5   {'quadraticdiscriminantanalysis__reg_param': 0...         0.848644   \n",
       "6   {'quadraticdiscriminantanalysis__reg_param': 0...         0.850243   \n",
       "7   {'quadraticdiscriminantanalysis__reg_param': 0...         0.850243   \n",
       "8   {'quadraticdiscriminantanalysis__reg_param': 0...         0.873458   \n",
       "9   {'quadraticdiscriminantanalysis__reg_param': 0...         0.873458   \n",
       "10  {'quadraticdiscriminantanalysis__reg_param': 1...         0.919129   \n",
       "11  {'quadraticdiscriminantanalysis__reg_param': 1...         0.919129   \n",
       "\n",
       "    split1_test_AUC  split2_test_AUC  ...  split3_test_Sensitivity  \\\n",
       "0          0.828068         0.800665  ...                 0.742138   \n",
       "1          0.828068         0.800665  ...                 0.742138   \n",
       "2          0.829036         0.800740  ...                 0.740042   \n",
       "3          0.829036         0.800740  ...                 0.740042   \n",
       "4          0.834768         0.801243  ...                 0.708595   \n",
       "5          0.834768         0.801243  ...                 0.708595   \n",
       "6          0.846531         0.801359  ...                 0.645702   \n",
       "7          0.846531         0.801359  ...                 0.645702   \n",
       "8          0.851085         0.805555  ...                 0.574423   \n",
       "9          0.851085         0.805555  ...                 0.574423   \n",
       "10         0.845140         0.815510  ...                 0.572327   \n",
       "11         0.845140         0.815510  ...                 0.572327   \n",
       "\n",
       "    mean_test_Sensitivity  std_test_Sensitivity  rank_test_Sensitivity  \\\n",
       "0                0.592226              0.115727                      1   \n",
       "1                0.592226              0.115727                      1   \n",
       "2                0.591701              0.115393                      3   \n",
       "3                0.591701              0.115393                      3   \n",
       "4                0.581745              0.106326                      5   \n",
       "5                0.581745              0.106326                      5   \n",
       "6                0.521474              0.095190                      7   \n",
       "7                0.521474              0.095190                      7   \n",
       "8                0.438139              0.102468                      9   \n",
       "9                0.438139              0.102468                      9   \n",
       "10               0.397778              0.131903                     11   \n",
       "11               0.397778              0.131903                     11   \n",
       "\n",
       "    split0_train_Sensitivity  split1_train_Sensitivity  \\\n",
       "0                   0.644305                  0.591195   \n",
       "1                   0.644305                  0.591195   \n",
       "2                   0.642907                  0.589797   \n",
       "3                   0.642907                  0.589797   \n",
       "4                   0.635220                  0.580014   \n",
       "5                   0.635220                  0.580014   \n",
       "6                   0.558351                  0.531796   \n",
       "7                   0.558351                  0.531796   \n",
       "8                   0.433962                  0.436059   \n",
       "9                   0.433962                  0.436059   \n",
       "10                  0.381551                  0.403215   \n",
       "11                  0.381551                  0.403215   \n",
       "\n",
       "    split2_train_Sensitivity  split3_train_Sensitivity  \\\n",
       "0                   0.640112                  0.651992   \n",
       "1                   0.640112                  0.651992   \n",
       "2                   0.638714                  0.650594   \n",
       "3                   0.638714                  0.650594   \n",
       "4                   0.628931                  0.638714   \n",
       "5                   0.628931                  0.638714   \n",
       "6                   0.584906                  0.580713   \n",
       "7                   0.584906                  0.580713   \n",
       "8                   0.461915                  0.463312   \n",
       "9                   0.461915                  0.463312   \n",
       "10                  0.438155                  0.419986   \n",
       "11                  0.438155                  0.419986   \n",
       "\n",
       "    mean_train_Sensitivity  std_train_Sensitivity  \n",
       "0                 0.631901               0.023885  \n",
       "1                 0.631901               0.023885  \n",
       "2                 0.630503               0.023885  \n",
       "3                 0.630503               0.023885  \n",
       "4                 0.620720               0.023762  \n",
       "5                 0.620720               0.023762  \n",
       "6                 0.563941               0.021127  \n",
       "7                 0.563941               0.021127  \n",
       "8                 0.448812               0.013830  \n",
       "9                 0.448812               0.013830  \n",
       "10                0.410727               0.020891  \n",
       "11                0.410727               0.020891  \n",
       "\n",
       "[12 rows x 46 columns]"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_qda= gs.cv_results_\n",
    "data = pandas.DataFrame(results_qda)\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>params</th>\n",
       "      <th>mean_test_AUC</th>\n",
       "      <th>mean_test_F_score</th>\n",
       "      <th>mean_test_Sensitivity</th>\n",
       "      <th>rank_test_AUC</th>\n",
       "      <th>rank_test_F_score</th>\n",
       "      <th>rank_test_Sensitivity</th>\n",
       "      <th>mean_train_AUC</th>\n",
       "      <th>mean_train_F_score</th>\n",
       "      <th>mean_train_Sensitivity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.094181</td>\n",
       "      <td>{'quadraticdiscriminantanalysis__reg_param': 0...</td>\n",
       "      <td>0.820525</td>\n",
       "      <td>0.504882</td>\n",
       "      <td>0.592226</td>\n",
       "      <td>11</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0.845410</td>\n",
       "      <td>0.541456</td>\n",
       "      <td>0.631901</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.074236</td>\n",
       "      <td>{'quadraticdiscriminantanalysis__reg_param': 0...</td>\n",
       "      <td>0.820525</td>\n",
       "      <td>0.504882</td>\n",
       "      <td>0.592226</td>\n",
       "      <td>11</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0.845410</td>\n",
       "      <td>0.541456</td>\n",
       "      <td>0.631901</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.108742</td>\n",
       "      <td>{'quadraticdiscriminantanalysis__reg_param': 0...</td>\n",
       "      <td>0.820785</td>\n",
       "      <td>0.505032</td>\n",
       "      <td>0.591701</td>\n",
       "      <td>9</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0.845649</td>\n",
       "      <td>0.541363</td>\n",
       "      <td>0.630503</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.117974</td>\n",
       "      <td>{'quadraticdiscriminantanalysis__reg_param': 0...</td>\n",
       "      <td>0.820785</td>\n",
       "      <td>0.505032</td>\n",
       "      <td>0.591701</td>\n",
       "      <td>9</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0.845649</td>\n",
       "      <td>0.541363</td>\n",
       "      <td>0.630503</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.158316</td>\n",
       "      <td>{'quadraticdiscriminantanalysis__reg_param': 0...</td>\n",
       "      <td>0.822152</td>\n",
       "      <td>0.505637</td>\n",
       "      <td>0.581745</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>0.846864</td>\n",
       "      <td>0.542564</td>\n",
       "      <td>0.620720</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.143254</td>\n",
       "      <td>{'quadraticdiscriminantanalysis__reg_param': 0...</td>\n",
       "      <td>0.822152</td>\n",
       "      <td>0.505637</td>\n",
       "      <td>0.581745</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>0.846864</td>\n",
       "      <td>0.542564</td>\n",
       "      <td>0.620720</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.097351</td>\n",
       "      <td>{'quadraticdiscriminantanalysis__reg_param': 0...</td>\n",
       "      <td>0.824929</td>\n",
       "      <td>0.494459</td>\n",
       "      <td>0.521474</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>0.846881</td>\n",
       "      <td>0.537770</td>\n",
       "      <td>0.563941</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.092275</td>\n",
       "      <td>{'quadraticdiscriminantanalysis__reg_param': 0...</td>\n",
       "      <td>0.824929</td>\n",
       "      <td>0.494459</td>\n",
       "      <td>0.521474</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>0.846881</td>\n",
       "      <td>0.537770</td>\n",
       "      <td>0.563941</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.097658</td>\n",
       "      <td>{'quadraticdiscriminantanalysis__reg_param': 0...</td>\n",
       "      <td>0.834557</td>\n",
       "      <td>0.463247</td>\n",
       "      <td>0.438139</td>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>0.847155</td>\n",
       "      <td>0.488946</td>\n",
       "      <td>0.448812</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.098202</td>\n",
       "      <td>{'quadraticdiscriminantanalysis__reg_param': 0...</td>\n",
       "      <td>0.834557</td>\n",
       "      <td>0.463247</td>\n",
       "      <td>0.438139</td>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>0.847155</td>\n",
       "      <td>0.488946</td>\n",
       "      <td>0.448812</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.103969</td>\n",
       "      <td>{'quadraticdiscriminantanalysis__reg_param': 1...</td>\n",
       "      <td>0.851237</td>\n",
       "      <td>0.434559</td>\n",
       "      <td>0.397778</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "      <td>11</td>\n",
       "      <td>0.855633</td>\n",
       "      <td>0.470089</td>\n",
       "      <td>0.410727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.093759</td>\n",
       "      <td>{'quadraticdiscriminantanalysis__reg_param': 1...</td>\n",
       "      <td>0.851237</td>\n",
       "      <td>0.434559</td>\n",
       "      <td>0.397778</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "      <td>11</td>\n",
       "      <td>0.855633</td>\n",
       "      <td>0.470089</td>\n",
       "      <td>0.410727</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    mean_fit_time                                             params  \\\n",
       "0        0.094181  {'quadraticdiscriminantanalysis__reg_param': 0...   \n",
       "1        0.074236  {'quadraticdiscriminantanalysis__reg_param': 0...   \n",
       "2        0.108742  {'quadraticdiscriminantanalysis__reg_param': 0...   \n",
       "3        0.117974  {'quadraticdiscriminantanalysis__reg_param': 0...   \n",
       "4        0.158316  {'quadraticdiscriminantanalysis__reg_param': 0...   \n",
       "5        0.143254  {'quadraticdiscriminantanalysis__reg_param': 0...   \n",
       "6        0.097351  {'quadraticdiscriminantanalysis__reg_param': 0...   \n",
       "7        0.092275  {'quadraticdiscriminantanalysis__reg_param': 0...   \n",
       "8        0.097658  {'quadraticdiscriminantanalysis__reg_param': 0...   \n",
       "9        0.098202  {'quadraticdiscriminantanalysis__reg_param': 0...   \n",
       "10       0.103969  {'quadraticdiscriminantanalysis__reg_param': 1...   \n",
       "11       0.093759  {'quadraticdiscriminantanalysis__reg_param': 1...   \n",
       "\n",
       "    mean_test_AUC  mean_test_F_score  mean_test_Sensitivity  rank_test_AUC  \\\n",
       "0        0.820525           0.504882               0.592226             11   \n",
       "1        0.820525           0.504882               0.592226             11   \n",
       "2        0.820785           0.505032               0.591701              9   \n",
       "3        0.820785           0.505032               0.591701              9   \n",
       "4        0.822152           0.505637               0.581745              7   \n",
       "5        0.822152           0.505637               0.581745              7   \n",
       "6        0.824929           0.494459               0.521474              5   \n",
       "7        0.824929           0.494459               0.521474              5   \n",
       "8        0.834557           0.463247               0.438139              3   \n",
       "9        0.834557           0.463247               0.438139              3   \n",
       "10       0.851237           0.434559               0.397778              1   \n",
       "11       0.851237           0.434559               0.397778              1   \n",
       "\n",
       "    rank_test_F_score  rank_test_Sensitivity  mean_train_AUC  \\\n",
       "0                   5                      1        0.845410   \n",
       "1                   5                      1        0.845410   \n",
       "2                   3                      3        0.845649   \n",
       "3                   3                      3        0.845649   \n",
       "4                   1                      5        0.846864   \n",
       "5                   1                      5        0.846864   \n",
       "6                   7                      7        0.846881   \n",
       "7                   7                      7        0.846881   \n",
       "8                   9                      9        0.847155   \n",
       "9                   9                      9        0.847155   \n",
       "10                 11                     11        0.855633   \n",
       "11                 11                     11        0.855633   \n",
       "\n",
       "    mean_train_F_score  mean_train_Sensitivity  \n",
       "0             0.541456                0.631901  \n",
       "1             0.541456                0.631901  \n",
       "2             0.541363                0.630503  \n",
       "3             0.541363                0.630503  \n",
       "4             0.542564                0.620720  \n",
       "5             0.542564                0.620720  \n",
       "6             0.537770                0.563941  \n",
       "7             0.537770                0.563941  \n",
       "8             0.488946                0.448812  \n",
       "9             0.488946                0.448812  \n",
       "10            0.470089                0.410727  \n",
       "11            0.470089                0.410727  "
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "table_qda = make_table(data)\n",
    "table_qda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'quadraticdiscriminantanalysis__reg_param': 0.01,\n",
       " 'quadraticdiscriminantanalysis__store_covariance': True}"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator, ClassifierMixin\n",
    "\n",
    "class KDEClassifier(BaseEstimator, ClassifierMixin):\n",
    "    \"\"\"Bayesian generative classification based on KDE\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    bandwidth : float\n",
    "        the kernel bandwidth within each class\n",
    "    kernel : str\n",
    "        the kernel name, passed to KernelDensity\n",
    "    algorithm : str\n",
    "        the algorithm name, passed to KernelDensity\n",
    "    \"\"\"\n",
    "    def __init__(self, bandwidth=1.0, kernel='gaussian', algorithm = 'kd_tree'):\n",
    "        self.bandwidth = bandwidth\n",
    "        self.kernel = kernel\n",
    "        self.algorithm = algorithm\n",
    "        \n",
    "    def fit(self, X, y):\n",
    "        self.classes_ = np.sort(np.unique(y))\n",
    "        training_sets = [X[y == yi] for yi in self.classes_]\n",
    "        self.models_ = [KernelDensity(bandwidth=self.bandwidth,\n",
    "                                      kernel=self.kernel, \n",
    "                                      algorithm=self.algorithm).fit(Xi)\n",
    "                        for Xi in training_sets]\n",
    "        self.logpriors_ = [np.log(Xi.shape[0] / X.shape[0])\n",
    "                           for Xi in training_sets]\n",
    "        return self\n",
    "        \n",
    "    def predict_proba(self, X):\n",
    "        logprobs = np.array([model.score_samples(X)\n",
    "                             for model in self.models_]).T\n",
    "        result = np.exp(logprobs + self.logpriors_)\n",
    "        return result / result.sum(1, keepdims=True)\n",
    "        \n",
    "    def predict(self, X):\n",
    "        return self.classes_[np.argmax(self.predict_proba(X), 1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1.        ,  1.29154967,  1.66810054,  2.15443469,  2.7825594 ,\n",
       "        3.59381366,  4.64158883,  5.9948425 ,  7.74263683, 10.        ])"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " 10 ** np.linspace(0, 1, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 4 folds for each of 10 candidates, totalling 40 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   5 tasks      | elapsed:  5.0min\n",
      "[Parallel(n_jobs=-1)]: Done  10 tasks      | elapsed:  7.2min\n",
      "[Parallel(n_jobs=-1)]: Done  17 tasks      | elapsed: 11.5min\n",
      "[Parallel(n_jobs=-1)]: Done  24 tasks      | elapsed: 13.7min\n",
      "[Parallel(n_jobs=-1)]: Done  33 tasks      | elapsed: 20.1min\n",
      "[Parallel(n_jobs=-1)]: Done  38 out of  40 | elapsed: 22.2min remaining:  1.2min\n",
      "[Parallel(n_jobs=-1)]: Done  40 out of  40 | elapsed: 22.2min finished\n"
     ]
    }
   ],
   "source": [
    "bandwidths = 10 ** np.linspace(0, 1, 10)\n",
    "scoring = {'AUC': 'roc_auc', 'F-score': 'f1', 'Sensitivity': make_scorer(recall_score)}\n",
    "parameters = {'kdeclassifier__bandwidth': bandwidths}\n",
    "\n",
    "pp = make_pipeline(StandardScaler(), KDEClassifier()) \n",
    "\n",
    "gs = GridSearchCV(pp, parameters, cv=skf, scoring=scoring, refit='F-score', return_train_score=True, n_jobs=-1, verbose=10) \n",
    "gs.fit(X, Y)\n",
    "results = gs.cv_results_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_kdeclassifier__bandwidth</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_AUC</th>\n",
       "      <th>split1_test_AUC</th>\n",
       "      <th>split2_test_AUC</th>\n",
       "      <th>split3_test_AUC</th>\n",
       "      <th>...</th>\n",
       "      <th>split3_test_Sensitivity</th>\n",
       "      <th>mean_test_Sensitivity</th>\n",
       "      <th>std_test_Sensitivity</th>\n",
       "      <th>rank_test_Sensitivity</th>\n",
       "      <th>split0_train_Sensitivity</th>\n",
       "      <th>split1_train_Sensitivity</th>\n",
       "      <th>split2_train_Sensitivity</th>\n",
       "      <th>split3_train_Sensitivity</th>\n",
       "      <th>mean_train_Sensitivity</th>\n",
       "      <th>std_train_Sensitivity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.123743</td>\n",
       "      <td>0.008164</td>\n",
       "      <td>31.727459</td>\n",
       "      <td>0.226179</td>\n",
       "      <td>1</td>\n",
       "      <td>{'kdeclassifier__bandwidth': 1.0}</td>\n",
       "      <td>0.894678</td>\n",
       "      <td>0.830510</td>\n",
       "      <td>0.790376</td>\n",
       "      <td>0.774951</td>\n",
       "      <td>...</td>\n",
       "      <td>0.274633</td>\n",
       "      <td>0.223790</td>\n",
       "      <td>0.031737</td>\n",
       "      <td>1</td>\n",
       "      <td>0.366876</td>\n",
       "      <td>0.407407</td>\n",
       "      <td>0.440252</td>\n",
       "      <td>0.441649</td>\n",
       "      <td>0.414046</td>\n",
       "      <td>0.030487</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.123992</td>\n",
       "      <td>0.004529</td>\n",
       "      <td>34.466054</td>\n",
       "      <td>0.213743</td>\n",
       "      <td>1.29155</td>\n",
       "      <td>{'kdeclassifier__bandwidth': 1.2915496650148839}</td>\n",
       "      <td>0.891654</td>\n",
       "      <td>0.831096</td>\n",
       "      <td>0.801189</td>\n",
       "      <td>0.795670</td>\n",
       "      <td>...</td>\n",
       "      <td>0.174004</td>\n",
       "      <td>0.145176</td>\n",
       "      <td>0.017563</td>\n",
       "      <td>2</td>\n",
       "      <td>0.212439</td>\n",
       "      <td>0.220126</td>\n",
       "      <td>0.259958</td>\n",
       "      <td>0.248777</td>\n",
       "      <td>0.235325</td>\n",
       "      <td>0.019638</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.131473</td>\n",
       "      <td>0.017763</td>\n",
       "      <td>37.283573</td>\n",
       "      <td>0.258985</td>\n",
       "      <td>1.6681</td>\n",
       "      <td>{'kdeclassifier__bandwidth': 1.6681005372000588}</td>\n",
       "      <td>0.893810</td>\n",
       "      <td>0.833773</td>\n",
       "      <td>0.801525</td>\n",
       "      <td>0.805612</td>\n",
       "      <td>...</td>\n",
       "      <td>0.092243</td>\n",
       "      <td>0.075995</td>\n",
       "      <td>0.009419</td>\n",
       "      <td>3</td>\n",
       "      <td>0.103424</td>\n",
       "      <td>0.109713</td>\n",
       "      <td>0.132075</td>\n",
       "      <td>0.124389</td>\n",
       "      <td>0.117400</td>\n",
       "      <td>0.011387</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.114167</td>\n",
       "      <td>0.012134</td>\n",
       "      <td>32.555808</td>\n",
       "      <td>0.126987</td>\n",
       "      <td>2.15443</td>\n",
       "      <td>{'kdeclassifier__bandwidth': 2.154434690031884}</td>\n",
       "      <td>0.901172</td>\n",
       "      <td>0.840102</td>\n",
       "      <td>0.805615</td>\n",
       "      <td>0.811767</td>\n",
       "      <td>...</td>\n",
       "      <td>0.046122</td>\n",
       "      <td>0.034590</td>\n",
       "      <td>0.008956</td>\n",
       "      <td>4</td>\n",
       "      <td>0.040531</td>\n",
       "      <td>0.042628</td>\n",
       "      <td>0.053809</td>\n",
       "      <td>0.049616</td>\n",
       "      <td>0.046646</td>\n",
       "      <td>0.005331</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.126461</td>\n",
       "      <td>0.019461</td>\n",
       "      <td>31.802794</td>\n",
       "      <td>0.207150</td>\n",
       "      <td>2.78256</td>\n",
       "      <td>{'kdeclassifier__bandwidth': 2.7825594022071245}</td>\n",
       "      <td>0.907466</td>\n",
       "      <td>0.847083</td>\n",
       "      <td>0.810753</td>\n",
       "      <td>0.818250</td>\n",
       "      <td>...</td>\n",
       "      <td>0.020964</td>\n",
       "      <td>0.016247</td>\n",
       "      <td>0.004775</td>\n",
       "      <td>5</td>\n",
       "      <td>0.020266</td>\n",
       "      <td>0.020964</td>\n",
       "      <td>0.024458</td>\n",
       "      <td>0.017470</td>\n",
       "      <td>0.020790</td>\n",
       "      <td>0.002489</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.125399</td>\n",
       "      <td>0.010837</td>\n",
       "      <td>32.305125</td>\n",
       "      <td>0.182488</td>\n",
       "      <td>3.59381</td>\n",
       "      <td>{'kdeclassifier__bandwidth': 3.5938136638046276}</td>\n",
       "      <td>0.912042</td>\n",
       "      <td>0.849152</td>\n",
       "      <td>0.813108</td>\n",
       "      <td>0.821159</td>\n",
       "      <td>...</td>\n",
       "      <td>0.008386</td>\n",
       "      <td>0.007337</td>\n",
       "      <td>0.003779</td>\n",
       "      <td>6</td>\n",
       "      <td>0.006289</td>\n",
       "      <td>0.007687</td>\n",
       "      <td>0.008386</td>\n",
       "      <td>0.007687</td>\n",
       "      <td>0.007512</td>\n",
       "      <td>0.000762</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.121087</td>\n",
       "      <td>0.012961</td>\n",
       "      <td>31.558014</td>\n",
       "      <td>0.112034</td>\n",
       "      <td>4.64159</td>\n",
       "      <td>{'kdeclassifier__bandwidth': 4.641588833612778}</td>\n",
       "      <td>0.914257</td>\n",
       "      <td>0.848604</td>\n",
       "      <td>0.813908</td>\n",
       "      <td>0.821646</td>\n",
       "      <td>...</td>\n",
       "      <td>0.002096</td>\n",
       "      <td>0.002096</td>\n",
       "      <td>0.002568</td>\n",
       "      <td>7</td>\n",
       "      <td>0.001398</td>\n",
       "      <td>0.001398</td>\n",
       "      <td>0.000699</td>\n",
       "      <td>0.001398</td>\n",
       "      <td>0.001223</td>\n",
       "      <td>0.000303</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.117178</td>\n",
       "      <td>0.013531</td>\n",
       "      <td>31.163359</td>\n",
       "      <td>0.218295</td>\n",
       "      <td>5.99484</td>\n",
       "      <td>{'kdeclassifier__bandwidth': 5.994842503189409}</td>\n",
       "      <td>0.915414</td>\n",
       "      <td>0.847477</td>\n",
       "      <td>0.814584</td>\n",
       "      <td>0.822821</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>8</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.109367</td>\n",
       "      <td>0.000006</td>\n",
       "      <td>31.348517</td>\n",
       "      <td>0.172236</td>\n",
       "      <td>7.74264</td>\n",
       "      <td>{'kdeclassifier__bandwidth': 7.742636826811269}</td>\n",
       "      <td>0.916126</td>\n",
       "      <td>0.846189</td>\n",
       "      <td>0.814964</td>\n",
       "      <td>0.823610</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>8</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.115231</td>\n",
       "      <td>0.004605</td>\n",
       "      <td>31.293514</td>\n",
       "      <td>0.130393</td>\n",
       "      <td>10</td>\n",
       "      <td>{'kdeclassifier__bandwidth': 10.0}</td>\n",
       "      <td>0.916743</td>\n",
       "      <td>0.845432</td>\n",
       "      <td>0.815206</td>\n",
       "      <td>0.824008</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>8</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 45 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "0       0.123743      0.008164        31.727459        0.226179   \n",
       "1       0.123992      0.004529        34.466054        0.213743   \n",
       "2       0.131473      0.017763        37.283573        0.258985   \n",
       "3       0.114167      0.012134        32.555808        0.126987   \n",
       "4       0.126461      0.019461        31.802794        0.207150   \n",
       "5       0.125399      0.010837        32.305125        0.182488   \n",
       "6       0.121087      0.012961        31.558014        0.112034   \n",
       "7       0.117178      0.013531        31.163359        0.218295   \n",
       "8       0.109367      0.000006        31.348517        0.172236   \n",
       "9       0.115231      0.004605        31.293514        0.130393   \n",
       "\n",
       "  param_kdeclassifier__bandwidth  \\\n",
       "0                              1   \n",
       "1                        1.29155   \n",
       "2                         1.6681   \n",
       "3                        2.15443   \n",
       "4                        2.78256   \n",
       "5                        3.59381   \n",
       "6                        4.64159   \n",
       "7                        5.99484   \n",
       "8                        7.74264   \n",
       "9                             10   \n",
       "\n",
       "                                             params  split0_test_AUC  \\\n",
       "0                 {'kdeclassifier__bandwidth': 1.0}         0.894678   \n",
       "1  {'kdeclassifier__bandwidth': 1.2915496650148839}         0.891654   \n",
       "2  {'kdeclassifier__bandwidth': 1.6681005372000588}         0.893810   \n",
       "3   {'kdeclassifier__bandwidth': 2.154434690031884}         0.901172   \n",
       "4  {'kdeclassifier__bandwidth': 2.7825594022071245}         0.907466   \n",
       "5  {'kdeclassifier__bandwidth': 3.5938136638046276}         0.912042   \n",
       "6   {'kdeclassifier__bandwidth': 4.641588833612778}         0.914257   \n",
       "7   {'kdeclassifier__bandwidth': 5.994842503189409}         0.915414   \n",
       "8   {'kdeclassifier__bandwidth': 7.742636826811269}         0.916126   \n",
       "9                {'kdeclassifier__bandwidth': 10.0}         0.916743   \n",
       "\n",
       "   split1_test_AUC  split2_test_AUC  split3_test_AUC  ...  \\\n",
       "0         0.830510         0.790376         0.774951  ...   \n",
       "1         0.831096         0.801189         0.795670  ...   \n",
       "2         0.833773         0.801525         0.805612  ...   \n",
       "3         0.840102         0.805615         0.811767  ...   \n",
       "4         0.847083         0.810753         0.818250  ...   \n",
       "5         0.849152         0.813108         0.821159  ...   \n",
       "6         0.848604         0.813908         0.821646  ...   \n",
       "7         0.847477         0.814584         0.822821  ...   \n",
       "8         0.846189         0.814964         0.823610  ...   \n",
       "9         0.845432         0.815206         0.824008  ...   \n",
       "\n",
       "   split3_test_Sensitivity  mean_test_Sensitivity  std_test_Sensitivity  \\\n",
       "0                 0.274633               0.223790              0.031737   \n",
       "1                 0.174004               0.145176              0.017563   \n",
       "2                 0.092243               0.075995              0.009419   \n",
       "3                 0.046122               0.034590              0.008956   \n",
       "4                 0.020964               0.016247              0.004775   \n",
       "5                 0.008386               0.007337              0.003779   \n",
       "6                 0.002096               0.002096              0.002568   \n",
       "7                 0.000000               0.000000              0.000000   \n",
       "8                 0.000000               0.000000              0.000000   \n",
       "9                 0.000000               0.000000              0.000000   \n",
       "\n",
       "   rank_test_Sensitivity  split0_train_Sensitivity  split1_train_Sensitivity  \\\n",
       "0                      1                  0.366876                  0.407407   \n",
       "1                      2                  0.212439                  0.220126   \n",
       "2                      3                  0.103424                  0.109713   \n",
       "3                      4                  0.040531                  0.042628   \n",
       "4                      5                  0.020266                  0.020964   \n",
       "5                      6                  0.006289                  0.007687   \n",
       "6                      7                  0.001398                  0.001398   \n",
       "7                      8                  0.000000                  0.000000   \n",
       "8                      8                  0.000000                  0.000000   \n",
       "9                      8                  0.000000                  0.000000   \n",
       "\n",
       "   split2_train_Sensitivity  split3_train_Sensitivity  mean_train_Sensitivity  \\\n",
       "0                  0.440252                  0.441649                0.414046   \n",
       "1                  0.259958                  0.248777                0.235325   \n",
       "2                  0.132075                  0.124389                0.117400   \n",
       "3                  0.053809                  0.049616                0.046646   \n",
       "4                  0.024458                  0.017470                0.020790   \n",
       "5                  0.008386                  0.007687                0.007512   \n",
       "6                  0.000699                  0.001398                0.001223   \n",
       "7                  0.000000                  0.000000                0.000000   \n",
       "8                  0.000000                  0.000000                0.000000   \n",
       "9                  0.000000                  0.000000                0.000000   \n",
       "\n",
       "   std_train_Sensitivity  \n",
       "0               0.030487  \n",
       "1               0.019638  \n",
       "2               0.011387  \n",
       "3               0.005331  \n",
       "4               0.002489  \n",
       "5               0.000762  \n",
       "6               0.000303  \n",
       "7               0.000000  \n",
       "8               0.000000  \n",
       "9               0.000000  \n",
       "\n",
       "[10 rows x 45 columns]"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_kd= gs.cv_results_\n",
    "data = pandas.DataFrame(results_kd)\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>params</th>\n",
       "      <th>mean_test_AUC</th>\n",
       "      <th>mean_test_F_score</th>\n",
       "      <th>mean_test_Sensitivity</th>\n",
       "      <th>rank_test_AUC</th>\n",
       "      <th>rank_test_F_score</th>\n",
       "      <th>rank_test_Sensitivity</th>\n",
       "      <th>mean_train_AUC</th>\n",
       "      <th>mean_train_F_score</th>\n",
       "      <th>mean_train_Sensitivity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.123743</td>\n",
       "      <td>{'kdeclassifier__bandwidth': 1.0}</td>\n",
       "      <td>0.822635</td>\n",
       "      <td>0.333549</td>\n",
       "      <td>0.223790</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.943239</td>\n",
       "      <td>0.578753</td>\n",
       "      <td>0.414046</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.123992</td>\n",
       "      <td>{'kdeclassifier__bandwidth': 1.2915496650148839}</td>\n",
       "      <td>0.829907</td>\n",
       "      <td>0.240523</td>\n",
       "      <td>0.145176</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0.906338</td>\n",
       "      <td>0.376716</td>\n",
       "      <td>0.235325</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.131473</td>\n",
       "      <td>{'kdeclassifier__bandwidth': 1.6681005372000588}</td>\n",
       "      <td>0.833685</td>\n",
       "      <td>0.138044</td>\n",
       "      <td>0.075995</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0.878227</td>\n",
       "      <td>0.209060</td>\n",
       "      <td>0.117400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.114167</td>\n",
       "      <td>{'kdeclassifier__bandwidth': 2.154434690031884}</td>\n",
       "      <td>0.839669</td>\n",
       "      <td>0.065942</td>\n",
       "      <td>0.034590</td>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>0.864297</td>\n",
       "      <td>0.088813</td>\n",
       "      <td>0.046646</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.126461</td>\n",
       "      <td>{'kdeclassifier__bandwidth': 2.7825594022071245}</td>\n",
       "      <td>0.845893</td>\n",
       "      <td>0.031702</td>\n",
       "      <td>0.016247</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>0.859112</td>\n",
       "      <td>0.040661</td>\n",
       "      <td>0.020790</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.125399</td>\n",
       "      <td>{'kdeclassifier__bandwidth': 3.5938136638046276}</td>\n",
       "      <td>0.848870</td>\n",
       "      <td>0.014461</td>\n",
       "      <td>0.007337</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>0.856430</td>\n",
       "      <td>0.014896</td>\n",
       "      <td>0.007512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.121087</td>\n",
       "      <td>{'kdeclassifier__bandwidth': 4.641588833612778}</td>\n",
       "      <td>0.849609</td>\n",
       "      <td>0.004157</td>\n",
       "      <td>0.002096</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>0.855848</td>\n",
       "      <td>0.002443</td>\n",
       "      <td>0.001223</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.117178</td>\n",
       "      <td>{'kdeclassifier__bandwidth': 5.994842503189409}</td>\n",
       "      <td>0.850079</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>0.855598</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.109367</td>\n",
       "      <td>{'kdeclassifier__bandwidth': 7.742636826811269}</td>\n",
       "      <td>0.850227</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>0.855355</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.115231</td>\n",
       "      <td>{'kdeclassifier__bandwidth': 10.0}</td>\n",
       "      <td>0.850353</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>0.855183</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean_fit_time                                            params  \\\n",
       "0       0.123743                 {'kdeclassifier__bandwidth': 1.0}   \n",
       "1       0.123992  {'kdeclassifier__bandwidth': 1.2915496650148839}   \n",
       "2       0.131473  {'kdeclassifier__bandwidth': 1.6681005372000588}   \n",
       "3       0.114167   {'kdeclassifier__bandwidth': 2.154434690031884}   \n",
       "4       0.126461  {'kdeclassifier__bandwidth': 2.7825594022071245}   \n",
       "5       0.125399  {'kdeclassifier__bandwidth': 3.5938136638046276}   \n",
       "6       0.121087   {'kdeclassifier__bandwidth': 4.641588833612778}   \n",
       "7       0.117178   {'kdeclassifier__bandwidth': 5.994842503189409}   \n",
       "8       0.109367   {'kdeclassifier__bandwidth': 7.742636826811269}   \n",
       "9       0.115231                {'kdeclassifier__bandwidth': 10.0}   \n",
       "\n",
       "   mean_test_AUC  mean_test_F_score  mean_test_Sensitivity  rank_test_AUC  \\\n",
       "0       0.822635           0.333549               0.223790             10   \n",
       "1       0.829907           0.240523               0.145176              9   \n",
       "2       0.833685           0.138044               0.075995              8   \n",
       "3       0.839669           0.065942               0.034590              7   \n",
       "4       0.845893           0.031702               0.016247              6   \n",
       "5       0.848870           0.014461               0.007337              5   \n",
       "6       0.849609           0.004157               0.002096              4   \n",
       "7       0.850079           0.000000               0.000000              3   \n",
       "8       0.850227           0.000000               0.000000              2   \n",
       "9       0.850353           0.000000               0.000000              1   \n",
       "\n",
       "   rank_test_F_score  rank_test_Sensitivity  mean_train_AUC  \\\n",
       "0                  1                      1        0.943239   \n",
       "1                  2                      2        0.906338   \n",
       "2                  3                      3        0.878227   \n",
       "3                  4                      4        0.864297   \n",
       "4                  5                      5        0.859112   \n",
       "5                  6                      6        0.856430   \n",
       "6                  7                      7        0.855848   \n",
       "7                  8                      8        0.855598   \n",
       "8                  8                      8        0.855355   \n",
       "9                  8                      8        0.855183   \n",
       "\n",
       "   mean_train_F_score  mean_train_Sensitivity  \n",
       "0            0.578753                0.414046  \n",
       "1            0.376716                0.235325  \n",
       "2            0.209060                0.117400  \n",
       "3            0.088813                0.046646  \n",
       "4            0.040661                0.020790  \n",
       "5            0.014896                0.007512  \n",
       "6            0.002443                0.001223  \n",
       "7            0.000000                0.000000  \n",
       "8            0.000000                0.000000  \n",
       "9            0.000000                0.000000  "
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "table_kd = make_table(data)\n",
    "table_kd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'kdeclassifier__bandwidth': 1.0}"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 4 folds for each of 432 candidates, totalling 1728 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   5 tasks      | elapsed:    7.7s\n",
      "[Parallel(n_jobs=-1)]: Done  10 tasks      | elapsed:   12.7s\n",
      "[Parallel(n_jobs=-1)]: Done  17 tasks      | elapsed:   21.3s\n",
      "[Parallel(n_jobs=-1)]: Done  24 tasks      | elapsed:   29.4s\n",
      "[Parallel(n_jobs=-1)]: Done  33 tasks      | elapsed:   59.8s\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "scoring = {'AUC': 'roc_auc', 'F-score': 'f1', 'Sensitivity': make_scorer(recall_score)} \n",
    "parameters = {\n",
    "    'mlpclassifier__hidden_layer_sizes': ((70, 20), (70, 30), (70, 40)),\n",
    "    'mlpclassifier__max_iter': (250, 500, 700),\n",
    "    'mlpclassifier__activation': ('identity', 'logistic', 'tanh', 'relu'),\n",
    "    'mlpclassifier__solver': ('sgd', 'adam'),\n",
    "    'mlpclassifier__alpha': (0.001, 0.01, 0.1),\n",
    "    'mlpclassifier__learning_rate': ('constant','adaptive'), \n",
    "    'mlpclassifier__random_state':[0]\n",
    "}\n",
    "\n",
    "pp = make_pipeline(StandardScaler(), MLPClassifier())\n",
    "\n",
    "gs = GridSearchCV(pp, parameters, cv=skf, scoring=scoring, refit='AUC', return_train_score=True, n_jobs=-1, verbose=10) \n",
    "gs.fit(X, Y)\n",
    "results = gs.cv_results_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_mlp = gs.cv_results_\n",
    "data = pandas.DataFrame(results_mlp)\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "table_mlp = make_table(data)\n",
    "table_mlp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gs.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 4 folds for each of 20 candidates, totalling 80 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   5 tasks      | elapsed:    0.3s\n",
      "[Parallel(n_jobs=-1)]: Done  10 tasks      | elapsed:    0.5s\n",
      "[Parallel(n_jobs=-1)]: Done  17 tasks      | elapsed:    0.9s\n",
      "[Parallel(n_jobs=-1)]: Done  24 tasks      | elapsed:    1.1s\n",
      "[Parallel(n_jobs=-1)]: Done  33 tasks      | elapsed:    1.7s\n",
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:    2.3s\n",
      "[Parallel(n_jobs=-1)]: Done  53 tasks      | elapsed:    2.9s\n",
      "[Parallel(n_jobs=-1)]: Done  64 tasks      | elapsed:    3.5s\n",
      "[Parallel(n_jobs=-1)]: Done  80 out of  80 | elapsed:    4.3s finished\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import ComplementNB\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "scoring = {'AUC': 'roc_auc', 'F-score': 'f1', 'Sensitivity': make_scorer(recall_score)} \n",
    "parameters = {\n",
    "    'complementnb__alpha': [0, 0.4, 0.5, 0.6, 1],\n",
    "    'complementnb__fit_prior': (True, False),\n",
    "    'complementnb__norm': (True, False)\n",
    "}\n",
    "\n",
    "pp = make_pipeline(MinMaxScaler(), ComplementNB())\n",
    "\n",
    "gs = GridSearchCV(pp, parameters, cv=skf, scoring=scoring, refit='F-score', return_train_score=True, n_jobs=-1, verbose=10) \n",
    "gs.fit(X, Y)\n",
    "results = gs.cv_results_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_complementnb__alpha</th>\n",
       "      <th>param_complementnb__fit_prior</th>\n",
       "      <th>param_complementnb__norm</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_AUC</th>\n",
       "      <th>split1_test_AUC</th>\n",
       "      <th>...</th>\n",
       "      <th>split3_test_Sensitivity</th>\n",
       "      <th>mean_test_Sensitivity</th>\n",
       "      <th>std_test_Sensitivity</th>\n",
       "      <th>rank_test_Sensitivity</th>\n",
       "      <th>split0_train_Sensitivity</th>\n",
       "      <th>split1_train_Sensitivity</th>\n",
       "      <th>split2_train_Sensitivity</th>\n",
       "      <th>split3_train_Sensitivity</th>\n",
       "      <th>mean_train_Sensitivity</th>\n",
       "      <th>std_train_Sensitivity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.034258</td>\n",
       "      <td>0.001295</td>\n",
       "      <td>0.047244</td>\n",
       "      <td>0.006984</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>{'complementnb__alpha': 0, 'complementnb__fit_...</td>\n",
       "      <td>0.813963</td>\n",
       "      <td>0.803381</td>\n",
       "      <td>...</td>\n",
       "      <td>0.853249</td>\n",
       "      <td>0.642534</td>\n",
       "      <td>0.179328</td>\n",
       "      <td>11</td>\n",
       "      <td>0.836478</td>\n",
       "      <td>0.450734</td>\n",
       "      <td>0.673655</td>\n",
       "      <td>0.718379</td>\n",
       "      <td>0.669811</td>\n",
       "      <td>0.139773</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.036255</td>\n",
       "      <td>0.011507</td>\n",
       "      <td>0.034548</td>\n",
       "      <td>0.003359</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>{'complementnb__alpha': 0, 'complementnb__fit_...</td>\n",
       "      <td>0.816455</td>\n",
       "      <td>0.819132</td>\n",
       "      <td>...</td>\n",
       "      <td>0.955975</td>\n",
       "      <td>0.835413</td>\n",
       "      <td>0.107610</td>\n",
       "      <td>1</td>\n",
       "      <td>0.870720</td>\n",
       "      <td>0.839273</td>\n",
       "      <td>0.877009</td>\n",
       "      <td>0.864430</td>\n",
       "      <td>0.862858</td>\n",
       "      <td>0.014325</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.035156</td>\n",
       "      <td>0.006772</td>\n",
       "      <td>0.039065</td>\n",
       "      <td>0.013554</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>{'complementnb__alpha': 0, 'complementnb__fit_...</td>\n",
       "      <td>0.813963</td>\n",
       "      <td>0.803381</td>\n",
       "      <td>...</td>\n",
       "      <td>0.853249</td>\n",
       "      <td>0.642534</td>\n",
       "      <td>0.179328</td>\n",
       "      <td>11</td>\n",
       "      <td>0.836478</td>\n",
       "      <td>0.450734</td>\n",
       "      <td>0.673655</td>\n",
       "      <td>0.718379</td>\n",
       "      <td>0.669811</td>\n",
       "      <td>0.139773</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.054212</td>\n",
       "      <td>0.013631</td>\n",
       "      <td>0.026475</td>\n",
       "      <td>0.005136</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>{'complementnb__alpha': 0, 'complementnb__fit_...</td>\n",
       "      <td>0.816455</td>\n",
       "      <td>0.819132</td>\n",
       "      <td>...</td>\n",
       "      <td>0.955975</td>\n",
       "      <td>0.835413</td>\n",
       "      <td>0.107610</td>\n",
       "      <td>1</td>\n",
       "      <td>0.870720</td>\n",
       "      <td>0.839273</td>\n",
       "      <td>0.877009</td>\n",
       "      <td>0.864430</td>\n",
       "      <td>0.862858</td>\n",
       "      <td>0.014325</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.035156</td>\n",
       "      <td>0.006764</td>\n",
       "      <td>0.039064</td>\n",
       "      <td>0.007809</td>\n",
       "      <td>0.4</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>{'complementnb__alpha': 0.4, 'complementnb__fi...</td>\n",
       "      <td>0.813820</td>\n",
       "      <td>0.802612</td>\n",
       "      <td>...</td>\n",
       "      <td>0.851153</td>\n",
       "      <td>0.639914</td>\n",
       "      <td>0.180396</td>\n",
       "      <td>13</td>\n",
       "      <td>0.828092</td>\n",
       "      <td>0.447240</td>\n",
       "      <td>0.671558</td>\n",
       "      <td>0.715584</td>\n",
       "      <td>0.665618</td>\n",
       "      <td>0.138401</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.046873</td>\n",
       "      <td>0.011056</td>\n",
       "      <td>0.039053</td>\n",
       "      <td>0.007804</td>\n",
       "      <td>0.4</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>{'complementnb__alpha': 0.4, 'complementnb__fi...</td>\n",
       "      <td>0.816521</td>\n",
       "      <td>0.818484</td>\n",
       "      <td>...</td>\n",
       "      <td>0.955975</td>\n",
       "      <td>0.835413</td>\n",
       "      <td>0.107610</td>\n",
       "      <td>1</td>\n",
       "      <td>0.870720</td>\n",
       "      <td>0.839972</td>\n",
       "      <td>0.875611</td>\n",
       "      <td>0.864430</td>\n",
       "      <td>0.862683</td>\n",
       "      <td>0.013698</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.060763</td>\n",
       "      <td>0.018033</td>\n",
       "      <td>0.045240</td>\n",
       "      <td>0.007587</td>\n",
       "      <td>0.4</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>{'complementnb__alpha': 0.4, 'complementnb__fi...</td>\n",
       "      <td>0.813820</td>\n",
       "      <td>0.802612</td>\n",
       "      <td>...</td>\n",
       "      <td>0.851153</td>\n",
       "      <td>0.639914</td>\n",
       "      <td>0.180396</td>\n",
       "      <td>13</td>\n",
       "      <td>0.828092</td>\n",
       "      <td>0.447240</td>\n",
       "      <td>0.671558</td>\n",
       "      <td>0.715584</td>\n",
       "      <td>0.665618</td>\n",
       "      <td>0.138401</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.056997</td>\n",
       "      <td>0.017936</td>\n",
       "      <td>0.061253</td>\n",
       "      <td>0.008869</td>\n",
       "      <td>0.4</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>{'complementnb__alpha': 0.4, 'complementnb__fi...</td>\n",
       "      <td>0.816521</td>\n",
       "      <td>0.818484</td>\n",
       "      <td>...</td>\n",
       "      <td>0.955975</td>\n",
       "      <td>0.835413</td>\n",
       "      <td>0.107610</td>\n",
       "      <td>1</td>\n",
       "      <td>0.870720</td>\n",
       "      <td>0.839972</td>\n",
       "      <td>0.875611</td>\n",
       "      <td>0.864430</td>\n",
       "      <td>0.862683</td>\n",
       "      <td>0.013698</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.054504</td>\n",
       "      <td>0.012627</td>\n",
       "      <td>0.048248</td>\n",
       "      <td>0.004258</td>\n",
       "      <td>0.5</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>{'complementnb__alpha': 0.5, 'complementnb__fi...</td>\n",
       "      <td>0.813757</td>\n",
       "      <td>0.802388</td>\n",
       "      <td>...</td>\n",
       "      <td>0.851153</td>\n",
       "      <td>0.639914</td>\n",
       "      <td>0.180396</td>\n",
       "      <td>13</td>\n",
       "      <td>0.826695</td>\n",
       "      <td>0.444444</td>\n",
       "      <td>0.671558</td>\n",
       "      <td>0.714885</td>\n",
       "      <td>0.664396</td>\n",
       "      <td>0.139032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.063504</td>\n",
       "      <td>0.017629</td>\n",
       "      <td>0.044748</td>\n",
       "      <td>0.002487</td>\n",
       "      <td>0.5</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>{'complementnb__alpha': 0.5, 'complementnb__fi...</td>\n",
       "      <td>0.816530</td>\n",
       "      <td>0.818332</td>\n",
       "      <td>...</td>\n",
       "      <td>0.955975</td>\n",
       "      <td>0.835413</td>\n",
       "      <td>0.107610</td>\n",
       "      <td>1</td>\n",
       "      <td>0.870720</td>\n",
       "      <td>0.839972</td>\n",
       "      <td>0.874913</td>\n",
       "      <td>0.864430</td>\n",
       "      <td>0.862509</td>\n",
       "      <td>0.013536</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.055000</td>\n",
       "      <td>0.010635</td>\n",
       "      <td>0.044995</td>\n",
       "      <td>0.005047</td>\n",
       "      <td>0.5</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>{'complementnb__alpha': 0.5, 'complementnb__fi...</td>\n",
       "      <td>0.813757</td>\n",
       "      <td>0.802388</td>\n",
       "      <td>...</td>\n",
       "      <td>0.851153</td>\n",
       "      <td>0.639914</td>\n",
       "      <td>0.180396</td>\n",
       "      <td>13</td>\n",
       "      <td>0.826695</td>\n",
       "      <td>0.444444</td>\n",
       "      <td>0.671558</td>\n",
       "      <td>0.714885</td>\n",
       "      <td>0.664396</td>\n",
       "      <td>0.139032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.055503</td>\n",
       "      <td>0.007700</td>\n",
       "      <td>0.047493</td>\n",
       "      <td>0.009066</td>\n",
       "      <td>0.5</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>{'complementnb__alpha': 0.5, 'complementnb__fi...</td>\n",
       "      <td>0.816530</td>\n",
       "      <td>0.818332</td>\n",
       "      <td>...</td>\n",
       "      <td>0.955975</td>\n",
       "      <td>0.835413</td>\n",
       "      <td>0.107610</td>\n",
       "      <td>1</td>\n",
       "      <td>0.870720</td>\n",
       "      <td>0.839972</td>\n",
       "      <td>0.874913</td>\n",
       "      <td>0.864430</td>\n",
       "      <td>0.862509</td>\n",
       "      <td>0.013536</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.069002</td>\n",
       "      <td>0.022504</td>\n",
       "      <td>0.047500</td>\n",
       "      <td>0.006580</td>\n",
       "      <td>0.6</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>{'complementnb__alpha': 0.6, 'complementnb__fi...</td>\n",
       "      <td>0.813695</td>\n",
       "      <td>0.802181</td>\n",
       "      <td>...</td>\n",
       "      <td>0.851153</td>\n",
       "      <td>0.638865</td>\n",
       "      <td>0.180195</td>\n",
       "      <td>17</td>\n",
       "      <td>0.826695</td>\n",
       "      <td>0.444444</td>\n",
       "      <td>0.670860</td>\n",
       "      <td>0.713487</td>\n",
       "      <td>0.663871</td>\n",
       "      <td>0.138898</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.055927</td>\n",
       "      <td>0.010170</td>\n",
       "      <td>0.035155</td>\n",
       "      <td>0.006768</td>\n",
       "      <td>0.6</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>{'complementnb__alpha': 0.6, 'complementnb__fi...</td>\n",
       "      <td>0.816552</td>\n",
       "      <td>0.818178</td>\n",
       "      <td>...</td>\n",
       "      <td>0.955975</td>\n",
       "      <td>0.835413</td>\n",
       "      <td>0.107610</td>\n",
       "      <td>1</td>\n",
       "      <td>0.870720</td>\n",
       "      <td>0.839972</td>\n",
       "      <td>0.875611</td>\n",
       "      <td>0.864430</td>\n",
       "      <td>0.862683</td>\n",
       "      <td>0.013698</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.050787</td>\n",
       "      <td>0.006776</td>\n",
       "      <td>0.046875</td>\n",
       "      <td>0.000017</td>\n",
       "      <td>0.6</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>{'complementnb__alpha': 0.6, 'complementnb__fi...</td>\n",
       "      <td>0.813695</td>\n",
       "      <td>0.802181</td>\n",
       "      <td>...</td>\n",
       "      <td>0.851153</td>\n",
       "      <td>0.638865</td>\n",
       "      <td>0.180195</td>\n",
       "      <td>17</td>\n",
       "      <td>0.826695</td>\n",
       "      <td>0.444444</td>\n",
       "      <td>0.670860</td>\n",
       "      <td>0.713487</td>\n",
       "      <td>0.663871</td>\n",
       "      <td>0.138898</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.059201</td>\n",
       "      <td>0.012571</td>\n",
       "      <td>0.042966</td>\n",
       "      <td>0.006758</td>\n",
       "      <td>0.6</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>{'complementnb__alpha': 0.6, 'complementnb__fi...</td>\n",
       "      <td>0.816552</td>\n",
       "      <td>0.818178</td>\n",
       "      <td>...</td>\n",
       "      <td>0.955975</td>\n",
       "      <td>0.835413</td>\n",
       "      <td>0.107610</td>\n",
       "      <td>1</td>\n",
       "      <td>0.870720</td>\n",
       "      <td>0.839972</td>\n",
       "      <td>0.875611</td>\n",
       "      <td>0.864430</td>\n",
       "      <td>0.862683</td>\n",
       "      <td>0.013698</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.050785</td>\n",
       "      <td>0.006763</td>\n",
       "      <td>0.050776</td>\n",
       "      <td>0.017027</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>{'complementnb__alpha': 1, 'complementnb__fit_...</td>\n",
       "      <td>0.813452</td>\n",
       "      <td>0.801399</td>\n",
       "      <td>...</td>\n",
       "      <td>0.846960</td>\n",
       "      <td>0.635196</td>\n",
       "      <td>0.181475</td>\n",
       "      <td>19</td>\n",
       "      <td>0.820405</td>\n",
       "      <td>0.436059</td>\n",
       "      <td>0.667365</td>\n",
       "      <td>0.712089</td>\n",
       "      <td>0.658980</td>\n",
       "      <td>0.140217</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.064924</td>\n",
       "      <td>0.013970</td>\n",
       "      <td>0.051369</td>\n",
       "      <td>0.019297</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>{'complementnb__alpha': 1, 'complementnb__fit_...</td>\n",
       "      <td>0.816570</td>\n",
       "      <td>0.817513</td>\n",
       "      <td>...</td>\n",
       "      <td>0.955975</td>\n",
       "      <td>0.834889</td>\n",
       "      <td>0.107884</td>\n",
       "      <td>9</td>\n",
       "      <td>0.870021</td>\n",
       "      <td>0.839972</td>\n",
       "      <td>0.875611</td>\n",
       "      <td>0.863732</td>\n",
       "      <td>0.862334</td>\n",
       "      <td>0.013577</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.042969</td>\n",
       "      <td>0.006731</td>\n",
       "      <td>0.042959</td>\n",
       "      <td>0.012933</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>{'complementnb__alpha': 1, 'complementnb__fit_...</td>\n",
       "      <td>0.813452</td>\n",
       "      <td>0.801399</td>\n",
       "      <td>...</td>\n",
       "      <td>0.846960</td>\n",
       "      <td>0.635196</td>\n",
       "      <td>0.181475</td>\n",
       "      <td>19</td>\n",
       "      <td>0.820405</td>\n",
       "      <td>0.436059</td>\n",
       "      <td>0.667365</td>\n",
       "      <td>0.712089</td>\n",
       "      <td>0.658980</td>\n",
       "      <td>0.140217</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.046872</td>\n",
       "      <td>0.000015</td>\n",
       "      <td>0.039067</td>\n",
       "      <td>0.007805</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>{'complementnb__alpha': 1, 'complementnb__fit_...</td>\n",
       "      <td>0.816570</td>\n",
       "      <td>0.817513</td>\n",
       "      <td>...</td>\n",
       "      <td>0.955975</td>\n",
       "      <td>0.834889</td>\n",
       "      <td>0.107884</td>\n",
       "      <td>9</td>\n",
       "      <td>0.870021</td>\n",
       "      <td>0.839972</td>\n",
       "      <td>0.875611</td>\n",
       "      <td>0.863732</td>\n",
       "      <td>0.862334</td>\n",
       "      <td>0.013577</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>20 rows × 47 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "0        0.034258      0.001295         0.047244        0.006984   \n",
       "1        0.036255      0.011507         0.034548        0.003359   \n",
       "2        0.035156      0.006772         0.039065        0.013554   \n",
       "3        0.054212      0.013631         0.026475        0.005136   \n",
       "4        0.035156      0.006764         0.039064        0.007809   \n",
       "5        0.046873      0.011056         0.039053        0.007804   \n",
       "6        0.060763      0.018033         0.045240        0.007587   \n",
       "7        0.056997      0.017936         0.061253        0.008869   \n",
       "8        0.054504      0.012627         0.048248        0.004258   \n",
       "9        0.063504      0.017629         0.044748        0.002487   \n",
       "10       0.055000      0.010635         0.044995        0.005047   \n",
       "11       0.055503      0.007700         0.047493        0.009066   \n",
       "12       0.069002      0.022504         0.047500        0.006580   \n",
       "13       0.055927      0.010170         0.035155        0.006768   \n",
       "14       0.050787      0.006776         0.046875        0.000017   \n",
       "15       0.059201      0.012571         0.042966        0.006758   \n",
       "16       0.050785      0.006763         0.050776        0.017027   \n",
       "17       0.064924      0.013970         0.051369        0.019297   \n",
       "18       0.042969      0.006731         0.042959        0.012933   \n",
       "19       0.046872      0.000015         0.039067        0.007805   \n",
       "\n",
       "   param_complementnb__alpha param_complementnb__fit_prior  \\\n",
       "0                          0                          True   \n",
       "1                          0                          True   \n",
       "2                          0                         False   \n",
       "3                          0                         False   \n",
       "4                        0.4                          True   \n",
       "5                        0.4                          True   \n",
       "6                        0.4                         False   \n",
       "7                        0.4                         False   \n",
       "8                        0.5                          True   \n",
       "9                        0.5                          True   \n",
       "10                       0.5                         False   \n",
       "11                       0.5                         False   \n",
       "12                       0.6                          True   \n",
       "13                       0.6                          True   \n",
       "14                       0.6                         False   \n",
       "15                       0.6                         False   \n",
       "16                         1                          True   \n",
       "17                         1                          True   \n",
       "18                         1                         False   \n",
       "19                         1                         False   \n",
       "\n",
       "   param_complementnb__norm  \\\n",
       "0                      True   \n",
       "1                     False   \n",
       "2                      True   \n",
       "3                     False   \n",
       "4                      True   \n",
       "5                     False   \n",
       "6                      True   \n",
       "7                     False   \n",
       "8                      True   \n",
       "9                     False   \n",
       "10                     True   \n",
       "11                    False   \n",
       "12                     True   \n",
       "13                    False   \n",
       "14                     True   \n",
       "15                    False   \n",
       "16                     True   \n",
       "17                    False   \n",
       "18                     True   \n",
       "19                    False   \n",
       "\n",
       "                                               params  split0_test_AUC  \\\n",
       "0   {'complementnb__alpha': 0, 'complementnb__fit_...         0.813963   \n",
       "1   {'complementnb__alpha': 0, 'complementnb__fit_...         0.816455   \n",
       "2   {'complementnb__alpha': 0, 'complementnb__fit_...         0.813963   \n",
       "3   {'complementnb__alpha': 0, 'complementnb__fit_...         0.816455   \n",
       "4   {'complementnb__alpha': 0.4, 'complementnb__fi...         0.813820   \n",
       "5   {'complementnb__alpha': 0.4, 'complementnb__fi...         0.816521   \n",
       "6   {'complementnb__alpha': 0.4, 'complementnb__fi...         0.813820   \n",
       "7   {'complementnb__alpha': 0.4, 'complementnb__fi...         0.816521   \n",
       "8   {'complementnb__alpha': 0.5, 'complementnb__fi...         0.813757   \n",
       "9   {'complementnb__alpha': 0.5, 'complementnb__fi...         0.816530   \n",
       "10  {'complementnb__alpha': 0.5, 'complementnb__fi...         0.813757   \n",
       "11  {'complementnb__alpha': 0.5, 'complementnb__fi...         0.816530   \n",
       "12  {'complementnb__alpha': 0.6, 'complementnb__fi...         0.813695   \n",
       "13  {'complementnb__alpha': 0.6, 'complementnb__fi...         0.816552   \n",
       "14  {'complementnb__alpha': 0.6, 'complementnb__fi...         0.813695   \n",
       "15  {'complementnb__alpha': 0.6, 'complementnb__fi...         0.816552   \n",
       "16  {'complementnb__alpha': 1, 'complementnb__fit_...         0.813452   \n",
       "17  {'complementnb__alpha': 1, 'complementnb__fit_...         0.816570   \n",
       "18  {'complementnb__alpha': 1, 'complementnb__fit_...         0.813452   \n",
       "19  {'complementnb__alpha': 1, 'complementnb__fit_...         0.816570   \n",
       "\n",
       "    split1_test_AUC  ...  split3_test_Sensitivity  mean_test_Sensitivity  \\\n",
       "0          0.803381  ...                 0.853249               0.642534   \n",
       "1          0.819132  ...                 0.955975               0.835413   \n",
       "2          0.803381  ...                 0.853249               0.642534   \n",
       "3          0.819132  ...                 0.955975               0.835413   \n",
       "4          0.802612  ...                 0.851153               0.639914   \n",
       "5          0.818484  ...                 0.955975               0.835413   \n",
       "6          0.802612  ...                 0.851153               0.639914   \n",
       "7          0.818484  ...                 0.955975               0.835413   \n",
       "8          0.802388  ...                 0.851153               0.639914   \n",
       "9          0.818332  ...                 0.955975               0.835413   \n",
       "10         0.802388  ...                 0.851153               0.639914   \n",
       "11         0.818332  ...                 0.955975               0.835413   \n",
       "12         0.802181  ...                 0.851153               0.638865   \n",
       "13         0.818178  ...                 0.955975               0.835413   \n",
       "14         0.802181  ...                 0.851153               0.638865   \n",
       "15         0.818178  ...                 0.955975               0.835413   \n",
       "16         0.801399  ...                 0.846960               0.635196   \n",
       "17         0.817513  ...                 0.955975               0.834889   \n",
       "18         0.801399  ...                 0.846960               0.635196   \n",
       "19         0.817513  ...                 0.955975               0.834889   \n",
       "\n",
       "    std_test_Sensitivity  rank_test_Sensitivity  split0_train_Sensitivity  \\\n",
       "0               0.179328                     11                  0.836478   \n",
       "1               0.107610                      1                  0.870720   \n",
       "2               0.179328                     11                  0.836478   \n",
       "3               0.107610                      1                  0.870720   \n",
       "4               0.180396                     13                  0.828092   \n",
       "5               0.107610                      1                  0.870720   \n",
       "6               0.180396                     13                  0.828092   \n",
       "7               0.107610                      1                  0.870720   \n",
       "8               0.180396                     13                  0.826695   \n",
       "9               0.107610                      1                  0.870720   \n",
       "10              0.180396                     13                  0.826695   \n",
       "11              0.107610                      1                  0.870720   \n",
       "12              0.180195                     17                  0.826695   \n",
       "13              0.107610                      1                  0.870720   \n",
       "14              0.180195                     17                  0.826695   \n",
       "15              0.107610                      1                  0.870720   \n",
       "16              0.181475                     19                  0.820405   \n",
       "17              0.107884                      9                  0.870021   \n",
       "18              0.181475                     19                  0.820405   \n",
       "19              0.107884                      9                  0.870021   \n",
       "\n",
       "    split1_train_Sensitivity  split2_train_Sensitivity  \\\n",
       "0                   0.450734                  0.673655   \n",
       "1                   0.839273                  0.877009   \n",
       "2                   0.450734                  0.673655   \n",
       "3                   0.839273                  0.877009   \n",
       "4                   0.447240                  0.671558   \n",
       "5                   0.839972                  0.875611   \n",
       "6                   0.447240                  0.671558   \n",
       "7                   0.839972                  0.875611   \n",
       "8                   0.444444                  0.671558   \n",
       "9                   0.839972                  0.874913   \n",
       "10                  0.444444                  0.671558   \n",
       "11                  0.839972                  0.874913   \n",
       "12                  0.444444                  0.670860   \n",
       "13                  0.839972                  0.875611   \n",
       "14                  0.444444                  0.670860   \n",
       "15                  0.839972                  0.875611   \n",
       "16                  0.436059                  0.667365   \n",
       "17                  0.839972                  0.875611   \n",
       "18                  0.436059                  0.667365   \n",
       "19                  0.839972                  0.875611   \n",
       "\n",
       "    split3_train_Sensitivity  mean_train_Sensitivity  std_train_Sensitivity  \n",
       "0                   0.718379                0.669811               0.139773  \n",
       "1                   0.864430                0.862858               0.014325  \n",
       "2                   0.718379                0.669811               0.139773  \n",
       "3                   0.864430                0.862858               0.014325  \n",
       "4                   0.715584                0.665618               0.138401  \n",
       "5                   0.864430                0.862683               0.013698  \n",
       "6                   0.715584                0.665618               0.138401  \n",
       "7                   0.864430                0.862683               0.013698  \n",
       "8                   0.714885                0.664396               0.139032  \n",
       "9                   0.864430                0.862509               0.013536  \n",
       "10                  0.714885                0.664396               0.139032  \n",
       "11                  0.864430                0.862509               0.013536  \n",
       "12                  0.713487                0.663871               0.138898  \n",
       "13                  0.864430                0.862683               0.013698  \n",
       "14                  0.713487                0.663871               0.138898  \n",
       "15                  0.864430                0.862683               0.013698  \n",
       "16                  0.712089                0.658980               0.140217  \n",
       "17                  0.863732                0.862334               0.013577  \n",
       "18                  0.712089                0.658980               0.140217  \n",
       "19                  0.863732                0.862334               0.013577  \n",
       "\n",
       "[20 rows x 47 columns]"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_cnb = gs.cv_results_\n",
    "data = pandas.DataFrame(results_cnb)\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>params</th>\n",
       "      <th>mean_test_AUC</th>\n",
       "      <th>mean_test_F_score</th>\n",
       "      <th>mean_test_Sensitivity</th>\n",
       "      <th>rank_test_AUC</th>\n",
       "      <th>rank_test_F_score</th>\n",
       "      <th>rank_test_Sensitivity</th>\n",
       "      <th>mean_train_AUC</th>\n",
       "      <th>mean_train_F_score</th>\n",
       "      <th>mean_train_Sensitivity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.034258</td>\n",
       "      <td>{'complementnb__alpha': 0, 'complementnb__fit_...</td>\n",
       "      <td>0.792167</td>\n",
       "      <td>0.441939</td>\n",
       "      <td>0.642534</td>\n",
       "      <td>11</td>\n",
       "      <td>7</td>\n",
       "      <td>11</td>\n",
       "      <td>0.807121</td>\n",
       "      <td>0.463429</td>\n",
       "      <td>0.669811</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.036255</td>\n",
       "      <td>{'complementnb__alpha': 0, 'complementnb__fit_...</td>\n",
       "      <td>0.797842</td>\n",
       "      <td>0.420761</td>\n",
       "      <td>0.835413</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>0.812993</td>\n",
       "      <td>0.418521</td>\n",
       "      <td>0.862858</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.035156</td>\n",
       "      <td>{'complementnb__alpha': 0, 'complementnb__fit_...</td>\n",
       "      <td>0.792167</td>\n",
       "      <td>0.441939</td>\n",
       "      <td>0.642534</td>\n",
       "      <td>11</td>\n",
       "      <td>7</td>\n",
       "      <td>11</td>\n",
       "      <td>0.807121</td>\n",
       "      <td>0.463429</td>\n",
       "      <td>0.669811</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.054212</td>\n",
       "      <td>{'complementnb__alpha': 0, 'complementnb__fit_...</td>\n",
       "      <td>0.797842</td>\n",
       "      <td>0.420761</td>\n",
       "      <td>0.835413</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>0.812993</td>\n",
       "      <td>0.418521</td>\n",
       "      <td>0.862858</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.035156</td>\n",
       "      <td>{'complementnb__alpha': 0.4, 'complementnb__fi...</td>\n",
       "      <td>0.791874</td>\n",
       "      <td>0.441950</td>\n",
       "      <td>0.639914</td>\n",
       "      <td>13</td>\n",
       "      <td>5</td>\n",
       "      <td>13</td>\n",
       "      <td>0.806888</td>\n",
       "      <td>0.464422</td>\n",
       "      <td>0.665618</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.046873</td>\n",
       "      <td>{'complementnb__alpha': 0.4, 'complementnb__fi...</td>\n",
       "      <td>0.797702</td>\n",
       "      <td>0.420606</td>\n",
       "      <td>0.835413</td>\n",
       "      <td>3</td>\n",
       "      <td>17</td>\n",
       "      <td>1</td>\n",
       "      <td>0.812962</td>\n",
       "      <td>0.418882</td>\n",
       "      <td>0.862683</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.060763</td>\n",
       "      <td>{'complementnb__alpha': 0.4, 'complementnb__fi...</td>\n",
       "      <td>0.791874</td>\n",
       "      <td>0.441950</td>\n",
       "      <td>0.639914</td>\n",
       "      <td>13</td>\n",
       "      <td>5</td>\n",
       "      <td>13</td>\n",
       "      <td>0.806888</td>\n",
       "      <td>0.464422</td>\n",
       "      <td>0.665618</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.056997</td>\n",
       "      <td>{'complementnb__alpha': 0.4, 'complementnb__fi...</td>\n",
       "      <td>0.797702</td>\n",
       "      <td>0.420606</td>\n",
       "      <td>0.835413</td>\n",
       "      <td>3</td>\n",
       "      <td>17</td>\n",
       "      <td>1</td>\n",
       "      <td>0.812962</td>\n",
       "      <td>0.418882</td>\n",
       "      <td>0.862683</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.054504</td>\n",
       "      <td>{'complementnb__alpha': 0.5, 'complementnb__fi...</td>\n",
       "      <td>0.791784</td>\n",
       "      <td>0.442446</td>\n",
       "      <td>0.639914</td>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>0.806834</td>\n",
       "      <td>0.464271</td>\n",
       "      <td>0.664396</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.063504</td>\n",
       "      <td>{'complementnb__alpha': 0.5, 'complementnb__fi...</td>\n",
       "      <td>0.797661</td>\n",
       "      <td>0.420680</td>\n",
       "      <td>0.835413</td>\n",
       "      <td>5</td>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "      <td>0.812953</td>\n",
       "      <td>0.418923</td>\n",
       "      <td>0.862509</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.055000</td>\n",
       "      <td>{'complementnb__alpha': 0.5, 'complementnb__fi...</td>\n",
       "      <td>0.791784</td>\n",
       "      <td>0.442446</td>\n",
       "      <td>0.639914</td>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>0.806834</td>\n",
       "      <td>0.464271</td>\n",
       "      <td>0.664396</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.055503</td>\n",
       "      <td>{'complementnb__alpha': 0.5, 'complementnb__fi...</td>\n",
       "      <td>0.797661</td>\n",
       "      <td>0.420680</td>\n",
       "      <td>0.835413</td>\n",
       "      <td>5</td>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "      <td>0.812953</td>\n",
       "      <td>0.418923</td>\n",
       "      <td>0.862509</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.069002</td>\n",
       "      <td>{'complementnb__alpha': 0.6, 'complementnb__fi...</td>\n",
       "      <td>0.791695</td>\n",
       "      <td>0.442157</td>\n",
       "      <td>0.638865</td>\n",
       "      <td>17</td>\n",
       "      <td>3</td>\n",
       "      <td>17</td>\n",
       "      <td>0.806776</td>\n",
       "      <td>0.464853</td>\n",
       "      <td>0.663871</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.055927</td>\n",
       "      <td>{'complementnb__alpha': 0.6, 'complementnb__fi...</td>\n",
       "      <td>0.797630</td>\n",
       "      <td>0.420610</td>\n",
       "      <td>0.835413</td>\n",
       "      <td>7</td>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "      <td>0.812943</td>\n",
       "      <td>0.418993</td>\n",
       "      <td>0.862683</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.050787</td>\n",
       "      <td>{'complementnb__alpha': 0.6, 'complementnb__fi...</td>\n",
       "      <td>0.791695</td>\n",
       "      <td>0.442157</td>\n",
       "      <td>0.638865</td>\n",
       "      <td>17</td>\n",
       "      <td>3</td>\n",
       "      <td>17</td>\n",
       "      <td>0.806776</td>\n",
       "      <td>0.464853</td>\n",
       "      <td>0.663871</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.059201</td>\n",
       "      <td>{'complementnb__alpha': 0.6, 'complementnb__fi...</td>\n",
       "      <td>0.797630</td>\n",
       "      <td>0.420610</td>\n",
       "      <td>0.835413</td>\n",
       "      <td>7</td>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "      <td>0.812943</td>\n",
       "      <td>0.418993</td>\n",
       "      <td>0.862683</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.050785</td>\n",
       "      <td>{'complementnb__alpha': 1, 'complementnb__fit_...</td>\n",
       "      <td>0.791362</td>\n",
       "      <td>0.441815</td>\n",
       "      <td>0.635196</td>\n",
       "      <td>19</td>\n",
       "      <td>9</td>\n",
       "      <td>19</td>\n",
       "      <td>0.806544</td>\n",
       "      <td>0.464452</td>\n",
       "      <td>0.658980</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.064924</td>\n",
       "      <td>{'complementnb__alpha': 1, 'complementnb__fit_...</td>\n",
       "      <td>0.797465</td>\n",
       "      <td>0.420549</td>\n",
       "      <td>0.834889</td>\n",
       "      <td>9</td>\n",
       "      <td>19</td>\n",
       "      <td>9</td>\n",
       "      <td>0.812911</td>\n",
       "      <td>0.419207</td>\n",
       "      <td>0.862334</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.042969</td>\n",
       "      <td>{'complementnb__alpha': 1, 'complementnb__fit_...</td>\n",
       "      <td>0.791362</td>\n",
       "      <td>0.441815</td>\n",
       "      <td>0.635196</td>\n",
       "      <td>19</td>\n",
       "      <td>9</td>\n",
       "      <td>19</td>\n",
       "      <td>0.806544</td>\n",
       "      <td>0.464452</td>\n",
       "      <td>0.658980</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.046872</td>\n",
       "      <td>{'complementnb__alpha': 1, 'complementnb__fit_...</td>\n",
       "      <td>0.797465</td>\n",
       "      <td>0.420549</td>\n",
       "      <td>0.834889</td>\n",
       "      <td>9</td>\n",
       "      <td>19</td>\n",
       "      <td>9</td>\n",
       "      <td>0.812911</td>\n",
       "      <td>0.419207</td>\n",
       "      <td>0.862334</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    mean_fit_time                                             params  \\\n",
       "0        0.034258  {'complementnb__alpha': 0, 'complementnb__fit_...   \n",
       "1        0.036255  {'complementnb__alpha': 0, 'complementnb__fit_...   \n",
       "2        0.035156  {'complementnb__alpha': 0, 'complementnb__fit_...   \n",
       "3        0.054212  {'complementnb__alpha': 0, 'complementnb__fit_...   \n",
       "4        0.035156  {'complementnb__alpha': 0.4, 'complementnb__fi...   \n",
       "5        0.046873  {'complementnb__alpha': 0.4, 'complementnb__fi...   \n",
       "6        0.060763  {'complementnb__alpha': 0.4, 'complementnb__fi...   \n",
       "7        0.056997  {'complementnb__alpha': 0.4, 'complementnb__fi...   \n",
       "8        0.054504  {'complementnb__alpha': 0.5, 'complementnb__fi...   \n",
       "9        0.063504  {'complementnb__alpha': 0.5, 'complementnb__fi...   \n",
       "10       0.055000  {'complementnb__alpha': 0.5, 'complementnb__fi...   \n",
       "11       0.055503  {'complementnb__alpha': 0.5, 'complementnb__fi...   \n",
       "12       0.069002  {'complementnb__alpha': 0.6, 'complementnb__fi...   \n",
       "13       0.055927  {'complementnb__alpha': 0.6, 'complementnb__fi...   \n",
       "14       0.050787  {'complementnb__alpha': 0.6, 'complementnb__fi...   \n",
       "15       0.059201  {'complementnb__alpha': 0.6, 'complementnb__fi...   \n",
       "16       0.050785  {'complementnb__alpha': 1, 'complementnb__fit_...   \n",
       "17       0.064924  {'complementnb__alpha': 1, 'complementnb__fit_...   \n",
       "18       0.042969  {'complementnb__alpha': 1, 'complementnb__fit_...   \n",
       "19       0.046872  {'complementnb__alpha': 1, 'complementnb__fit_...   \n",
       "\n",
       "    mean_test_AUC  mean_test_F_score  mean_test_Sensitivity  rank_test_AUC  \\\n",
       "0        0.792167           0.441939               0.642534             11   \n",
       "1        0.797842           0.420761               0.835413              1   \n",
       "2        0.792167           0.441939               0.642534             11   \n",
       "3        0.797842           0.420761               0.835413              1   \n",
       "4        0.791874           0.441950               0.639914             13   \n",
       "5        0.797702           0.420606               0.835413              3   \n",
       "6        0.791874           0.441950               0.639914             13   \n",
       "7        0.797702           0.420606               0.835413              3   \n",
       "8        0.791784           0.442446               0.639914             15   \n",
       "9        0.797661           0.420680               0.835413              5   \n",
       "10       0.791784           0.442446               0.639914             15   \n",
       "11       0.797661           0.420680               0.835413              5   \n",
       "12       0.791695           0.442157               0.638865             17   \n",
       "13       0.797630           0.420610               0.835413              7   \n",
       "14       0.791695           0.442157               0.638865             17   \n",
       "15       0.797630           0.420610               0.835413              7   \n",
       "16       0.791362           0.441815               0.635196             19   \n",
       "17       0.797465           0.420549               0.834889              9   \n",
       "18       0.791362           0.441815               0.635196             19   \n",
       "19       0.797465           0.420549               0.834889              9   \n",
       "\n",
       "    rank_test_F_score  rank_test_Sensitivity  mean_train_AUC  \\\n",
       "0                   7                     11        0.807121   \n",
       "1                  11                      1        0.812993   \n",
       "2                   7                     11        0.807121   \n",
       "3                  11                      1        0.812993   \n",
       "4                   5                     13        0.806888   \n",
       "5                  17                      1        0.812962   \n",
       "6                   5                     13        0.806888   \n",
       "7                  17                      1        0.812962   \n",
       "8                   1                     13        0.806834   \n",
       "9                  13                      1        0.812953   \n",
       "10                  1                     13        0.806834   \n",
       "11                 13                      1        0.812953   \n",
       "12                  3                     17        0.806776   \n",
       "13                 15                      1        0.812943   \n",
       "14                  3                     17        0.806776   \n",
       "15                 15                      1        0.812943   \n",
       "16                  9                     19        0.806544   \n",
       "17                 19                      9        0.812911   \n",
       "18                  9                     19        0.806544   \n",
       "19                 19                      9        0.812911   \n",
       "\n",
       "    mean_train_F_score  mean_train_Sensitivity  \n",
       "0             0.463429                0.669811  \n",
       "1             0.418521                0.862858  \n",
       "2             0.463429                0.669811  \n",
       "3             0.418521                0.862858  \n",
       "4             0.464422                0.665618  \n",
       "5             0.418882                0.862683  \n",
       "6             0.464422                0.665618  \n",
       "7             0.418882                0.862683  \n",
       "8             0.464271                0.664396  \n",
       "9             0.418923                0.862509  \n",
       "10            0.464271                0.664396  \n",
       "11            0.418923                0.862509  \n",
       "12            0.464853                0.663871  \n",
       "13            0.418993                0.862683  \n",
       "14            0.464853                0.663871  \n",
       "15            0.418993                0.862683  \n",
       "16            0.464452                0.658980  \n",
       "17            0.419207                0.862334  \n",
       "18            0.464452                0.658980  \n",
       "19            0.419207                0.862334  "
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "table_cnb = make_table(data)\n",
    "table_cnb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'complementnb__alpha': 0.5,\n",
       " 'complementnb__fit_prior': True,\n",
       " 'complementnb__norm': True}"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 4 folds for each of 11 candidates, totalling 44 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   5 tasks      | elapsed:    0.5s\n",
      "[Parallel(n_jobs=-1)]: Done  10 tasks      | elapsed:    1.0s\n",
      "[Parallel(n_jobs=-1)]: Done  17 tasks      | elapsed:    1.9s\n",
      "[Parallel(n_jobs=-1)]: Done  24 tasks      | elapsed:    2.5s\n",
      "[Parallel(n_jobs=-1)]: Done  33 tasks      | elapsed:    3.7s\n",
      "[Parallel(n_jobs=-1)]: Done  42 out of  44 | elapsed:    4.7s remaining:    0.1s\n",
      "[Parallel(n_jobs=-1)]: Done  44 out of  44 | elapsed:    4.7s finished\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "scoring = {'AUC': 'roc_auc', 'F-score': 'f1', 'Sensitivity': make_scorer(recall_score)} \n",
    "parameters = {\n",
    "    'gaussiannb__var_smoothing': [0.0000000001, 0.00000001, 0.000001, 0.0001, 0.1, 10, 100, 1000, 100000, 1000000, 100000000]\n",
    "}\n",
    "\n",
    "pp = make_pipeline(StandardScaler(), GaussianNB())\n",
    "\n",
    "gs = GridSearchCV(pp, parameters, cv=skf, scoring=scoring, refit='F-score', return_train_score=True, n_jobs=-1, verbose=10) \n",
    "gs.fit(X, Y)\n",
    "results = gs.cv_results_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_gaussiannb__var_smoothing</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_AUC</th>\n",
       "      <th>split1_test_AUC</th>\n",
       "      <th>split2_test_AUC</th>\n",
       "      <th>split3_test_AUC</th>\n",
       "      <th>...</th>\n",
       "      <th>split3_test_Sensitivity</th>\n",
       "      <th>mean_test_Sensitivity</th>\n",
       "      <th>std_test_Sensitivity</th>\n",
       "      <th>rank_test_Sensitivity</th>\n",
       "      <th>split0_train_Sensitivity</th>\n",
       "      <th>split1_train_Sensitivity</th>\n",
       "      <th>split2_train_Sensitivity</th>\n",
       "      <th>split3_train_Sensitivity</th>\n",
       "      <th>mean_train_Sensitivity</th>\n",
       "      <th>std_train_Sensitivity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.079499</td>\n",
       "      <td>0.004940</td>\n",
       "      <td>0.060749</td>\n",
       "      <td>0.004810</td>\n",
       "      <td>1e-10</td>\n",
       "      <td>{'gaussiannb__var_smoothing': 1e-10}</td>\n",
       "      <td>0.848756</td>\n",
       "      <td>0.830094</td>\n",
       "      <td>0.800651</td>\n",
       "      <td>0.806303</td>\n",
       "      <td>...</td>\n",
       "      <td>0.823899</td>\n",
       "      <td>0.649351</td>\n",
       "      <td>0.132485</td>\n",
       "      <td>1</td>\n",
       "      <td>0.709294</td>\n",
       "      <td>0.649196</td>\n",
       "      <td>0.689029</td>\n",
       "      <td>0.718379</td>\n",
       "      <td>0.691474</td>\n",
       "      <td>0.026621</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.062663</td>\n",
       "      <td>0.000249</td>\n",
       "      <td>0.050786</td>\n",
       "      <td>0.006753</td>\n",
       "      <td>1e-08</td>\n",
       "      <td>{'gaussiannb__var_smoothing': 1e-08}</td>\n",
       "      <td>0.848756</td>\n",
       "      <td>0.830094</td>\n",
       "      <td>0.800651</td>\n",
       "      <td>0.806303</td>\n",
       "      <td>...</td>\n",
       "      <td>0.823899</td>\n",
       "      <td>0.649351</td>\n",
       "      <td>0.132485</td>\n",
       "      <td>1</td>\n",
       "      <td>0.709294</td>\n",
       "      <td>0.649196</td>\n",
       "      <td>0.689029</td>\n",
       "      <td>0.718379</td>\n",
       "      <td>0.691474</td>\n",
       "      <td>0.026621</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.093762</td>\n",
       "      <td>0.011059</td>\n",
       "      <td>0.076338</td>\n",
       "      <td>0.014632</td>\n",
       "      <td>1e-06</td>\n",
       "      <td>{'gaussiannb__var_smoothing': 1e-06}</td>\n",
       "      <td>0.848756</td>\n",
       "      <td>0.830095</td>\n",
       "      <td>0.800651</td>\n",
       "      <td>0.806302</td>\n",
       "      <td>...</td>\n",
       "      <td>0.823899</td>\n",
       "      <td>0.649351</td>\n",
       "      <td>0.132485</td>\n",
       "      <td>1</td>\n",
       "      <td>0.709294</td>\n",
       "      <td>0.649196</td>\n",
       "      <td>0.689029</td>\n",
       "      <td>0.718379</td>\n",
       "      <td>0.691474</td>\n",
       "      <td>0.026621</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.121751</td>\n",
       "      <td>0.032900</td>\n",
       "      <td>0.098747</td>\n",
       "      <td>0.017100</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>{'gaussiannb__var_smoothing': 0.0001}</td>\n",
       "      <td>0.848759</td>\n",
       "      <td>0.830101</td>\n",
       "      <td>0.800648</td>\n",
       "      <td>0.806298</td>\n",
       "      <td>...</td>\n",
       "      <td>0.823899</td>\n",
       "      <td>0.649351</td>\n",
       "      <td>0.132485</td>\n",
       "      <td>1</td>\n",
       "      <td>0.709294</td>\n",
       "      <td>0.649196</td>\n",
       "      <td>0.689029</td>\n",
       "      <td>0.718379</td>\n",
       "      <td>0.691474</td>\n",
       "      <td>0.026621</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.124741</td>\n",
       "      <td>0.015825</td>\n",
       "      <td>0.075324</td>\n",
       "      <td>0.024469</td>\n",
       "      <td>0.1</td>\n",
       "      <td>{'gaussiannb__var_smoothing': 0.1}</td>\n",
       "      <td>0.849927</td>\n",
       "      <td>0.834127</td>\n",
       "      <td>0.797387</td>\n",
       "      <td>0.803957</td>\n",
       "      <td>...</td>\n",
       "      <td>0.740042</td>\n",
       "      <td>0.574929</td>\n",
       "      <td>0.120297</td>\n",
       "      <td>5</td>\n",
       "      <td>0.614256</td>\n",
       "      <td>0.568134</td>\n",
       "      <td>0.622642</td>\n",
       "      <td>0.645003</td>\n",
       "      <td>0.612509</td>\n",
       "      <td>0.027976</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.121096</td>\n",
       "      <td>0.027891</td>\n",
       "      <td>0.066414</td>\n",
       "      <td>0.017030</td>\n",
       "      <td>10</td>\n",
       "      <td>{'gaussiannb__var_smoothing': 10}</td>\n",
       "      <td>0.902410</td>\n",
       "      <td>0.840693</td>\n",
       "      <td>0.807217</td>\n",
       "      <td>0.816855</td>\n",
       "      <td>...</td>\n",
       "      <td>0.008386</td>\n",
       "      <td>0.008909</td>\n",
       "      <td>0.003743</td>\n",
       "      <td>6</td>\n",
       "      <td>0.009783</td>\n",
       "      <td>0.010482</td>\n",
       "      <td>0.009085</td>\n",
       "      <td>0.010482</td>\n",
       "      <td>0.009958</td>\n",
       "      <td>0.000579</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.097652</td>\n",
       "      <td>0.024027</td>\n",
       "      <td>0.074227</td>\n",
       "      <td>0.027898</td>\n",
       "      <td>100</td>\n",
       "      <td>{'gaussiannb__var_smoothing': 100}</td>\n",
       "      <td>0.917182</td>\n",
       "      <td>0.844509</td>\n",
       "      <td>0.814459</td>\n",
       "      <td>0.824082</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.089851</td>\n",
       "      <td>0.017025</td>\n",
       "      <td>0.074209</td>\n",
       "      <td>0.012958</td>\n",
       "      <td>1000</td>\n",
       "      <td>{'gaussiannb__var_smoothing': 1000}</td>\n",
       "      <td>0.918948</td>\n",
       "      <td>0.845084</td>\n",
       "      <td>0.815406</td>\n",
       "      <td>0.825040</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.129291</td>\n",
       "      <td>0.013739</td>\n",
       "      <td>0.088745</td>\n",
       "      <td>0.008550</td>\n",
       "      <td>100000</td>\n",
       "      <td>{'gaussiannb__var_smoothing': 100000}</td>\n",
       "      <td>0.919126</td>\n",
       "      <td>0.845140</td>\n",
       "      <td>0.815510</td>\n",
       "      <td>0.825148</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.092042</td>\n",
       "      <td>0.016431</td>\n",
       "      <td>0.080500</td>\n",
       "      <td>0.028086</td>\n",
       "      <td>1000000</td>\n",
       "      <td>{'gaussiannb__var_smoothing': 1000000}</td>\n",
       "      <td>0.919129</td>\n",
       "      <td>0.845140</td>\n",
       "      <td>0.815510</td>\n",
       "      <td>0.825150</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.144359</td>\n",
       "      <td>0.018933</td>\n",
       "      <td>0.102747</td>\n",
       "      <td>0.012047</td>\n",
       "      <td>100000000</td>\n",
       "      <td>{'gaussiannb__var_smoothing': 100000000}</td>\n",
       "      <td>0.919129</td>\n",
       "      <td>0.845140</td>\n",
       "      <td>0.815510</td>\n",
       "      <td>0.825150</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>11 rows × 45 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "0        0.079499      0.004940         0.060749        0.004810   \n",
       "1        0.062663      0.000249         0.050786        0.006753   \n",
       "2        0.093762      0.011059         0.076338        0.014632   \n",
       "3        0.121751      0.032900         0.098747        0.017100   \n",
       "4        0.124741      0.015825         0.075324        0.024469   \n",
       "5        0.121096      0.027891         0.066414        0.017030   \n",
       "6        0.097652      0.024027         0.074227        0.027898   \n",
       "7        0.089851      0.017025         0.074209        0.012958   \n",
       "8        0.129291      0.013739         0.088745        0.008550   \n",
       "9        0.092042      0.016431         0.080500        0.028086   \n",
       "10       0.144359      0.018933         0.102747        0.012047   \n",
       "\n",
       "   param_gaussiannb__var_smoothing                                    params  \\\n",
       "0                            1e-10      {'gaussiannb__var_smoothing': 1e-10}   \n",
       "1                            1e-08      {'gaussiannb__var_smoothing': 1e-08}   \n",
       "2                            1e-06      {'gaussiannb__var_smoothing': 1e-06}   \n",
       "3                           0.0001     {'gaussiannb__var_smoothing': 0.0001}   \n",
       "4                              0.1        {'gaussiannb__var_smoothing': 0.1}   \n",
       "5                               10         {'gaussiannb__var_smoothing': 10}   \n",
       "6                              100        {'gaussiannb__var_smoothing': 100}   \n",
       "7                             1000       {'gaussiannb__var_smoothing': 1000}   \n",
       "8                           100000     {'gaussiannb__var_smoothing': 100000}   \n",
       "9                          1000000    {'gaussiannb__var_smoothing': 1000000}   \n",
       "10                       100000000  {'gaussiannb__var_smoothing': 100000000}   \n",
       "\n",
       "    split0_test_AUC  split1_test_AUC  split2_test_AUC  split3_test_AUC  ...  \\\n",
       "0          0.848756         0.830094         0.800651         0.806303  ...   \n",
       "1          0.848756         0.830094         0.800651         0.806303  ...   \n",
       "2          0.848756         0.830095         0.800651         0.806302  ...   \n",
       "3          0.848759         0.830101         0.800648         0.806298  ...   \n",
       "4          0.849927         0.834127         0.797387         0.803957  ...   \n",
       "5          0.902410         0.840693         0.807217         0.816855  ...   \n",
       "6          0.917182         0.844509         0.814459         0.824082  ...   \n",
       "7          0.918948         0.845084         0.815406         0.825040  ...   \n",
       "8          0.919126         0.845140         0.815510         0.825148  ...   \n",
       "9          0.919129         0.845140         0.815510         0.825150  ...   \n",
       "10         0.919129         0.845140         0.815510         0.825150  ...   \n",
       "\n",
       "    split3_test_Sensitivity  mean_test_Sensitivity  std_test_Sensitivity  \\\n",
       "0                  0.823899               0.649351              0.132485   \n",
       "1                  0.823899               0.649351              0.132485   \n",
       "2                  0.823899               0.649351              0.132485   \n",
       "3                  0.823899               0.649351              0.132485   \n",
       "4                  0.740042               0.574929              0.120297   \n",
       "5                  0.008386               0.008909              0.003743   \n",
       "6                  0.000000               0.000000              0.000000   \n",
       "7                  0.000000               0.000000              0.000000   \n",
       "8                  0.000000               0.000000              0.000000   \n",
       "9                  0.000000               0.000000              0.000000   \n",
       "10                 0.000000               0.000000              0.000000   \n",
       "\n",
       "    rank_test_Sensitivity  split0_train_Sensitivity  split1_train_Sensitivity  \\\n",
       "0                       1                  0.709294                  0.649196   \n",
       "1                       1                  0.709294                  0.649196   \n",
       "2                       1                  0.709294                  0.649196   \n",
       "3                       1                  0.709294                  0.649196   \n",
       "4                       5                  0.614256                  0.568134   \n",
       "5                       6                  0.009783                  0.010482   \n",
       "6                       7                  0.000000                  0.000000   \n",
       "7                       7                  0.000000                  0.000000   \n",
       "8                       7                  0.000000                  0.000000   \n",
       "9                       7                  0.000000                  0.000000   \n",
       "10                      7                  0.000000                  0.000000   \n",
       "\n",
       "    split2_train_Sensitivity  split3_train_Sensitivity  \\\n",
       "0                   0.689029                  0.718379   \n",
       "1                   0.689029                  0.718379   \n",
       "2                   0.689029                  0.718379   \n",
       "3                   0.689029                  0.718379   \n",
       "4                   0.622642                  0.645003   \n",
       "5                   0.009085                  0.010482   \n",
       "6                   0.000000                  0.000000   \n",
       "7                   0.000000                  0.000000   \n",
       "8                   0.000000                  0.000000   \n",
       "9                   0.000000                  0.000000   \n",
       "10                  0.000000                  0.000000   \n",
       "\n",
       "    mean_train_Sensitivity  std_train_Sensitivity  \n",
       "0                 0.691474               0.026621  \n",
       "1                 0.691474               0.026621  \n",
       "2                 0.691474               0.026621  \n",
       "3                 0.691474               0.026621  \n",
       "4                 0.612509               0.027976  \n",
       "5                 0.009958               0.000579  \n",
       "6                 0.000000               0.000000  \n",
       "7                 0.000000               0.000000  \n",
       "8                 0.000000               0.000000  \n",
       "9                 0.000000               0.000000  \n",
       "10                0.000000               0.000000  \n",
       "\n",
       "[11 rows x 45 columns]"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_gnb = gs.cv_results_\n",
    "data = pandas.DataFrame(results_gnb)\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>params</th>\n",
       "      <th>mean_test_AUC</th>\n",
       "      <th>mean_test_F_score</th>\n",
       "      <th>mean_test_Sensitivity</th>\n",
       "      <th>rank_test_AUC</th>\n",
       "      <th>rank_test_F_score</th>\n",
       "      <th>rank_test_Sensitivity</th>\n",
       "      <th>mean_train_AUC</th>\n",
       "      <th>mean_train_F_score</th>\n",
       "      <th>mean_train_Sensitivity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.079499</td>\n",
       "      <td>{'gaussiannb__var_smoothing': 1e-10}</td>\n",
       "      <td>0.821454</td>\n",
       "      <td>0.495376</td>\n",
       "      <td>0.649351</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0.835938</td>\n",
       "      <td>0.516555</td>\n",
       "      <td>0.691474</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.062663</td>\n",
       "      <td>{'gaussiannb__var_smoothing': 1e-08}</td>\n",
       "      <td>0.821454</td>\n",
       "      <td>0.495376</td>\n",
       "      <td>0.649351</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0.835938</td>\n",
       "      <td>0.516555</td>\n",
       "      <td>0.691474</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.093762</td>\n",
       "      <td>{'gaussiannb__var_smoothing': 1e-06}</td>\n",
       "      <td>0.821454</td>\n",
       "      <td>0.495376</td>\n",
       "      <td>0.649351</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0.835938</td>\n",
       "      <td>0.516555</td>\n",
       "      <td>0.691474</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.121751</td>\n",
       "      <td>{'gaussiannb__var_smoothing': 0.0001}</td>\n",
       "      <td>0.821454</td>\n",
       "      <td>0.495452</td>\n",
       "      <td>0.649351</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.835938</td>\n",
       "      <td>0.516617</td>\n",
       "      <td>0.691474</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.124741</td>\n",
       "      <td>{'gaussiannb__var_smoothing': 0.1}</td>\n",
       "      <td>0.821353</td>\n",
       "      <td>0.484189</td>\n",
       "      <td>0.574929</td>\n",
       "      <td>11</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>0.834098</td>\n",
       "      <td>0.516355</td>\n",
       "      <td>0.612509</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.121096</td>\n",
       "      <td>{'gaussiannb__var_smoothing': 10}</td>\n",
       "      <td>0.841798</td>\n",
       "      <td>0.017491</td>\n",
       "      <td>0.008909</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>0.846939</td>\n",
       "      <td>0.019630</td>\n",
       "      <td>0.009958</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.097652</td>\n",
       "      <td>{'gaussiannb__var_smoothing': 100}</td>\n",
       "      <td>0.850063</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>0.854538</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.089851</td>\n",
       "      <td>{'gaussiannb__var_smoothing': 1000}</td>\n",
       "      <td>0.851124</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>0.855518</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.129291</td>\n",
       "      <td>{'gaussiannb__var_smoothing': 100000}</td>\n",
       "      <td>0.851236</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>0.855632</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.092042</td>\n",
       "      <td>{'gaussiannb__var_smoothing': 1000000}</td>\n",
       "      <td>0.851237</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>0.855633</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.144359</td>\n",
       "      <td>{'gaussiannb__var_smoothing': 100000000}</td>\n",
       "      <td>0.851237</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>0.855633</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    mean_fit_time                                    params  mean_test_AUC  \\\n",
       "0        0.079499      {'gaussiannb__var_smoothing': 1e-10}       0.821454   \n",
       "1        0.062663      {'gaussiannb__var_smoothing': 1e-08}       0.821454   \n",
       "2        0.093762      {'gaussiannb__var_smoothing': 1e-06}       0.821454   \n",
       "3        0.121751     {'gaussiannb__var_smoothing': 0.0001}       0.821454   \n",
       "4        0.124741        {'gaussiannb__var_smoothing': 0.1}       0.821353   \n",
       "5        0.121096         {'gaussiannb__var_smoothing': 10}       0.841798   \n",
       "6        0.097652        {'gaussiannb__var_smoothing': 100}       0.850063   \n",
       "7        0.089851       {'gaussiannb__var_smoothing': 1000}       0.851124   \n",
       "8        0.129291     {'gaussiannb__var_smoothing': 100000}       0.851236   \n",
       "9        0.092042    {'gaussiannb__var_smoothing': 1000000}       0.851237   \n",
       "10       0.144359  {'gaussiannb__var_smoothing': 100000000}       0.851237   \n",
       "\n",
       "    mean_test_F_score  mean_test_Sensitivity  rank_test_AUC  \\\n",
       "0            0.495376               0.649351              9   \n",
       "1            0.495376               0.649351              9   \n",
       "2            0.495376               0.649351              8   \n",
       "3            0.495452               0.649351              7   \n",
       "4            0.484189               0.574929             11   \n",
       "5            0.017491               0.008909              6   \n",
       "6            0.000000               0.000000              5   \n",
       "7            0.000000               0.000000              4   \n",
       "8            0.000000               0.000000              3   \n",
       "9            0.000000               0.000000              1   \n",
       "10           0.000000               0.000000              1   \n",
       "\n",
       "    rank_test_F_score  rank_test_Sensitivity  mean_train_AUC  \\\n",
       "0                   2                      1        0.835938   \n",
       "1                   2                      1        0.835938   \n",
       "2                   2                      1        0.835938   \n",
       "3                   1                      1        0.835938   \n",
       "4                   5                      5        0.834098   \n",
       "5                   6                      6        0.846939   \n",
       "6                   7                      7        0.854538   \n",
       "7                   7                      7        0.855518   \n",
       "8                   7                      7        0.855632   \n",
       "9                   7                      7        0.855633   \n",
       "10                  7                      7        0.855633   \n",
       "\n",
       "    mean_train_F_score  mean_train_Sensitivity  \n",
       "0             0.516555                0.691474  \n",
       "1             0.516555                0.691474  \n",
       "2             0.516555                0.691474  \n",
       "3             0.516617                0.691474  \n",
       "4             0.516355                0.612509  \n",
       "5             0.019630                0.009958  \n",
       "6             0.000000                0.000000  \n",
       "7             0.000000                0.000000  \n",
       "8             0.000000                0.000000  \n",
       "9             0.000000                0.000000  \n",
       "10            0.000000                0.000000  "
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "table_gnb = make_table(data)\n",
    "table_gnb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'gaussiannb__var_smoothing': 0.0001}"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 4 folds for each of 120 candidates, totalling 480 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   5 tasks      | elapsed:    0.6s\n",
      "[Parallel(n_jobs=-1)]: Done  10 tasks      | elapsed:    1.3s\n",
      "[Parallel(n_jobs=-1)]: Done  17 tasks      | elapsed:    3.1s\n",
      "[Parallel(n_jobs=-1)]: Done  24 tasks      | elapsed:    4.5s\n",
      "[Parallel(n_jobs=-1)]: Done  33 tasks      | elapsed:    8.5s\n",
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:   12.4s\n",
      "[Parallel(n_jobs=-1)]: Done  53 tasks      | elapsed:   15.8s\n",
      "[Parallel(n_jobs=-1)]: Done  64 tasks      | elapsed:   17.3s\n",
      "[Parallel(n_jobs=-1)]: Done  77 tasks      | elapsed:   22.3s\n",
      "[Parallel(n_jobs=-1)]: Done  90 tasks      | elapsed:   30.5s\n",
      "[Parallel(n_jobs=-1)]: Done 105 tasks      | elapsed:   35.6s\n",
      "[Parallel(n_jobs=-1)]: Done 120 tasks      | elapsed:   40.5s\n",
      "[Parallel(n_jobs=-1)]: Done 137 tasks      | elapsed:   49.4s\n",
      "[Parallel(n_jobs=-1)]: Done 154 tasks      | elapsed:   54.2s\n",
      "[Parallel(n_jobs=-1)]: Done 173 tasks      | elapsed:   59.7s\n",
      "[Parallel(n_jobs=-1)]: Done 192 tasks      | elapsed:  1.2min\n",
      "[Parallel(n_jobs=-1)]: Done 213 tasks      | elapsed:  1.2min\n",
      "[Parallel(n_jobs=-1)]: Done 234 tasks      | elapsed:  1.4min\n",
      "[Parallel(n_jobs=-1)]: Done 257 tasks      | elapsed:  1.5min\n",
      "[Parallel(n_jobs=-1)]: Done 280 tasks      | elapsed:  1.6min\n",
      "[Parallel(n_jobs=-1)]: Done 305 tasks      | elapsed:  1.8min\n",
      "[Parallel(n_jobs=-1)]: Done 330 tasks      | elapsed:  2.0min\n",
      "[Parallel(n_jobs=-1)]: Done 357 tasks      | elapsed:  2.2min\n",
      "[Parallel(n_jobs=-1)]: Done 384 tasks      | elapsed:  2.4min\n",
      "[Parallel(n_jobs=-1)]: Done 413 tasks      | elapsed:  2.6min\n",
      "[Parallel(n_jobs=-1)]: Done 442 tasks      | elapsed:  2.8min\n",
      "[Parallel(n_jobs=-1)]: Done 473 tasks      | elapsed:  3.1min\n",
      "[Parallel(n_jobs=-1)]: Done 480 out of 480 | elapsed:  3.1min finished\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "\n",
    "scoring = {'AUC': 'roc_auc', 'F-score': 'f1', 'Sensitivity': make_scorer(recall_score)} \n",
    "parameters = {\n",
    "    'adaboostclassifier__n_estimators': (3, 5, 10, 15, 20, 50),\n",
    "    'adaboostclassifier__learning_rate': (0.1, 0.15, 0.2, 0.25, 0.5),\n",
    "    'adaboostclassifier__algorithm': ('SAMME', 'SAMME.R'),\n",
    "    'adaboostclassifier__random_state': (0, 1)\n",
    "}\n",
    "\n",
    "pp = make_pipeline(StandardScaler(), AdaBoostClassifier())\n",
    "\n",
    "gs = GridSearchCV(pp, parameters, cv=skf, scoring=scoring, refit='F-score', return_train_score=True, n_jobs=-1, verbose=10) \n",
    "gs.fit(X, Y)\n",
    "results = gs.cv_results_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_adaboostclassifier__algorithm</th>\n",
       "      <th>param_adaboostclassifier__learning_rate</th>\n",
       "      <th>param_adaboostclassifier__n_estimators</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_AUC</th>\n",
       "      <th>split1_test_AUC</th>\n",
       "      <th>...</th>\n",
       "      <th>split3_test_Sensitivity</th>\n",
       "      <th>mean_test_Sensitivity</th>\n",
       "      <th>std_test_Sensitivity</th>\n",
       "      <th>rank_test_Sensitivity</th>\n",
       "      <th>split0_train_Sensitivity</th>\n",
       "      <th>split1_train_Sensitivity</th>\n",
       "      <th>split2_train_Sensitivity</th>\n",
       "      <th>split3_train_Sensitivity</th>\n",
       "      <th>mean_train_Sensitivity</th>\n",
       "      <th>std_train_Sensitivity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.210407</td>\n",
       "      <td>0.018926</td>\n",
       "      <td>0.112625</td>\n",
       "      <td>0.014590</td>\n",
       "      <td>SAMME</td>\n",
       "      <td>0.1</td>\n",
       "      <td>1</td>\n",
       "      <td>{'adaboostclassifier__algorithm': 'SAMME', 'ad...</td>\n",
       "      <td>0.962114</td>\n",
       "      <td>0.840824</td>\n",
       "      <td>...</td>\n",
       "      <td>0.651992</td>\n",
       "      <td>0.794567</td>\n",
       "      <td>0.129634</td>\n",
       "      <td>1</td>\n",
       "      <td>0.730957</td>\n",
       "      <td>0.794549</td>\n",
       "      <td>0.834382</td>\n",
       "      <td>0.836478</td>\n",
       "      <td>0.799092</td>\n",
       "      <td>0.042738</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.404845</td>\n",
       "      <td>0.065424</td>\n",
       "      <td>0.139534</td>\n",
       "      <td>0.019095</td>\n",
       "      <td>SAMME</td>\n",
       "      <td>0.1</td>\n",
       "      <td>5</td>\n",
       "      <td>{'adaboostclassifier__algorithm': 'SAMME', 'ad...</td>\n",
       "      <td>0.963083</td>\n",
       "      <td>0.856736</td>\n",
       "      <td>...</td>\n",
       "      <td>0.618449</td>\n",
       "      <td>0.768890</td>\n",
       "      <td>0.150175</td>\n",
       "      <td>11</td>\n",
       "      <td>0.730957</td>\n",
       "      <td>0.794549</td>\n",
       "      <td>0.785465</td>\n",
       "      <td>0.795947</td>\n",
       "      <td>0.776730</td>\n",
       "      <td>0.026731</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.408737</td>\n",
       "      <td>0.006303</td>\n",
       "      <td>0.109997</td>\n",
       "      <td>0.014295</td>\n",
       "      <td>SAMME</td>\n",
       "      <td>0.1</td>\n",
       "      <td>10</td>\n",
       "      <td>{'adaboostclassifier__algorithm': 'SAMME', 'ad...</td>\n",
       "      <td>0.969984</td>\n",
       "      <td>0.856736</td>\n",
       "      <td>...</td>\n",
       "      <td>0.618449</td>\n",
       "      <td>0.744252</td>\n",
       "      <td>0.114405</td>\n",
       "      <td>12</td>\n",
       "      <td>0.626136</td>\n",
       "      <td>0.794549</td>\n",
       "      <td>0.785465</td>\n",
       "      <td>0.795947</td>\n",
       "      <td>0.750524</td>\n",
       "      <td>0.071928</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.565251</td>\n",
       "      <td>0.023900</td>\n",
       "      <td>0.177492</td>\n",
       "      <td>0.049731</td>\n",
       "      <td>SAMME</td>\n",
       "      <td>0.1</td>\n",
       "      <td>15</td>\n",
       "      <td>{'adaboostclassifier__algorithm': 'SAMME', 'ad...</td>\n",
       "      <td>0.973825</td>\n",
       "      <td>0.860533</td>\n",
       "      <td>...</td>\n",
       "      <td>0.618449</td>\n",
       "      <td>0.671390</td>\n",
       "      <td>0.038123</td>\n",
       "      <td>17</td>\n",
       "      <td>0.511530</td>\n",
       "      <td>0.688330</td>\n",
       "      <td>0.785465</td>\n",
       "      <td>0.795947</td>\n",
       "      <td>0.695318</td>\n",
       "      <td>0.114104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.779069</td>\n",
       "      <td>0.051684</td>\n",
       "      <td>0.242261</td>\n",
       "      <td>0.075231</td>\n",
       "      <td>SAMME</td>\n",
       "      <td>0.1</td>\n",
       "      <td>20</td>\n",
       "      <td>{'adaboostclassifier__algorithm': 'SAMME', 'ad...</td>\n",
       "      <td>0.973825</td>\n",
       "      <td>0.860533</td>\n",
       "      <td>...</td>\n",
       "      <td>0.618449</td>\n",
       "      <td>0.465390</td>\n",
       "      <td>0.275031</td>\n",
       "      <td>25</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.688330</td>\n",
       "      <td>0.676450</td>\n",
       "      <td>0.771488</td>\n",
       "      <td>0.534067</td>\n",
       "      <td>0.310510</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2.144364</td>\n",
       "      <td>0.112788</td>\n",
       "      <td>0.614523</td>\n",
       "      <td>0.056231</td>\n",
       "      <td>SAMME</td>\n",
       "      <td>0.1</td>\n",
       "      <td>50</td>\n",
       "      <td>{'adaboostclassifier__algorithm': 'SAMME', 'ad...</td>\n",
       "      <td>0.974442</td>\n",
       "      <td>0.891596</td>\n",
       "      <td>...</td>\n",
       "      <td>0.618449</td>\n",
       "      <td>0.418204</td>\n",
       "      <td>0.259764</td>\n",
       "      <td>51</td>\n",
       "      <td>0.378057</td>\n",
       "      <td>0.522013</td>\n",
       "      <td>0.632425</td>\n",
       "      <td>0.569532</td>\n",
       "      <td>0.525507</td>\n",
       "      <td>0.093706</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.191374</td>\n",
       "      <td>0.065781</td>\n",
       "      <td>0.134287</td>\n",
       "      <td>0.025834</td>\n",
       "      <td>SAMME</td>\n",
       "      <td>0.25</td>\n",
       "      <td>1</td>\n",
       "      <td>{'adaboostclassifier__algorithm': 'SAMME', 'ad...</td>\n",
       "      <td>0.962114</td>\n",
       "      <td>0.840824</td>\n",
       "      <td>...</td>\n",
       "      <td>0.651992</td>\n",
       "      <td>0.794567</td>\n",
       "      <td>0.129634</td>\n",
       "      <td>1</td>\n",
       "      <td>0.730957</td>\n",
       "      <td>0.794549</td>\n",
       "      <td>0.834382</td>\n",
       "      <td>0.836478</td>\n",
       "      <td>0.799092</td>\n",
       "      <td>0.042738</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.460502</td>\n",
       "      <td>0.091289</td>\n",
       "      <td>0.139001</td>\n",
       "      <td>0.040580</td>\n",
       "      <td>SAMME</td>\n",
       "      <td>0.25</td>\n",
       "      <td>5</td>\n",
       "      <td>{'adaboostclassifier__algorithm': 'SAMME', 'ad...</td>\n",
       "      <td>0.972798</td>\n",
       "      <td>0.856736</td>\n",
       "      <td>...</td>\n",
       "      <td>0.563941</td>\n",
       "      <td>0.629468</td>\n",
       "      <td>0.078629</td>\n",
       "      <td>18</td>\n",
       "      <td>0.511530</td>\n",
       "      <td>0.688330</td>\n",
       "      <td>0.676450</td>\n",
       "      <td>0.735849</td>\n",
       "      <td>0.653040</td>\n",
       "      <td>0.084670</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.486754</td>\n",
       "      <td>0.073828</td>\n",
       "      <td>0.111512</td>\n",
       "      <td>0.022059</td>\n",
       "      <td>SAMME</td>\n",
       "      <td>0.25</td>\n",
       "      <td>10</td>\n",
       "      <td>{'adaboostclassifier__algorithm': 'SAMME', 'ad...</td>\n",
       "      <td>0.972798</td>\n",
       "      <td>0.869455</td>\n",
       "      <td>...</td>\n",
       "      <td>0.563941</td>\n",
       "      <td>0.451766</td>\n",
       "      <td>0.268381</td>\n",
       "      <td>28</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.688330</td>\n",
       "      <td>0.676450</td>\n",
       "      <td>0.735849</td>\n",
       "      <td>0.525157</td>\n",
       "      <td>0.304013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.561256</td>\n",
       "      <td>0.044249</td>\n",
       "      <td>0.145256</td>\n",
       "      <td>0.016949</td>\n",
       "      <td>SAMME</td>\n",
       "      <td>0.25</td>\n",
       "      <td>15</td>\n",
       "      <td>{'adaboostclassifier__algorithm': 'SAMME', 'ad...</td>\n",
       "      <td>0.972798</td>\n",
       "      <td>0.883423</td>\n",
       "      <td>...</td>\n",
       "      <td>0.651992</td>\n",
       "      <td>0.491064</td>\n",
       "      <td>0.283567</td>\n",
       "      <td>23</td>\n",
       "      <td>0.453529</td>\n",
       "      <td>0.676450</td>\n",
       "      <td>0.740741</td>\n",
       "      <td>0.628931</td>\n",
       "      <td>0.624913</td>\n",
       "      <td>0.106608</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.777015</td>\n",
       "      <td>0.047181</td>\n",
       "      <td>0.184585</td>\n",
       "      <td>0.028691</td>\n",
       "      <td>SAMME</td>\n",
       "      <td>0.25</td>\n",
       "      <td>20</td>\n",
       "      <td>{'adaboostclassifier__algorithm': 'SAMME', 'ad...</td>\n",
       "      <td>0.972798</td>\n",
       "      <td>0.890068</td>\n",
       "      <td>...</td>\n",
       "      <td>0.563941</td>\n",
       "      <td>0.403007</td>\n",
       "      <td>0.248610</td>\n",
       "      <td>56</td>\n",
       "      <td>0.464011</td>\n",
       "      <td>0.522711</td>\n",
       "      <td>0.712788</td>\n",
       "      <td>0.586303</td>\n",
       "      <td>0.571454</td>\n",
       "      <td>0.092352</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1.944576</td>\n",
       "      <td>0.086465</td>\n",
       "      <td>0.573593</td>\n",
       "      <td>0.069418</td>\n",
       "      <td>SAMME</td>\n",
       "      <td>0.25</td>\n",
       "      <td>50</td>\n",
       "      <td>{'adaboostclassifier__algorithm': 'SAMME', 'ad...</td>\n",
       "      <td>0.976654</td>\n",
       "      <td>0.889185</td>\n",
       "      <td>...</td>\n",
       "      <td>0.651992</td>\n",
       "      <td>0.433400</td>\n",
       "      <td>0.274128</td>\n",
       "      <td>40</td>\n",
       "      <td>0.461216</td>\n",
       "      <td>0.519916</td>\n",
       "      <td>0.659679</td>\n",
       "      <td>0.589099</td>\n",
       "      <td>0.557477</td>\n",
       "      <td>0.074367</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.187849</td>\n",
       "      <td>0.008862</td>\n",
       "      <td>0.107593</td>\n",
       "      <td>0.010260</td>\n",
       "      <td>SAMME</td>\n",
       "      <td>0.15</td>\n",
       "      <td>1</td>\n",
       "      <td>{'adaboostclassifier__algorithm': 'SAMME', 'ad...</td>\n",
       "      <td>0.962114</td>\n",
       "      <td>0.840824</td>\n",
       "      <td>...</td>\n",
       "      <td>0.651992</td>\n",
       "      <td>0.794567</td>\n",
       "      <td>0.129634</td>\n",
       "      <td>1</td>\n",
       "      <td>0.730957</td>\n",
       "      <td>0.794549</td>\n",
       "      <td>0.834382</td>\n",
       "      <td>0.836478</td>\n",
       "      <td>0.799092</td>\n",
       "      <td>0.042738</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.329682</td>\n",
       "      <td>0.013742</td>\n",
       "      <td>0.094034</td>\n",
       "      <td>0.013848</td>\n",
       "      <td>SAMME</td>\n",
       "      <td>0.15</td>\n",
       "      <td>5</td>\n",
       "      <td>{'adaboostclassifier__algorithm': 'SAMME', 'ad...</td>\n",
       "      <td>0.969984</td>\n",
       "      <td>0.856730</td>\n",
       "      <td>...</td>\n",
       "      <td>0.618449</td>\n",
       "      <td>0.744252</td>\n",
       "      <td>0.114405</td>\n",
       "      <td>12</td>\n",
       "      <td>0.626136</td>\n",
       "      <td>0.794549</td>\n",
       "      <td>0.785465</td>\n",
       "      <td>0.795947</td>\n",
       "      <td>0.750524</td>\n",
       "      <td>0.071928</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.404792</td>\n",
       "      <td>0.044303</td>\n",
       "      <td>0.109746</td>\n",
       "      <td>0.020164</td>\n",
       "      <td>SAMME</td>\n",
       "      <td>0.15</td>\n",
       "      <td>10</td>\n",
       "      <td>{'adaboostclassifier__algorithm': 'SAMME', 'ad...</td>\n",
       "      <td>0.969984</td>\n",
       "      <td>0.856730</td>\n",
       "      <td>...</td>\n",
       "      <td>0.618449</td>\n",
       "      <td>0.744252</td>\n",
       "      <td>0.114405</td>\n",
       "      <td>12</td>\n",
       "      <td>0.626136</td>\n",
       "      <td>0.794549</td>\n",
       "      <td>0.785465</td>\n",
       "      <td>0.795947</td>\n",
       "      <td>0.750524</td>\n",
       "      <td>0.071928</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.608753</td>\n",
       "      <td>0.047765</td>\n",
       "      <td>0.192562</td>\n",
       "      <td>0.050896</td>\n",
       "      <td>SAMME</td>\n",
       "      <td>0.15</td>\n",
       "      <td>15</td>\n",
       "      <td>{'adaboostclassifier__algorithm': 'SAMME', 'ad...</td>\n",
       "      <td>0.969984</td>\n",
       "      <td>0.874492</td>\n",
       "      <td>...</td>\n",
       "      <td>0.618449</td>\n",
       "      <td>0.493688</td>\n",
       "      <td>0.286703</td>\n",
       "      <td>22</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.688330</td>\n",
       "      <td>0.734451</td>\n",
       "      <td>0.731656</td>\n",
       "      <td>0.538609</td>\n",
       "      <td>0.311503</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>1.189356</td>\n",
       "      <td>0.061035</td>\n",
       "      <td>0.253480</td>\n",
       "      <td>0.063318</td>\n",
       "      <td>SAMME</td>\n",
       "      <td>0.15</td>\n",
       "      <td>20</td>\n",
       "      <td>{'adaboostclassifier__algorithm': 'SAMME', 'ad...</td>\n",
       "      <td>0.969984</td>\n",
       "      <td>0.874492</td>\n",
       "      <td>...</td>\n",
       "      <td>0.618449</td>\n",
       "      <td>0.473244</td>\n",
       "      <td>0.273563</td>\n",
       "      <td>24</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.634521</td>\n",
       "      <td>0.734451</td>\n",
       "      <td>0.731656</td>\n",
       "      <td>0.525157</td>\n",
       "      <td>0.305858</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>2.157015</td>\n",
       "      <td>0.024652</td>\n",
       "      <td>0.604048</td>\n",
       "      <td>0.092277</td>\n",
       "      <td>SAMME</td>\n",
       "      <td>0.15</td>\n",
       "      <td>50</td>\n",
       "      <td>{'adaboostclassifier__algorithm': 'SAMME', 'ad...</td>\n",
       "      <td>0.974272</td>\n",
       "      <td>0.892974</td>\n",
       "      <td>...</td>\n",
       "      <td>0.618449</td>\n",
       "      <td>0.349534</td>\n",
       "      <td>0.289439</td>\n",
       "      <td>58</td>\n",
       "      <td>0.378057</td>\n",
       "      <td>0.358491</td>\n",
       "      <td>0.567435</td>\n",
       "      <td>0.566737</td>\n",
       "      <td>0.467680</td>\n",
       "      <td>0.099647</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.162862</td>\n",
       "      <td>0.027440</td>\n",
       "      <td>0.096542</td>\n",
       "      <td>0.009529</td>\n",
       "      <td>SAMME</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1</td>\n",
       "      <td>{'adaboostclassifier__algorithm': 'SAMME', 'ad...</td>\n",
       "      <td>0.962114</td>\n",
       "      <td>0.840824</td>\n",
       "      <td>...</td>\n",
       "      <td>0.651992</td>\n",
       "      <td>0.794567</td>\n",
       "      <td>0.129634</td>\n",
       "      <td>1</td>\n",
       "      <td>0.730957</td>\n",
       "      <td>0.794549</td>\n",
       "      <td>0.834382</td>\n",
       "      <td>0.836478</td>\n",
       "      <td>0.799092</td>\n",
       "      <td>0.042738</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.638915</td>\n",
       "      <td>0.030541</td>\n",
       "      <td>0.188142</td>\n",
       "      <td>0.019033</td>\n",
       "      <td>SAMME</td>\n",
       "      <td>0.5</td>\n",
       "      <td>5</td>\n",
       "      <td>{'adaboostclassifier__algorithm': 'SAMME', 'ad...</td>\n",
       "      <td>0.971828</td>\n",
       "      <td>0.864266</td>\n",
       "      <td>...</td>\n",
       "      <td>0.536688</td>\n",
       "      <td>0.618463</td>\n",
       "      <td>0.089277</td>\n",
       "      <td>19</td>\n",
       "      <td>0.511530</td>\n",
       "      <td>0.688330</td>\n",
       "      <td>0.665968</td>\n",
       "      <td>0.702306</td>\n",
       "      <td>0.642034</td>\n",
       "      <td>0.076453</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.998192</td>\n",
       "      <td>0.115942</td>\n",
       "      <td>0.227374</td>\n",
       "      <td>0.032912</td>\n",
       "      <td>SAMME</td>\n",
       "      <td>0.5</td>\n",
       "      <td>10</td>\n",
       "      <td>{'adaboostclassifier__algorithm': 'SAMME', 'ad...</td>\n",
       "      <td>0.971828</td>\n",
       "      <td>0.883483</td>\n",
       "      <td>...</td>\n",
       "      <td>0.651992</td>\n",
       "      <td>0.505737</td>\n",
       "      <td>0.292880</td>\n",
       "      <td>20</td>\n",
       "      <td>0.464011</td>\n",
       "      <td>0.676450</td>\n",
       "      <td>0.735849</td>\n",
       "      <td>0.570231</td>\n",
       "      <td>0.611635</td>\n",
       "      <td>0.103848</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.595501</td>\n",
       "      <td>0.029263</td>\n",
       "      <td>0.153684</td>\n",
       "      <td>0.017427</td>\n",
       "      <td>SAMME</td>\n",
       "      <td>0.5</td>\n",
       "      <td>15</td>\n",
       "      <td>{'adaboostclassifier__algorithm': 'SAMME', 'ad...</td>\n",
       "      <td>0.972755</td>\n",
       "      <td>0.886054</td>\n",
       "      <td>...</td>\n",
       "      <td>0.651992</td>\n",
       "      <td>0.364207</td>\n",
       "      <td>0.302884</td>\n",
       "      <td>57</td>\n",
       "      <td>0.463312</td>\n",
       "      <td>0.359189</td>\n",
       "      <td>0.589099</td>\n",
       "      <td>0.569532</td>\n",
       "      <td>0.495283</td>\n",
       "      <td>0.092002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>1.244599</td>\n",
       "      <td>0.057319</td>\n",
       "      <td>0.202678</td>\n",
       "      <td>0.044130</td>\n",
       "      <td>SAMME</td>\n",
       "      <td>0.5</td>\n",
       "      <td>20</td>\n",
       "      <td>{'adaboostclassifier__algorithm': 'SAMME', 'ad...</td>\n",
       "      <td>0.973333</td>\n",
       "      <td>0.886228</td>\n",
       "      <td>...</td>\n",
       "      <td>0.651992</td>\n",
       "      <td>0.404046</td>\n",
       "      <td>0.278992</td>\n",
       "      <td>55</td>\n",
       "      <td>0.464011</td>\n",
       "      <td>0.464011</td>\n",
       "      <td>0.589099</td>\n",
       "      <td>0.599581</td>\n",
       "      <td>0.529175</td>\n",
       "      <td>0.065270</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>2.983380</td>\n",
       "      <td>0.118194</td>\n",
       "      <td>0.822055</td>\n",
       "      <td>0.062292</td>\n",
       "      <td>SAMME</td>\n",
       "      <td>0.5</td>\n",
       "      <td>50</td>\n",
       "      <td>{'adaboostclassifier__algorithm': 'SAMME', 'ad...</td>\n",
       "      <td>0.977512</td>\n",
       "      <td>0.893482</td>\n",
       "      <td>...</td>\n",
       "      <td>0.651992</td>\n",
       "      <td>0.430255</td>\n",
       "      <td>0.272358</td>\n",
       "      <td>45</td>\n",
       "      <td>0.519217</td>\n",
       "      <td>0.549266</td>\n",
       "      <td>0.618449</td>\n",
       "      <td>0.598882</td>\n",
       "      <td>0.571454</td>\n",
       "      <td>0.039312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.310666</td>\n",
       "      <td>0.135606</td>\n",
       "      <td>0.288018</td>\n",
       "      <td>0.068520</td>\n",
       "      <td>SAMME</td>\n",
       "      <td>0.6</td>\n",
       "      <td>1</td>\n",
       "      <td>{'adaboostclassifier__algorithm': 'SAMME', 'ad...</td>\n",
       "      <td>0.962114</td>\n",
       "      <td>0.840824</td>\n",
       "      <td>...</td>\n",
       "      <td>0.651992</td>\n",
       "      <td>0.794567</td>\n",
       "      <td>0.129634</td>\n",
       "      <td>1</td>\n",
       "      <td>0.730957</td>\n",
       "      <td>0.794549</td>\n",
       "      <td>0.834382</td>\n",
       "      <td>0.836478</td>\n",
       "      <td>0.799092</td>\n",
       "      <td>0.042738</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>1.064104</td>\n",
       "      <td>0.114123</td>\n",
       "      <td>0.158516</td>\n",
       "      <td>0.044381</td>\n",
       "      <td>SAMME</td>\n",
       "      <td>0.6</td>\n",
       "      <td>5</td>\n",
       "      <td>{'adaboostclassifier__algorithm': 'SAMME', 'ad...</td>\n",
       "      <td>0.962114</td>\n",
       "      <td>0.867079</td>\n",
       "      <td>...</td>\n",
       "      <td>0.651992</td>\n",
       "      <td>0.457003</td>\n",
       "      <td>0.270338</td>\n",
       "      <td>27</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.640811</td>\n",
       "      <td>0.651293</td>\n",
       "      <td>0.740042</td>\n",
       "      <td>0.508036</td>\n",
       "      <td>0.295837</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0.631202</td>\n",
       "      <td>0.077608</td>\n",
       "      <td>0.269771</td>\n",
       "      <td>0.037901</td>\n",
       "      <td>SAMME</td>\n",
       "      <td>0.6</td>\n",
       "      <td>10</td>\n",
       "      <td>{'adaboostclassifier__algorithm': 'SAMME', 'ad...</td>\n",
       "      <td>0.971898</td>\n",
       "      <td>0.885620</td>\n",
       "      <td>...</td>\n",
       "      <td>0.651992</td>\n",
       "      <td>0.496825</td>\n",
       "      <td>0.288877</td>\n",
       "      <td>21</td>\n",
       "      <td>0.385744</td>\n",
       "      <td>0.629630</td>\n",
       "      <td>0.733753</td>\n",
       "      <td>0.726765</td>\n",
       "      <td>0.618973</td>\n",
       "      <td>0.140804</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0.915525</td>\n",
       "      <td>0.104474</td>\n",
       "      <td>0.190173</td>\n",
       "      <td>0.015110</td>\n",
       "      <td>SAMME</td>\n",
       "      <td>0.6</td>\n",
       "      <td>15</td>\n",
       "      <td>{'adaboostclassifier__algorithm': 'SAMME', 'ad...</td>\n",
       "      <td>0.971899</td>\n",
       "      <td>0.889817</td>\n",
       "      <td>...</td>\n",
       "      <td>0.651992</td>\n",
       "      <td>0.432352</td>\n",
       "      <td>0.274276</td>\n",
       "      <td>42</td>\n",
       "      <td>0.385744</td>\n",
       "      <td>0.493361</td>\n",
       "      <td>0.515723</td>\n",
       "      <td>0.675751</td>\n",
       "      <td>0.517645</td>\n",
       "      <td>0.103669</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0.710747</td>\n",
       "      <td>0.040957</td>\n",
       "      <td>0.185510</td>\n",
       "      <td>0.027291</td>\n",
       "      <td>SAMME</td>\n",
       "      <td>0.6</td>\n",
       "      <td>20</td>\n",
       "      <td>{'adaboostclassifier__algorithm': 'SAMME', 'ad...</td>\n",
       "      <td>0.973974</td>\n",
       "      <td>0.884765</td>\n",
       "      <td>...</td>\n",
       "      <td>0.651992</td>\n",
       "      <td>0.438118</td>\n",
       "      <td>0.273609</td>\n",
       "      <td>38</td>\n",
       "      <td>0.549965</td>\n",
       "      <td>0.583508</td>\n",
       "      <td>0.624039</td>\n",
       "      <td>0.581412</td>\n",
       "      <td>0.584731</td>\n",
       "      <td>0.026298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>1.534826</td>\n",
       "      <td>0.085667</td>\n",
       "      <td>0.360747</td>\n",
       "      <td>0.030111</td>\n",
       "      <td>SAMME</td>\n",
       "      <td>0.6</td>\n",
       "      <td>50</td>\n",
       "      <td>{'adaboostclassifier__algorithm': 'SAMME', 'ad...</td>\n",
       "      <td>0.976205</td>\n",
       "      <td>0.895205</td>\n",
       "      <td>...</td>\n",
       "      <td>0.649895</td>\n",
       "      <td>0.451223</td>\n",
       "      <td>0.273098</td>\n",
       "      <td>30</td>\n",
       "      <td>0.569532</td>\n",
       "      <td>0.611461</td>\n",
       "      <td>0.625437</td>\n",
       "      <td>0.629630</td>\n",
       "      <td>0.609015</td>\n",
       "      <td>0.023767</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>0.155387</td>\n",
       "      <td>0.061356</td>\n",
       "      <td>0.132540</td>\n",
       "      <td>0.038589</td>\n",
       "      <td>SAMME.R</td>\n",
       "      <td>0.1</td>\n",
       "      <td>1</td>\n",
       "      <td>{'adaboostclassifier__algorithm': 'SAMME.R', '...</td>\n",
       "      <td>0.962114</td>\n",
       "      <td>0.840824</td>\n",
       "      <td>...</td>\n",
       "      <td>0.651992</td>\n",
       "      <td>0.794567</td>\n",
       "      <td>0.129634</td>\n",
       "      <td>1</td>\n",
       "      <td>0.730957</td>\n",
       "      <td>0.794549</td>\n",
       "      <td>0.834382</td>\n",
       "      <td>0.836478</td>\n",
       "      <td>0.799092</td>\n",
       "      <td>0.042738</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>0.455081</td>\n",
       "      <td>0.069888</td>\n",
       "      <td>0.130576</td>\n",
       "      <td>0.014335</td>\n",
       "      <td>SAMME.R</td>\n",
       "      <td>0.1</td>\n",
       "      <td>5</td>\n",
       "      <td>{'adaboostclassifier__algorithm': 'SAMME.R', '...</td>\n",
       "      <td>0.969984</td>\n",
       "      <td>0.845985</td>\n",
       "      <td>...</td>\n",
       "      <td>0.618449</td>\n",
       "      <td>0.744252</td>\n",
       "      <td>0.114405</td>\n",
       "      <td>12</td>\n",
       "      <td>0.626136</td>\n",
       "      <td>0.793850</td>\n",
       "      <td>0.785465</td>\n",
       "      <td>0.795947</td>\n",
       "      <td>0.750349</td>\n",
       "      <td>0.071822</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>0.480885</td>\n",
       "      <td>0.036657</td>\n",
       "      <td>0.124496</td>\n",
       "      <td>0.008953</td>\n",
       "      <td>SAMME.R</td>\n",
       "      <td>0.1</td>\n",
       "      <td>10</td>\n",
       "      <td>{'adaboostclassifier__algorithm': 'SAMME.R', '...</td>\n",
       "      <td>0.973825</td>\n",
       "      <td>0.856730</td>\n",
       "      <td>...</td>\n",
       "      <td>0.563941</td>\n",
       "      <td>0.451766</td>\n",
       "      <td>0.268381</td>\n",
       "      <td>28</td>\n",
       "      <td>0.453529</td>\n",
       "      <td>0.688330</td>\n",
       "      <td>0.676450</td>\n",
       "      <td>0.735849</td>\n",
       "      <td>0.638539</td>\n",
       "      <td>0.109104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>0.849989</td>\n",
       "      <td>0.045569</td>\n",
       "      <td>0.189895</td>\n",
       "      <td>0.043158</td>\n",
       "      <td>SAMME.R</td>\n",
       "      <td>0.1</td>\n",
       "      <td>15</td>\n",
       "      <td>{'adaboostclassifier__algorithm': 'SAMME.R', '...</td>\n",
       "      <td>0.974442</td>\n",
       "      <td>0.872700</td>\n",
       "      <td>...</td>\n",
       "      <td>0.563941</td>\n",
       "      <td>0.443903</td>\n",
       "      <td>0.261230</td>\n",
       "      <td>33</td>\n",
       "      <td>0.453529</td>\n",
       "      <td>0.670161</td>\n",
       "      <td>0.670161</td>\n",
       "      <td>0.696017</td>\n",
       "      <td>0.622467</td>\n",
       "      <td>0.098106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>0.931538</td>\n",
       "      <td>0.029684</td>\n",
       "      <td>0.271930</td>\n",
       "      <td>0.072328</td>\n",
       "      <td>SAMME.R</td>\n",
       "      <td>0.1</td>\n",
       "      <td>20</td>\n",
       "      <td>{'adaboostclassifier__algorithm': 'SAMME.R', '...</td>\n",
       "      <td>0.974728</td>\n",
       "      <td>0.888520</td>\n",
       "      <td>...</td>\n",
       "      <td>0.563941</td>\n",
       "      <td>0.308137</td>\n",
       "      <td>0.247651</td>\n",
       "      <td>60</td>\n",
       "      <td>0.453529</td>\n",
       "      <td>0.359189</td>\n",
       "      <td>0.608665</td>\n",
       "      <td>0.645003</td>\n",
       "      <td>0.516597</td>\n",
       "      <td>0.115887</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>1.963384</td>\n",
       "      <td>0.102696</td>\n",
       "      <td>0.429840</td>\n",
       "      <td>0.017631</td>\n",
       "      <td>SAMME.R</td>\n",
       "      <td>0.1</td>\n",
       "      <td>50</td>\n",
       "      <td>{'adaboostclassifier__algorithm': 'SAMME.R', '...</td>\n",
       "      <td>0.977611</td>\n",
       "      <td>0.894340</td>\n",
       "      <td>...</td>\n",
       "      <td>0.649895</td>\n",
       "      <td>0.415057</td>\n",
       "      <td>0.263386</td>\n",
       "      <td>53</td>\n",
       "      <td>0.456324</td>\n",
       "      <td>0.516422</td>\n",
       "      <td>0.584906</td>\n",
       "      <td>0.575821</td>\n",
       "      <td>0.533368</td>\n",
       "      <td>0.051675</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>0.109503</td>\n",
       "      <td>0.017384</td>\n",
       "      <td>0.066498</td>\n",
       "      <td>0.012660</td>\n",
       "      <td>SAMME.R</td>\n",
       "      <td>0.25</td>\n",
       "      <td>1</td>\n",
       "      <td>{'adaboostclassifier__algorithm': 'SAMME.R', '...</td>\n",
       "      <td>0.962114</td>\n",
       "      <td>0.840824</td>\n",
       "      <td>...</td>\n",
       "      <td>0.651992</td>\n",
       "      <td>0.794567</td>\n",
       "      <td>0.129634</td>\n",
       "      <td>1</td>\n",
       "      <td>0.730957</td>\n",
       "      <td>0.794549</td>\n",
       "      <td>0.834382</td>\n",
       "      <td>0.836478</td>\n",
       "      <td>0.799092</td>\n",
       "      <td>0.042738</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>0.252502</td>\n",
       "      <td>0.034972</td>\n",
       "      <td>0.100998</td>\n",
       "      <td>0.023683</td>\n",
       "      <td>SAMME.R</td>\n",
       "      <td>0.25</td>\n",
       "      <td>5</td>\n",
       "      <td>{'adaboostclassifier__algorithm': 'SAMME.R', '...</td>\n",
       "      <td>0.970175</td>\n",
       "      <td>0.856736</td>\n",
       "      <td>...</td>\n",
       "      <td>0.563941</td>\n",
       "      <td>0.447574</td>\n",
       "      <td>0.267117</td>\n",
       "      <td>31</td>\n",
       "      <td>0.556953</td>\n",
       "      <td>0.688330</td>\n",
       "      <td>0.665968</td>\n",
       "      <td>0.368973</td>\n",
       "      <td>0.570056</td>\n",
       "      <td>0.126287</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>0.392494</td>\n",
       "      <td>0.029964</td>\n",
       "      <td>0.111503</td>\n",
       "      <td>0.004503</td>\n",
       "      <td>SAMME.R</td>\n",
       "      <td>0.25</td>\n",
       "      <td>10</td>\n",
       "      <td>{'adaboostclassifier__algorithm': 'SAMME.R', '...</td>\n",
       "      <td>0.974354</td>\n",
       "      <td>0.887944</td>\n",
       "      <td>...</td>\n",
       "      <td>0.563941</td>\n",
       "      <td>0.335910</td>\n",
       "      <td>0.277497</td>\n",
       "      <td>59</td>\n",
       "      <td>0.378057</td>\n",
       "      <td>0.358491</td>\n",
       "      <td>0.640811</td>\n",
       "      <td>0.586303</td>\n",
       "      <td>0.490915</td>\n",
       "      <td>0.124339</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>0.568995</td>\n",
       "      <td>0.016180</td>\n",
       "      <td>0.157502</td>\n",
       "      <td>0.014876</td>\n",
       "      <td>SAMME.R</td>\n",
       "      <td>0.25</td>\n",
       "      <td>15</td>\n",
       "      <td>{'adaboostclassifier__algorithm': 'SAMME.R', '...</td>\n",
       "      <td>0.975790</td>\n",
       "      <td>0.891107</td>\n",
       "      <td>...</td>\n",
       "      <td>0.649895</td>\n",
       "      <td>0.422395</td>\n",
       "      <td>0.266503</td>\n",
       "      <td>48</td>\n",
       "      <td>0.515723</td>\n",
       "      <td>0.515024</td>\n",
       "      <td>0.629630</td>\n",
       "      <td>0.603075</td>\n",
       "      <td>0.565863</td>\n",
       "      <td>0.051355</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>0.714894</td>\n",
       "      <td>0.024069</td>\n",
       "      <td>0.188138</td>\n",
       "      <td>0.022854</td>\n",
       "      <td>SAMME.R</td>\n",
       "      <td>0.25</td>\n",
       "      <td>20</td>\n",
       "      <td>{'adaboostclassifier__algorithm': 'SAMME.R', '...</td>\n",
       "      <td>0.976842</td>\n",
       "      <td>0.894262</td>\n",
       "      <td>...</td>\n",
       "      <td>0.649895</td>\n",
       "      <td>0.420824</td>\n",
       "      <td>0.262703</td>\n",
       "      <td>49</td>\n",
       "      <td>0.505241</td>\n",
       "      <td>0.522013</td>\n",
       "      <td>0.587701</td>\n",
       "      <td>0.582809</td>\n",
       "      <td>0.549441</td>\n",
       "      <td>0.036343</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>1.652345</td>\n",
       "      <td>0.019460</td>\n",
       "      <td>0.422789</td>\n",
       "      <td>0.030085</td>\n",
       "      <td>SAMME.R</td>\n",
       "      <td>0.25</td>\n",
       "      <td>50</td>\n",
       "      <td>{'adaboostclassifier__algorithm': 'SAMME.R', '...</td>\n",
       "      <td>0.978649</td>\n",
       "      <td>0.896150</td>\n",
       "      <td>...</td>\n",
       "      <td>0.647799</td>\n",
       "      <td>0.431829</td>\n",
       "      <td>0.270662</td>\n",
       "      <td>43</td>\n",
       "      <td>0.545073</td>\n",
       "      <td>0.575122</td>\n",
       "      <td>0.616352</td>\n",
       "      <td>0.598882</td>\n",
       "      <td>0.583857</td>\n",
       "      <td>0.026750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>0.102884</td>\n",
       "      <td>0.010459</td>\n",
       "      <td>0.058641</td>\n",
       "      <td>0.005467</td>\n",
       "      <td>SAMME.R</td>\n",
       "      <td>0.15</td>\n",
       "      <td>1</td>\n",
       "      <td>{'adaboostclassifier__algorithm': 'SAMME.R', '...</td>\n",
       "      <td>0.962114</td>\n",
       "      <td>0.840824</td>\n",
       "      <td>...</td>\n",
       "      <td>0.651992</td>\n",
       "      <td>0.794567</td>\n",
       "      <td>0.129634</td>\n",
       "      <td>1</td>\n",
       "      <td>0.730957</td>\n",
       "      <td>0.794549</td>\n",
       "      <td>0.834382</td>\n",
       "      <td>0.836478</td>\n",
       "      <td>0.799092</td>\n",
       "      <td>0.042738</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>0.266515</td>\n",
       "      <td>0.030403</td>\n",
       "      <td>0.086737</td>\n",
       "      <td>0.019105</td>\n",
       "      <td>SAMME.R</td>\n",
       "      <td>0.15</td>\n",
       "      <td>5</td>\n",
       "      <td>{'adaboostclassifier__algorithm': 'SAMME.R', '...</td>\n",
       "      <td>0.969984</td>\n",
       "      <td>0.856730</td>\n",
       "      <td>...</td>\n",
       "      <td>0.563941</td>\n",
       "      <td>0.676645</td>\n",
       "      <td>0.143255</td>\n",
       "      <td>16</td>\n",
       "      <td>0.626136</td>\n",
       "      <td>0.688330</td>\n",
       "      <td>0.676450</td>\n",
       "      <td>0.735849</td>\n",
       "      <td>0.681691</td>\n",
       "      <td>0.039023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>0.412500</td>\n",
       "      <td>0.043724</td>\n",
       "      <td>0.119499</td>\n",
       "      <td>0.008355</td>\n",
       "      <td>SAMME.R</td>\n",
       "      <td>0.15</td>\n",
       "      <td>10</td>\n",
       "      <td>{'adaboostclassifier__algorithm': 'SAMME.R', '...</td>\n",
       "      <td>0.974442</td>\n",
       "      <td>0.872033</td>\n",
       "      <td>...</td>\n",
       "      <td>0.563941</td>\n",
       "      <td>0.443903</td>\n",
       "      <td>0.261230</td>\n",
       "      <td>33</td>\n",
       "      <td>0.453529</td>\n",
       "      <td>0.670161</td>\n",
       "      <td>0.662474</td>\n",
       "      <td>0.677848</td>\n",
       "      <td>0.616003</td>\n",
       "      <td>0.093962</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>0.693139</td>\n",
       "      <td>0.077243</td>\n",
       "      <td>0.201024</td>\n",
       "      <td>0.025816</td>\n",
       "      <td>SAMME.R</td>\n",
       "      <td>0.15</td>\n",
       "      <td>15</td>\n",
       "      <td>{'adaboostclassifier__algorithm': 'SAMME.R', '...</td>\n",
       "      <td>0.974856</td>\n",
       "      <td>0.891693</td>\n",
       "      <td>...</td>\n",
       "      <td>0.618449</td>\n",
       "      <td>0.418204</td>\n",
       "      <td>0.259764</td>\n",
       "      <td>51</td>\n",
       "      <td>0.447939</td>\n",
       "      <td>0.522013</td>\n",
       "      <td>0.640811</td>\n",
       "      <td>0.605171</td>\n",
       "      <td>0.553983</td>\n",
       "      <td>0.074878</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>0.920443</td>\n",
       "      <td>0.023301</td>\n",
       "      <td>0.269053</td>\n",
       "      <td>0.049839</td>\n",
       "      <td>SAMME.R</td>\n",
       "      <td>0.15</td>\n",
       "      <td>20</td>\n",
       "      <td>{'adaboostclassifier__algorithm': 'SAMME.R', '...</td>\n",
       "      <td>0.975259</td>\n",
       "      <td>0.890351</td>\n",
       "      <td>...</td>\n",
       "      <td>0.618449</td>\n",
       "      <td>0.412962</td>\n",
       "      <td>0.258638</td>\n",
       "      <td>54</td>\n",
       "      <td>0.450734</td>\n",
       "      <td>0.512229</td>\n",
       "      <td>0.562544</td>\n",
       "      <td>0.567435</td>\n",
       "      <td>0.523235</td>\n",
       "      <td>0.047107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>1.990230</td>\n",
       "      <td>0.070840</td>\n",
       "      <td>0.554399</td>\n",
       "      <td>0.052743</td>\n",
       "      <td>SAMME.R</td>\n",
       "      <td>0.15</td>\n",
       "      <td>50</td>\n",
       "      <td>{'adaboostclassifier__algorithm': 'SAMME.R', '...</td>\n",
       "      <td>0.977559</td>\n",
       "      <td>0.895089</td>\n",
       "      <td>...</td>\n",
       "      <td>0.645702</td>\n",
       "      <td>0.433925</td>\n",
       "      <td>0.273179</td>\n",
       "      <td>39</td>\n",
       "      <td>0.505940</td>\n",
       "      <td>0.570231</td>\n",
       "      <td>0.615653</td>\n",
       "      <td>0.592593</td>\n",
       "      <td>0.571104</td>\n",
       "      <td>0.040907</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>0.194256</td>\n",
       "      <td>0.028557</td>\n",
       "      <td>0.160503</td>\n",
       "      <td>0.018033</td>\n",
       "      <td>SAMME.R</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1</td>\n",
       "      <td>{'adaboostclassifier__algorithm': 'SAMME.R', '...</td>\n",
       "      <td>0.962114</td>\n",
       "      <td>0.840824</td>\n",
       "      <td>...</td>\n",
       "      <td>0.651992</td>\n",
       "      <td>0.794567</td>\n",
       "      <td>0.129634</td>\n",
       "      <td>1</td>\n",
       "      <td>0.730957</td>\n",
       "      <td>0.794549</td>\n",
       "      <td>0.834382</td>\n",
       "      <td>0.836478</td>\n",
       "      <td>0.799092</td>\n",
       "      <td>0.042738</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>0.403752</td>\n",
       "      <td>0.007891</td>\n",
       "      <td>0.096746</td>\n",
       "      <td>0.012193</td>\n",
       "      <td>SAMME.R</td>\n",
       "      <td>0.5</td>\n",
       "      <td>5</td>\n",
       "      <td>{'adaboostclassifier__algorithm': 'SAMME.R', '...</td>\n",
       "      <td>0.973654</td>\n",
       "      <td>0.880422</td>\n",
       "      <td>...</td>\n",
       "      <td>0.651992</td>\n",
       "      <td>0.462767</td>\n",
       "      <td>0.271488</td>\n",
       "      <td>26</td>\n",
       "      <td>0.475891</td>\n",
       "      <td>0.676450</td>\n",
       "      <td>0.343117</td>\n",
       "      <td>0.401817</td>\n",
       "      <td>0.474319</td>\n",
       "      <td>0.125827</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>0.731514</td>\n",
       "      <td>0.024804</td>\n",
       "      <td>0.264629</td>\n",
       "      <td>0.020530</td>\n",
       "      <td>SAMME.R</td>\n",
       "      <td>0.5</td>\n",
       "      <td>10</td>\n",
       "      <td>{'adaboostclassifier__algorithm': 'SAMME.R', '...</td>\n",
       "      <td>0.976835</td>\n",
       "      <td>0.890688</td>\n",
       "      <td>...</td>\n",
       "      <td>0.643606</td>\n",
       "      <td>0.430256</td>\n",
       "      <td>0.270415</td>\n",
       "      <td>44</td>\n",
       "      <td>0.471698</td>\n",
       "      <td>0.522013</td>\n",
       "      <td>0.587002</td>\n",
       "      <td>0.577219</td>\n",
       "      <td>0.539483</td>\n",
       "      <td>0.046320</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>0.704511</td>\n",
       "      <td>0.059470</td>\n",
       "      <td>0.226007</td>\n",
       "      <td>0.024174</td>\n",
       "      <td>SAMME.R</td>\n",
       "      <td>0.5</td>\n",
       "      <td>15</td>\n",
       "      <td>{'adaboostclassifier__algorithm': 'SAMME.R', '...</td>\n",
       "      <td>0.978102</td>\n",
       "      <td>0.895239</td>\n",
       "      <td>...</td>\n",
       "      <td>0.645702</td>\n",
       "      <td>0.432877</td>\n",
       "      <td>0.270619</td>\n",
       "      <td>41</td>\n",
       "      <td>0.514326</td>\n",
       "      <td>0.577219</td>\n",
       "      <td>0.617750</td>\n",
       "      <td>0.605870</td>\n",
       "      <td>0.578791</td>\n",
       "      <td>0.040029</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>1.044506</td>\n",
       "      <td>0.042670</td>\n",
       "      <td>0.214015</td>\n",
       "      <td>0.022289</td>\n",
       "      <td>SAMME.R</td>\n",
       "      <td>0.5</td>\n",
       "      <td>20</td>\n",
       "      <td>{'adaboostclassifier__algorithm': 'SAMME.R', '...</td>\n",
       "      <td>0.978090</td>\n",
       "      <td>0.894200</td>\n",
       "      <td>...</td>\n",
       "      <td>0.647799</td>\n",
       "      <td>0.442836</td>\n",
       "      <td>0.271576</td>\n",
       "      <td>36</td>\n",
       "      <td>0.568134</td>\n",
       "      <td>0.583508</td>\n",
       "      <td>0.624738</td>\n",
       "      <td>0.595388</td>\n",
       "      <td>0.592942</td>\n",
       "      <td>0.020745</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>1.689334</td>\n",
       "      <td>0.017014</td>\n",
       "      <td>0.531815</td>\n",
       "      <td>0.099948</td>\n",
       "      <td>SAMME.R</td>\n",
       "      <td>0.5</td>\n",
       "      <td>50</td>\n",
       "      <td>{'adaboostclassifier__algorithm': 'SAMME.R', '...</td>\n",
       "      <td>0.978817</td>\n",
       "      <td>0.844669</td>\n",
       "      <td>...</td>\n",
       "      <td>0.645702</td>\n",
       "      <td>0.419772</td>\n",
       "      <td>0.273348</td>\n",
       "      <td>50</td>\n",
       "      <td>0.559050</td>\n",
       "      <td>0.579315</td>\n",
       "      <td>0.619846</td>\n",
       "      <td>0.605870</td>\n",
       "      <td>0.591020</td>\n",
       "      <td>0.023508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>0.187504</td>\n",
       "      <td>0.048296</td>\n",
       "      <td>0.098253</td>\n",
       "      <td>0.019961</td>\n",
       "      <td>SAMME.R</td>\n",
       "      <td>0.6</td>\n",
       "      <td>1</td>\n",
       "      <td>{'adaboostclassifier__algorithm': 'SAMME.R', '...</td>\n",
       "      <td>0.962114</td>\n",
       "      <td>0.840824</td>\n",
       "      <td>...</td>\n",
       "      <td>0.651992</td>\n",
       "      <td>0.794567</td>\n",
       "      <td>0.129634</td>\n",
       "      <td>1</td>\n",
       "      <td>0.730957</td>\n",
       "      <td>0.794549</td>\n",
       "      <td>0.834382</td>\n",
       "      <td>0.836478</td>\n",
       "      <td>0.799092</td>\n",
       "      <td>0.042738</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>0.497763</td>\n",
       "      <td>0.076810</td>\n",
       "      <td>0.225125</td>\n",
       "      <td>0.031804</td>\n",
       "      <td>SAMME.R</td>\n",
       "      <td>0.6</td>\n",
       "      <td>5</td>\n",
       "      <td>{'adaboostclassifier__algorithm': 'SAMME.R', '...</td>\n",
       "      <td>0.973331</td>\n",
       "      <td>0.883682</td>\n",
       "      <td>...</td>\n",
       "      <td>0.651992</td>\n",
       "      <td>0.441784</td>\n",
       "      <td>0.282711</td>\n",
       "      <td>37</td>\n",
       "      <td>0.441649</td>\n",
       "      <td>0.519217</td>\n",
       "      <td>0.443047</td>\n",
       "      <td>0.394130</td>\n",
       "      <td>0.449511</td>\n",
       "      <td>0.044804</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>0.618909</td>\n",
       "      <td>0.074037</td>\n",
       "      <td>0.191763</td>\n",
       "      <td>0.071316</td>\n",
       "      <td>SAMME.R</td>\n",
       "      <td>0.6</td>\n",
       "      <td>10</td>\n",
       "      <td>{'adaboostclassifier__algorithm': 'SAMME.R', '...</td>\n",
       "      <td>0.975662</td>\n",
       "      <td>0.897291</td>\n",
       "      <td>...</td>\n",
       "      <td>0.651992</td>\n",
       "      <td>0.447554</td>\n",
       "      <td>0.272425</td>\n",
       "      <td>32</td>\n",
       "      <td>0.452131</td>\n",
       "      <td>0.548567</td>\n",
       "      <td>0.616352</td>\n",
       "      <td>0.589099</td>\n",
       "      <td>0.551537</td>\n",
       "      <td>0.062254</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>0.939167</td>\n",
       "      <td>0.021592</td>\n",
       "      <td>0.183633</td>\n",
       "      <td>0.020714</td>\n",
       "      <td>SAMME.R</td>\n",
       "      <td>0.6</td>\n",
       "      <td>15</td>\n",
       "      <td>{'adaboostclassifier__algorithm': 'SAMME.R', '...</td>\n",
       "      <td>0.977151</td>\n",
       "      <td>0.893342</td>\n",
       "      <td>...</td>\n",
       "      <td>0.645702</td>\n",
       "      <td>0.428159</td>\n",
       "      <td>0.270610</td>\n",
       "      <td>46</td>\n",
       "      <td>0.563242</td>\n",
       "      <td>0.543676</td>\n",
       "      <td>0.623340</td>\n",
       "      <td>0.601677</td>\n",
       "      <td>0.582984</td>\n",
       "      <td>0.031277</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>0.881235</td>\n",
       "      <td>0.046780</td>\n",
       "      <td>0.216769</td>\n",
       "      <td>0.018212</td>\n",
       "      <td>SAMME.R</td>\n",
       "      <td>0.6</td>\n",
       "      <td>20</td>\n",
       "      <td>{'adaboostclassifier__algorithm': 'SAMME.R', '...</td>\n",
       "      <td>0.978039</td>\n",
       "      <td>0.892346</td>\n",
       "      <td>...</td>\n",
       "      <td>0.647799</td>\n",
       "      <td>0.443884</td>\n",
       "      <td>0.272501</td>\n",
       "      <td>35</td>\n",
       "      <td>0.563242</td>\n",
       "      <td>0.575821</td>\n",
       "      <td>0.625437</td>\n",
       "      <td>0.596785</td>\n",
       "      <td>0.590321</td>\n",
       "      <td>0.023550</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>1.650498</td>\n",
       "      <td>0.018553</td>\n",
       "      <td>0.499992</td>\n",
       "      <td>0.057973</td>\n",
       "      <td>SAMME.R</td>\n",
       "      <td>0.6</td>\n",
       "      <td>50</td>\n",
       "      <td>{'adaboostclassifier__algorithm': 'SAMME.R', '...</td>\n",
       "      <td>0.977825</td>\n",
       "      <td>0.830322</td>\n",
       "      <td>...</td>\n",
       "      <td>0.645702</td>\n",
       "      <td>0.423967</td>\n",
       "      <td>0.267522</td>\n",
       "      <td>47</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>0.595388</td>\n",
       "      <td>0.626136</td>\n",
       "      <td>0.610762</td>\n",
       "      <td>0.596960</td>\n",
       "      <td>0.026261</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>60 rows × 47 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "0        0.210407      0.018926         0.112625        0.014590   \n",
       "1        0.404845      0.065424         0.139534        0.019095   \n",
       "2        0.408737      0.006303         0.109997        0.014295   \n",
       "3        0.565251      0.023900         0.177492        0.049731   \n",
       "4        0.779069      0.051684         0.242261        0.075231   \n",
       "5        2.144364      0.112788         0.614523        0.056231   \n",
       "6        0.191374      0.065781         0.134287        0.025834   \n",
       "7        0.460502      0.091289         0.139001        0.040580   \n",
       "8        0.486754      0.073828         0.111512        0.022059   \n",
       "9        0.561256      0.044249         0.145256        0.016949   \n",
       "10       0.777015      0.047181         0.184585        0.028691   \n",
       "11       1.944576      0.086465         0.573593        0.069418   \n",
       "12       0.187849      0.008862         0.107593        0.010260   \n",
       "13       0.329682      0.013742         0.094034        0.013848   \n",
       "14       0.404792      0.044303         0.109746        0.020164   \n",
       "15       0.608753      0.047765         0.192562        0.050896   \n",
       "16       1.189356      0.061035         0.253480        0.063318   \n",
       "17       2.157015      0.024652         0.604048        0.092277   \n",
       "18       0.162862      0.027440         0.096542        0.009529   \n",
       "19       0.638915      0.030541         0.188142        0.019033   \n",
       "20       0.998192      0.115942         0.227374        0.032912   \n",
       "21       0.595501      0.029263         0.153684        0.017427   \n",
       "22       1.244599      0.057319         0.202678        0.044130   \n",
       "23       2.983380      0.118194         0.822055        0.062292   \n",
       "24       0.310666      0.135606         0.288018        0.068520   \n",
       "25       1.064104      0.114123         0.158516        0.044381   \n",
       "26       0.631202      0.077608         0.269771        0.037901   \n",
       "27       0.915525      0.104474         0.190173        0.015110   \n",
       "28       0.710747      0.040957         0.185510        0.027291   \n",
       "29       1.534826      0.085667         0.360747        0.030111   \n",
       "30       0.155387      0.061356         0.132540        0.038589   \n",
       "31       0.455081      0.069888         0.130576        0.014335   \n",
       "32       0.480885      0.036657         0.124496        0.008953   \n",
       "33       0.849989      0.045569         0.189895        0.043158   \n",
       "34       0.931538      0.029684         0.271930        0.072328   \n",
       "35       1.963384      0.102696         0.429840        0.017631   \n",
       "36       0.109503      0.017384         0.066498        0.012660   \n",
       "37       0.252502      0.034972         0.100998        0.023683   \n",
       "38       0.392494      0.029964         0.111503        0.004503   \n",
       "39       0.568995      0.016180         0.157502        0.014876   \n",
       "40       0.714894      0.024069         0.188138        0.022854   \n",
       "41       1.652345      0.019460         0.422789        0.030085   \n",
       "42       0.102884      0.010459         0.058641        0.005467   \n",
       "43       0.266515      0.030403         0.086737        0.019105   \n",
       "44       0.412500      0.043724         0.119499        0.008355   \n",
       "45       0.693139      0.077243         0.201024        0.025816   \n",
       "46       0.920443      0.023301         0.269053        0.049839   \n",
       "47       1.990230      0.070840         0.554399        0.052743   \n",
       "48       0.194256      0.028557         0.160503        0.018033   \n",
       "49       0.403752      0.007891         0.096746        0.012193   \n",
       "50       0.731514      0.024804         0.264629        0.020530   \n",
       "51       0.704511      0.059470         0.226007        0.024174   \n",
       "52       1.044506      0.042670         0.214015        0.022289   \n",
       "53       1.689334      0.017014         0.531815        0.099948   \n",
       "54       0.187504      0.048296         0.098253        0.019961   \n",
       "55       0.497763      0.076810         0.225125        0.031804   \n",
       "56       0.618909      0.074037         0.191763        0.071316   \n",
       "57       0.939167      0.021592         0.183633        0.020714   \n",
       "58       0.881235      0.046780         0.216769        0.018212   \n",
       "59       1.650498      0.018553         0.499992        0.057973   \n",
       "\n",
       "   param_adaboostclassifier__algorithm  \\\n",
       "0                                SAMME   \n",
       "1                                SAMME   \n",
       "2                                SAMME   \n",
       "3                                SAMME   \n",
       "4                                SAMME   \n",
       "5                                SAMME   \n",
       "6                                SAMME   \n",
       "7                                SAMME   \n",
       "8                                SAMME   \n",
       "9                                SAMME   \n",
       "10                               SAMME   \n",
       "11                               SAMME   \n",
       "12                               SAMME   \n",
       "13                               SAMME   \n",
       "14                               SAMME   \n",
       "15                               SAMME   \n",
       "16                               SAMME   \n",
       "17                               SAMME   \n",
       "18                               SAMME   \n",
       "19                               SAMME   \n",
       "20                               SAMME   \n",
       "21                               SAMME   \n",
       "22                               SAMME   \n",
       "23                               SAMME   \n",
       "24                               SAMME   \n",
       "25                               SAMME   \n",
       "26                               SAMME   \n",
       "27                               SAMME   \n",
       "28                               SAMME   \n",
       "29                               SAMME   \n",
       "30                             SAMME.R   \n",
       "31                             SAMME.R   \n",
       "32                             SAMME.R   \n",
       "33                             SAMME.R   \n",
       "34                             SAMME.R   \n",
       "35                             SAMME.R   \n",
       "36                             SAMME.R   \n",
       "37                             SAMME.R   \n",
       "38                             SAMME.R   \n",
       "39                             SAMME.R   \n",
       "40                             SAMME.R   \n",
       "41                             SAMME.R   \n",
       "42                             SAMME.R   \n",
       "43                             SAMME.R   \n",
       "44                             SAMME.R   \n",
       "45                             SAMME.R   \n",
       "46                             SAMME.R   \n",
       "47                             SAMME.R   \n",
       "48                             SAMME.R   \n",
       "49                             SAMME.R   \n",
       "50                             SAMME.R   \n",
       "51                             SAMME.R   \n",
       "52                             SAMME.R   \n",
       "53                             SAMME.R   \n",
       "54                             SAMME.R   \n",
       "55                             SAMME.R   \n",
       "56                             SAMME.R   \n",
       "57                             SAMME.R   \n",
       "58                             SAMME.R   \n",
       "59                             SAMME.R   \n",
       "\n",
       "   param_adaboostclassifier__learning_rate  \\\n",
       "0                                      0.1   \n",
       "1                                      0.1   \n",
       "2                                      0.1   \n",
       "3                                      0.1   \n",
       "4                                      0.1   \n",
       "5                                      0.1   \n",
       "6                                     0.25   \n",
       "7                                     0.25   \n",
       "8                                     0.25   \n",
       "9                                     0.25   \n",
       "10                                    0.25   \n",
       "11                                    0.25   \n",
       "12                                    0.15   \n",
       "13                                    0.15   \n",
       "14                                    0.15   \n",
       "15                                    0.15   \n",
       "16                                    0.15   \n",
       "17                                    0.15   \n",
       "18                                     0.5   \n",
       "19                                     0.5   \n",
       "20                                     0.5   \n",
       "21                                     0.5   \n",
       "22                                     0.5   \n",
       "23                                     0.5   \n",
       "24                                     0.6   \n",
       "25                                     0.6   \n",
       "26                                     0.6   \n",
       "27                                     0.6   \n",
       "28                                     0.6   \n",
       "29                                     0.6   \n",
       "30                                     0.1   \n",
       "31                                     0.1   \n",
       "32                                     0.1   \n",
       "33                                     0.1   \n",
       "34                                     0.1   \n",
       "35                                     0.1   \n",
       "36                                    0.25   \n",
       "37                                    0.25   \n",
       "38                                    0.25   \n",
       "39                                    0.25   \n",
       "40                                    0.25   \n",
       "41                                    0.25   \n",
       "42                                    0.15   \n",
       "43                                    0.15   \n",
       "44                                    0.15   \n",
       "45                                    0.15   \n",
       "46                                    0.15   \n",
       "47                                    0.15   \n",
       "48                                     0.5   \n",
       "49                                     0.5   \n",
       "50                                     0.5   \n",
       "51                                     0.5   \n",
       "52                                     0.5   \n",
       "53                                     0.5   \n",
       "54                                     0.6   \n",
       "55                                     0.6   \n",
       "56                                     0.6   \n",
       "57                                     0.6   \n",
       "58                                     0.6   \n",
       "59                                     0.6   \n",
       "\n",
       "   param_adaboostclassifier__n_estimators  \\\n",
       "0                                       1   \n",
       "1                                       5   \n",
       "2                                      10   \n",
       "3                                      15   \n",
       "4                                      20   \n",
       "5                                      50   \n",
       "6                                       1   \n",
       "7                                       5   \n",
       "8                                      10   \n",
       "9                                      15   \n",
       "10                                     20   \n",
       "11                                     50   \n",
       "12                                      1   \n",
       "13                                      5   \n",
       "14                                     10   \n",
       "15                                     15   \n",
       "16                                     20   \n",
       "17                                     50   \n",
       "18                                      1   \n",
       "19                                      5   \n",
       "20                                     10   \n",
       "21                                     15   \n",
       "22                                     20   \n",
       "23                                     50   \n",
       "24                                      1   \n",
       "25                                      5   \n",
       "26                                     10   \n",
       "27                                     15   \n",
       "28                                     20   \n",
       "29                                     50   \n",
       "30                                      1   \n",
       "31                                      5   \n",
       "32                                     10   \n",
       "33                                     15   \n",
       "34                                     20   \n",
       "35                                     50   \n",
       "36                                      1   \n",
       "37                                      5   \n",
       "38                                     10   \n",
       "39                                     15   \n",
       "40                                     20   \n",
       "41                                     50   \n",
       "42                                      1   \n",
       "43                                      5   \n",
       "44                                     10   \n",
       "45                                     15   \n",
       "46                                     20   \n",
       "47                                     50   \n",
       "48                                      1   \n",
       "49                                      5   \n",
       "50                                     10   \n",
       "51                                     15   \n",
       "52                                     20   \n",
       "53                                     50   \n",
       "54                                      1   \n",
       "55                                      5   \n",
       "56                                     10   \n",
       "57                                     15   \n",
       "58                                     20   \n",
       "59                                     50   \n",
       "\n",
       "                                               params  split0_test_AUC  \\\n",
       "0   {'adaboostclassifier__algorithm': 'SAMME', 'ad...         0.962114   \n",
       "1   {'adaboostclassifier__algorithm': 'SAMME', 'ad...         0.963083   \n",
       "2   {'adaboostclassifier__algorithm': 'SAMME', 'ad...         0.969984   \n",
       "3   {'adaboostclassifier__algorithm': 'SAMME', 'ad...         0.973825   \n",
       "4   {'adaboostclassifier__algorithm': 'SAMME', 'ad...         0.973825   \n",
       "5   {'adaboostclassifier__algorithm': 'SAMME', 'ad...         0.974442   \n",
       "6   {'adaboostclassifier__algorithm': 'SAMME', 'ad...         0.962114   \n",
       "7   {'adaboostclassifier__algorithm': 'SAMME', 'ad...         0.972798   \n",
       "8   {'adaboostclassifier__algorithm': 'SAMME', 'ad...         0.972798   \n",
       "9   {'adaboostclassifier__algorithm': 'SAMME', 'ad...         0.972798   \n",
       "10  {'adaboostclassifier__algorithm': 'SAMME', 'ad...         0.972798   \n",
       "11  {'adaboostclassifier__algorithm': 'SAMME', 'ad...         0.976654   \n",
       "12  {'adaboostclassifier__algorithm': 'SAMME', 'ad...         0.962114   \n",
       "13  {'adaboostclassifier__algorithm': 'SAMME', 'ad...         0.969984   \n",
       "14  {'adaboostclassifier__algorithm': 'SAMME', 'ad...         0.969984   \n",
       "15  {'adaboostclassifier__algorithm': 'SAMME', 'ad...         0.969984   \n",
       "16  {'adaboostclassifier__algorithm': 'SAMME', 'ad...         0.969984   \n",
       "17  {'adaboostclassifier__algorithm': 'SAMME', 'ad...         0.974272   \n",
       "18  {'adaboostclassifier__algorithm': 'SAMME', 'ad...         0.962114   \n",
       "19  {'adaboostclassifier__algorithm': 'SAMME', 'ad...         0.971828   \n",
       "20  {'adaboostclassifier__algorithm': 'SAMME', 'ad...         0.971828   \n",
       "21  {'adaboostclassifier__algorithm': 'SAMME', 'ad...         0.972755   \n",
       "22  {'adaboostclassifier__algorithm': 'SAMME', 'ad...         0.973333   \n",
       "23  {'adaboostclassifier__algorithm': 'SAMME', 'ad...         0.977512   \n",
       "24  {'adaboostclassifier__algorithm': 'SAMME', 'ad...         0.962114   \n",
       "25  {'adaboostclassifier__algorithm': 'SAMME', 'ad...         0.962114   \n",
       "26  {'adaboostclassifier__algorithm': 'SAMME', 'ad...         0.971898   \n",
       "27  {'adaboostclassifier__algorithm': 'SAMME', 'ad...         0.971899   \n",
       "28  {'adaboostclassifier__algorithm': 'SAMME', 'ad...         0.973974   \n",
       "29  {'adaboostclassifier__algorithm': 'SAMME', 'ad...         0.976205   \n",
       "30  {'adaboostclassifier__algorithm': 'SAMME.R', '...         0.962114   \n",
       "31  {'adaboostclassifier__algorithm': 'SAMME.R', '...         0.969984   \n",
       "32  {'adaboostclassifier__algorithm': 'SAMME.R', '...         0.973825   \n",
       "33  {'adaboostclassifier__algorithm': 'SAMME.R', '...         0.974442   \n",
       "34  {'adaboostclassifier__algorithm': 'SAMME.R', '...         0.974728   \n",
       "35  {'adaboostclassifier__algorithm': 'SAMME.R', '...         0.977611   \n",
       "36  {'adaboostclassifier__algorithm': 'SAMME.R', '...         0.962114   \n",
       "37  {'adaboostclassifier__algorithm': 'SAMME.R', '...         0.970175   \n",
       "38  {'adaboostclassifier__algorithm': 'SAMME.R', '...         0.974354   \n",
       "39  {'adaboostclassifier__algorithm': 'SAMME.R', '...         0.975790   \n",
       "40  {'adaboostclassifier__algorithm': 'SAMME.R', '...         0.976842   \n",
       "41  {'adaboostclassifier__algorithm': 'SAMME.R', '...         0.978649   \n",
       "42  {'adaboostclassifier__algorithm': 'SAMME.R', '...         0.962114   \n",
       "43  {'adaboostclassifier__algorithm': 'SAMME.R', '...         0.969984   \n",
       "44  {'adaboostclassifier__algorithm': 'SAMME.R', '...         0.974442   \n",
       "45  {'adaboostclassifier__algorithm': 'SAMME.R', '...         0.974856   \n",
       "46  {'adaboostclassifier__algorithm': 'SAMME.R', '...         0.975259   \n",
       "47  {'adaboostclassifier__algorithm': 'SAMME.R', '...         0.977559   \n",
       "48  {'adaboostclassifier__algorithm': 'SAMME.R', '...         0.962114   \n",
       "49  {'adaboostclassifier__algorithm': 'SAMME.R', '...         0.973654   \n",
       "50  {'adaboostclassifier__algorithm': 'SAMME.R', '...         0.976835   \n",
       "51  {'adaboostclassifier__algorithm': 'SAMME.R', '...         0.978102   \n",
       "52  {'adaboostclassifier__algorithm': 'SAMME.R', '...         0.978090   \n",
       "53  {'adaboostclassifier__algorithm': 'SAMME.R', '...         0.978817   \n",
       "54  {'adaboostclassifier__algorithm': 'SAMME.R', '...         0.962114   \n",
       "55  {'adaboostclassifier__algorithm': 'SAMME.R', '...         0.973331   \n",
       "56  {'adaboostclassifier__algorithm': 'SAMME.R', '...         0.975662   \n",
       "57  {'adaboostclassifier__algorithm': 'SAMME.R', '...         0.977151   \n",
       "58  {'adaboostclassifier__algorithm': 'SAMME.R', '...         0.978039   \n",
       "59  {'adaboostclassifier__algorithm': 'SAMME.R', '...         0.977825   \n",
       "\n",
       "    split1_test_AUC  ...  split3_test_Sensitivity  mean_test_Sensitivity  \\\n",
       "0          0.840824  ...                 0.651992               0.794567   \n",
       "1          0.856736  ...                 0.618449               0.768890   \n",
       "2          0.856736  ...                 0.618449               0.744252   \n",
       "3          0.860533  ...                 0.618449               0.671390   \n",
       "4          0.860533  ...                 0.618449               0.465390   \n",
       "5          0.891596  ...                 0.618449               0.418204   \n",
       "6          0.840824  ...                 0.651992               0.794567   \n",
       "7          0.856736  ...                 0.563941               0.629468   \n",
       "8          0.869455  ...                 0.563941               0.451766   \n",
       "9          0.883423  ...                 0.651992               0.491064   \n",
       "10         0.890068  ...                 0.563941               0.403007   \n",
       "11         0.889185  ...                 0.651992               0.433400   \n",
       "12         0.840824  ...                 0.651992               0.794567   \n",
       "13         0.856730  ...                 0.618449               0.744252   \n",
       "14         0.856730  ...                 0.618449               0.744252   \n",
       "15         0.874492  ...                 0.618449               0.493688   \n",
       "16         0.874492  ...                 0.618449               0.473244   \n",
       "17         0.892974  ...                 0.618449               0.349534   \n",
       "18         0.840824  ...                 0.651992               0.794567   \n",
       "19         0.864266  ...                 0.536688               0.618463   \n",
       "20         0.883483  ...                 0.651992               0.505737   \n",
       "21         0.886054  ...                 0.651992               0.364207   \n",
       "22         0.886228  ...                 0.651992               0.404046   \n",
       "23         0.893482  ...                 0.651992               0.430255   \n",
       "24         0.840824  ...                 0.651992               0.794567   \n",
       "25         0.867079  ...                 0.651992               0.457003   \n",
       "26         0.885620  ...                 0.651992               0.496825   \n",
       "27         0.889817  ...                 0.651992               0.432352   \n",
       "28         0.884765  ...                 0.651992               0.438118   \n",
       "29         0.895205  ...                 0.649895               0.451223   \n",
       "30         0.840824  ...                 0.651992               0.794567   \n",
       "31         0.845985  ...                 0.618449               0.744252   \n",
       "32         0.856730  ...                 0.563941               0.451766   \n",
       "33         0.872700  ...                 0.563941               0.443903   \n",
       "34         0.888520  ...                 0.563941               0.308137   \n",
       "35         0.894340  ...                 0.649895               0.415057   \n",
       "36         0.840824  ...                 0.651992               0.794567   \n",
       "37         0.856736  ...                 0.563941               0.447574   \n",
       "38         0.887944  ...                 0.563941               0.335910   \n",
       "39         0.891107  ...                 0.649895               0.422395   \n",
       "40         0.894262  ...                 0.649895               0.420824   \n",
       "41         0.896150  ...                 0.647799               0.431829   \n",
       "42         0.840824  ...                 0.651992               0.794567   \n",
       "43         0.856730  ...                 0.563941               0.676645   \n",
       "44         0.872033  ...                 0.563941               0.443903   \n",
       "45         0.891693  ...                 0.618449               0.418204   \n",
       "46         0.890351  ...                 0.618449               0.412962   \n",
       "47         0.895089  ...                 0.645702               0.433925   \n",
       "48         0.840824  ...                 0.651992               0.794567   \n",
       "49         0.880422  ...                 0.651992               0.462767   \n",
       "50         0.890688  ...                 0.643606               0.430256   \n",
       "51         0.895239  ...                 0.645702               0.432877   \n",
       "52         0.894200  ...                 0.647799               0.442836   \n",
       "53         0.844669  ...                 0.645702               0.419772   \n",
       "54         0.840824  ...                 0.651992               0.794567   \n",
       "55         0.883682  ...                 0.651992               0.441784   \n",
       "56         0.897291  ...                 0.651992               0.447554   \n",
       "57         0.893342  ...                 0.645702               0.428159   \n",
       "58         0.892346  ...                 0.647799               0.443884   \n",
       "59         0.830322  ...                 0.645702               0.423967   \n",
       "\n",
       "    std_test_Sensitivity  rank_test_Sensitivity  split0_train_Sensitivity  \\\n",
       "0               0.129634                      1                  0.730957   \n",
       "1               0.150175                     11                  0.730957   \n",
       "2               0.114405                     12                  0.626136   \n",
       "3               0.038123                     17                  0.511530   \n",
       "4               0.275031                     25                  0.000000   \n",
       "5               0.259764                     51                  0.378057   \n",
       "6               0.129634                      1                  0.730957   \n",
       "7               0.078629                     18                  0.511530   \n",
       "8               0.268381                     28                  0.000000   \n",
       "9               0.283567                     23                  0.453529   \n",
       "10              0.248610                     56                  0.464011   \n",
       "11              0.274128                     40                  0.461216   \n",
       "12              0.129634                      1                  0.730957   \n",
       "13              0.114405                     12                  0.626136   \n",
       "14              0.114405                     12                  0.626136   \n",
       "15              0.286703                     22                  0.000000   \n",
       "16              0.273563                     24                  0.000000   \n",
       "17              0.289439                     58                  0.378057   \n",
       "18              0.129634                      1                  0.730957   \n",
       "19              0.089277                     19                  0.511530   \n",
       "20              0.292880                     20                  0.464011   \n",
       "21              0.302884                     57                  0.463312   \n",
       "22              0.278992                     55                  0.464011   \n",
       "23              0.272358                     45                  0.519217   \n",
       "24              0.129634                      1                  0.730957   \n",
       "25              0.270338                     27                  0.000000   \n",
       "26              0.288877                     21                  0.385744   \n",
       "27              0.274276                     42                  0.385744   \n",
       "28              0.273609                     38                  0.549965   \n",
       "29              0.273098                     30                  0.569532   \n",
       "30              0.129634                      1                  0.730957   \n",
       "31              0.114405                     12                  0.626136   \n",
       "32              0.268381                     28                  0.453529   \n",
       "33              0.261230                     33                  0.453529   \n",
       "34              0.247651                     60                  0.453529   \n",
       "35              0.263386                     53                  0.456324   \n",
       "36              0.129634                      1                  0.730957   \n",
       "37              0.267117                     31                  0.556953   \n",
       "38              0.277497                     59                  0.378057   \n",
       "39              0.266503                     48                  0.515723   \n",
       "40              0.262703                     49                  0.505241   \n",
       "41              0.270662                     43                  0.545073   \n",
       "42              0.129634                      1                  0.730957   \n",
       "43              0.143255                     16                  0.626136   \n",
       "44              0.261230                     33                  0.453529   \n",
       "45              0.259764                     51                  0.447939   \n",
       "46              0.258638                     54                  0.450734   \n",
       "47              0.273179                     39                  0.505940   \n",
       "48              0.129634                      1                  0.730957   \n",
       "49              0.271488                     26                  0.475891   \n",
       "50              0.270415                     44                  0.471698   \n",
       "51              0.270619                     41                  0.514326   \n",
       "52              0.271576                     36                  0.568134   \n",
       "53              0.273348                     50                  0.559050   \n",
       "54              0.129634                      1                  0.730957   \n",
       "55              0.282711                     37                  0.441649   \n",
       "56              0.272425                     32                  0.452131   \n",
       "57              0.270610                     46                  0.563242   \n",
       "58              0.272501                     35                  0.563242   \n",
       "59              0.267522                     47                  0.555556   \n",
       "\n",
       "    split1_train_Sensitivity  split2_train_Sensitivity  \\\n",
       "0                   0.794549                  0.834382   \n",
       "1                   0.794549                  0.785465   \n",
       "2                   0.794549                  0.785465   \n",
       "3                   0.688330                  0.785465   \n",
       "4                   0.688330                  0.676450   \n",
       "5                   0.522013                  0.632425   \n",
       "6                   0.794549                  0.834382   \n",
       "7                   0.688330                  0.676450   \n",
       "8                   0.688330                  0.676450   \n",
       "9                   0.676450                  0.740741   \n",
       "10                  0.522711                  0.712788   \n",
       "11                  0.519916                  0.659679   \n",
       "12                  0.794549                  0.834382   \n",
       "13                  0.794549                  0.785465   \n",
       "14                  0.794549                  0.785465   \n",
       "15                  0.688330                  0.734451   \n",
       "16                  0.634521                  0.734451   \n",
       "17                  0.358491                  0.567435   \n",
       "18                  0.794549                  0.834382   \n",
       "19                  0.688330                  0.665968   \n",
       "20                  0.676450                  0.735849   \n",
       "21                  0.359189                  0.589099   \n",
       "22                  0.464011                  0.589099   \n",
       "23                  0.549266                  0.618449   \n",
       "24                  0.794549                  0.834382   \n",
       "25                  0.640811                  0.651293   \n",
       "26                  0.629630                  0.733753   \n",
       "27                  0.493361                  0.515723   \n",
       "28                  0.583508                  0.624039   \n",
       "29                  0.611461                  0.625437   \n",
       "30                  0.794549                  0.834382   \n",
       "31                  0.793850                  0.785465   \n",
       "32                  0.688330                  0.676450   \n",
       "33                  0.670161                  0.670161   \n",
       "34                  0.359189                  0.608665   \n",
       "35                  0.516422                  0.584906   \n",
       "36                  0.794549                  0.834382   \n",
       "37                  0.688330                  0.665968   \n",
       "38                  0.358491                  0.640811   \n",
       "39                  0.515024                  0.629630   \n",
       "40                  0.522013                  0.587701   \n",
       "41                  0.575122                  0.616352   \n",
       "42                  0.794549                  0.834382   \n",
       "43                  0.688330                  0.676450   \n",
       "44                  0.670161                  0.662474   \n",
       "45                  0.522013                  0.640811   \n",
       "46                  0.512229                  0.562544   \n",
       "47                  0.570231                  0.615653   \n",
       "48                  0.794549                  0.834382   \n",
       "49                  0.676450                  0.343117   \n",
       "50                  0.522013                  0.587002   \n",
       "51                  0.577219                  0.617750   \n",
       "52                  0.583508                  0.624738   \n",
       "53                  0.579315                  0.619846   \n",
       "54                  0.794549                  0.834382   \n",
       "55                  0.519217                  0.443047   \n",
       "56                  0.548567                  0.616352   \n",
       "57                  0.543676                  0.623340   \n",
       "58                  0.575821                  0.625437   \n",
       "59                  0.595388                  0.626136   \n",
       "\n",
       "    split3_train_Sensitivity  mean_train_Sensitivity  std_train_Sensitivity  \n",
       "0                   0.836478                0.799092               0.042738  \n",
       "1                   0.795947                0.776730               0.026731  \n",
       "2                   0.795947                0.750524               0.071928  \n",
       "3                   0.795947                0.695318               0.114104  \n",
       "4                   0.771488                0.534067               0.310510  \n",
       "5                   0.569532                0.525507               0.093706  \n",
       "6                   0.836478                0.799092               0.042738  \n",
       "7                   0.735849                0.653040               0.084670  \n",
       "8                   0.735849                0.525157               0.304013  \n",
       "9                   0.628931                0.624913               0.106608  \n",
       "10                  0.586303                0.571454               0.092352  \n",
       "11                  0.589099                0.557477               0.074367  \n",
       "12                  0.836478                0.799092               0.042738  \n",
       "13                  0.795947                0.750524               0.071928  \n",
       "14                  0.795947                0.750524               0.071928  \n",
       "15                  0.731656                0.538609               0.311503  \n",
       "16                  0.731656                0.525157               0.305858  \n",
       "17                  0.566737                0.467680               0.099647  \n",
       "18                  0.836478                0.799092               0.042738  \n",
       "19                  0.702306                0.642034               0.076453  \n",
       "20                  0.570231                0.611635               0.103848  \n",
       "21                  0.569532                0.495283               0.092002  \n",
       "22                  0.599581                0.529175               0.065270  \n",
       "23                  0.598882                0.571454               0.039312  \n",
       "24                  0.836478                0.799092               0.042738  \n",
       "25                  0.740042                0.508036               0.295837  \n",
       "26                  0.726765                0.618973               0.140804  \n",
       "27                  0.675751                0.517645               0.103669  \n",
       "28                  0.581412                0.584731               0.026298  \n",
       "29                  0.629630                0.609015               0.023767  \n",
       "30                  0.836478                0.799092               0.042738  \n",
       "31                  0.795947                0.750349               0.071822  \n",
       "32                  0.735849                0.638539               0.109104  \n",
       "33                  0.696017                0.622467               0.098106  \n",
       "34                  0.645003                0.516597               0.115887  \n",
       "35                  0.575821                0.533368               0.051675  \n",
       "36                  0.836478                0.799092               0.042738  \n",
       "37                  0.368973                0.570056               0.126287  \n",
       "38                  0.586303                0.490915               0.124339  \n",
       "39                  0.603075                0.565863               0.051355  \n",
       "40                  0.582809                0.549441               0.036343  \n",
       "41                  0.598882                0.583857               0.026750  \n",
       "42                  0.836478                0.799092               0.042738  \n",
       "43                  0.735849                0.681691               0.039023  \n",
       "44                  0.677848                0.616003               0.093962  \n",
       "45                  0.605171                0.553983               0.074878  \n",
       "46                  0.567435                0.523235               0.047107  \n",
       "47                  0.592593                0.571104               0.040907  \n",
       "48                  0.836478                0.799092               0.042738  \n",
       "49                  0.401817                0.474319               0.125827  \n",
       "50                  0.577219                0.539483               0.046320  \n",
       "51                  0.605870                0.578791               0.040029  \n",
       "52                  0.595388                0.592942               0.020745  \n",
       "53                  0.605870                0.591020               0.023508  \n",
       "54                  0.836478                0.799092               0.042738  \n",
       "55                  0.394130                0.449511               0.044804  \n",
       "56                  0.589099                0.551537               0.062254  \n",
       "57                  0.601677                0.582984               0.031277  \n",
       "58                  0.596785                0.590321               0.023550  \n",
       "59                  0.610762                0.596960               0.026261  \n",
       "\n",
       "[60 rows x 47 columns]"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_abc= gs.cv_results_\n",
    "data = pandas.DataFrame(results_abc)\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'adaboostclassifier__algorithm': 'SAMME',\n",
       " 'adaboostclassifier__learning_rate': 0.15,\n",
       " 'adaboostclassifier__n_estimators': 3}"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>params</th>\n",
       "      <th>mean_test_AUC</th>\n",
       "      <th>mean_test_F_score</th>\n",
       "      <th>mean_test_Sensitivity</th>\n",
       "      <th>rank_test_AUC</th>\n",
       "      <th>rank_test_F_score</th>\n",
       "      <th>rank_test_Sensitivity</th>\n",
       "      <th>mean_train_AUC</th>\n",
       "      <th>mean_train_F_score</th>\n",
       "      <th>mean_train_Sensitivity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.210407</td>\n",
       "      <td>{'adaboostclassifier__algorithm': 'SAMME', 'ad...</td>\n",
       "      <td>0.841200</td>\n",
       "      <td>0.659963</td>\n",
       "      <td>0.794567</td>\n",
       "      <td>51</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.844582</td>\n",
       "      <td>0.665962</td>\n",
       "      <td>0.799092</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.404845</td>\n",
       "      <td>{'adaboostclassifier__algorithm': 'SAMME', 'ad...</td>\n",
       "      <td>0.851425</td>\n",
       "      <td>0.657874</td>\n",
       "      <td>0.768890</td>\n",
       "      <td>49</td>\n",
       "      <td>11</td>\n",
       "      <td>11</td>\n",
       "      <td>0.852968</td>\n",
       "      <td>0.666585</td>\n",
       "      <td>0.776730</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.408737</td>\n",
       "      <td>{'adaboostclassifier__algorithm': 'SAMME', 'ad...</td>\n",
       "      <td>0.853937</td>\n",
       "      <td>0.655670</td>\n",
       "      <td>0.744252</td>\n",
       "      <td>45</td>\n",
       "      <td>12</td>\n",
       "      <td>12</td>\n",
       "      <td>0.855969</td>\n",
       "      <td>0.664336</td>\n",
       "      <td>0.750524</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.565251</td>\n",
       "      <td>{'adaboostclassifier__algorithm': 'SAMME', 'ad...</td>\n",
       "      <td>0.856433</td>\n",
       "      <td>0.639291</td>\n",
       "      <td>0.671390</td>\n",
       "      <td>39</td>\n",
       "      <td>17</td>\n",
       "      <td>17</td>\n",
       "      <td>0.858755</td>\n",
       "      <td>0.653211</td>\n",
       "      <td>0.695318</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.779069</td>\n",
       "      <td>{'adaboostclassifier__algorithm': 'SAMME', 'ad...</td>\n",
       "      <td>0.856693</td>\n",
       "      <td>0.443687</td>\n",
       "      <td>0.465390</td>\n",
       "      <td>38</td>\n",
       "      <td>25</td>\n",
       "      <td>25</td>\n",
       "      <td>0.882185</td>\n",
       "      <td>0.508378</td>\n",
       "      <td>0.534067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2.144364</td>\n",
       "      <td>{'adaboostclassifier__algorithm': 'SAMME', 'ad...</td>\n",
       "      <td>0.875720</td>\n",
       "      <td>0.423286</td>\n",
       "      <td>0.418204</td>\n",
       "      <td>20</td>\n",
       "      <td>42</td>\n",
       "      <td>51</td>\n",
       "      <td>0.909647</td>\n",
       "      <td>0.594287</td>\n",
       "      <td>0.525507</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.191374</td>\n",
       "      <td>{'adaboostclassifier__algorithm': 'SAMME', 'ad...</td>\n",
       "      <td>0.841200</td>\n",
       "      <td>0.659963</td>\n",
       "      <td>0.794567</td>\n",
       "      <td>51</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.844582</td>\n",
       "      <td>0.665962</td>\n",
       "      <td>0.799092</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.460502</td>\n",
       "      <td>{'adaboostclassifier__algorithm': 'SAMME', 'ad...</td>\n",
       "      <td>0.854494</td>\n",
       "      <td>0.629237</td>\n",
       "      <td>0.629468</td>\n",
       "      <td>42</td>\n",
       "      <td>18</td>\n",
       "      <td>18</td>\n",
       "      <td>0.856952</td>\n",
       "      <td>0.648421</td>\n",
       "      <td>0.653040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.486754</td>\n",
       "      <td>{'adaboostclassifier__algorithm': 'SAMME', 'ad...</td>\n",
       "      <td>0.858571</td>\n",
       "      <td>0.441291</td>\n",
       "      <td>0.451766</td>\n",
       "      <td>37</td>\n",
       "      <td>30</td>\n",
       "      <td>28</td>\n",
       "      <td>0.901920</td>\n",
       "      <td>0.506505</td>\n",
       "      <td>0.525157</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.561256</td>\n",
       "      <td>{'adaboostclassifier__algorithm': 'SAMME', 'ad...</td>\n",
       "      <td>0.862219</td>\n",
       "      <td>0.450101</td>\n",
       "      <td>0.491064</td>\n",
       "      <td>30</td>\n",
       "      <td>24</td>\n",
       "      <td>23</td>\n",
       "      <td>0.906274</td>\n",
       "      <td>0.640532</td>\n",
       "      <td>0.624913</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.777015</td>\n",
       "      <td>{'adaboostclassifier__algorithm': 'SAMME', 'ad...</td>\n",
       "      <td>0.869765</td>\n",
       "      <td>0.422243</td>\n",
       "      <td>0.403007</td>\n",
       "      <td>24</td>\n",
       "      <td>47</td>\n",
       "      <td>56</td>\n",
       "      <td>0.908882</td>\n",
       "      <td>0.617763</td>\n",
       "      <td>0.571454</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1.944576</td>\n",
       "      <td>{'adaboostclassifier__algorithm': 'SAMME', 'ad...</td>\n",
       "      <td>0.881393</td>\n",
       "      <td>0.423637</td>\n",
       "      <td>0.433400</td>\n",
       "      <td>8</td>\n",
       "      <td>40</td>\n",
       "      <td>40</td>\n",
       "      <td>0.917990</td>\n",
       "      <td>0.616437</td>\n",
       "      <td>0.557477</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.187849</td>\n",
       "      <td>{'adaboostclassifier__algorithm': 'SAMME', 'ad...</td>\n",
       "      <td>0.841200</td>\n",
       "      <td>0.659963</td>\n",
       "      <td>0.794567</td>\n",
       "      <td>51</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.844582</td>\n",
       "      <td>0.665962</td>\n",
       "      <td>0.799092</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.329682</td>\n",
       "      <td>{'adaboostclassifier__algorithm': 'SAMME', 'ad...</td>\n",
       "      <td>0.853127</td>\n",
       "      <td>0.655670</td>\n",
       "      <td>0.744252</td>\n",
       "      <td>48</td>\n",
       "      <td>12</td>\n",
       "      <td>12</td>\n",
       "      <td>0.854953</td>\n",
       "      <td>0.664336</td>\n",
       "      <td>0.750524</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.404792</td>\n",
       "      <td>{'adaboostclassifier__algorithm': 'SAMME', 'ad...</td>\n",
       "      <td>0.854374</td>\n",
       "      <td>0.655670</td>\n",
       "      <td>0.744252</td>\n",
       "      <td>43</td>\n",
       "      <td>12</td>\n",
       "      <td>12</td>\n",
       "      <td>0.856960</td>\n",
       "      <td>0.664336</td>\n",
       "      <td>0.750524</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.608753</td>\n",
       "      <td>{'adaboostclassifier__algorithm': 'SAMME', 'ad...</td>\n",
       "      <td>0.858815</td>\n",
       "      <td>0.451345</td>\n",
       "      <td>0.493688</td>\n",
       "      <td>36</td>\n",
       "      <td>21</td>\n",
       "      <td>22</td>\n",
       "      <td>0.891960</td>\n",
       "      <td>0.512983</td>\n",
       "      <td>0.538609</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>1.189356</td>\n",
       "      <td>{'adaboostclassifier__algorithm': 'SAMME', 'ad...</td>\n",
       "      <td>0.860518</td>\n",
       "      <td>0.451267</td>\n",
       "      <td>0.473244</td>\n",
       "      <td>33</td>\n",
       "      <td>22</td>\n",
       "      <td>24</td>\n",
       "      <td>0.904527</td>\n",
       "      <td>0.509098</td>\n",
       "      <td>0.525157</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>2.157015</td>\n",
       "      <td>{'adaboostclassifier__algorithm': 'SAMME', 'ad...</td>\n",
       "      <td>0.880423</td>\n",
       "      <td>0.345517</td>\n",
       "      <td>0.349534</td>\n",
       "      <td>10</td>\n",
       "      <td>57</td>\n",
       "      <td>58</td>\n",
       "      <td>0.913291</td>\n",
       "      <td>0.553363</td>\n",
       "      <td>0.467680</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.162862</td>\n",
       "      <td>{'adaboostclassifier__algorithm': 'SAMME', 'ad...</td>\n",
       "      <td>0.841200</td>\n",
       "      <td>0.659963</td>\n",
       "      <td>0.794567</td>\n",
       "      <td>51</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.844582</td>\n",
       "      <td>0.665962</td>\n",
       "      <td>0.799092</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.638915</td>\n",
       "      <td>{'adaboostclassifier__algorithm': 'SAMME', 'ad...</td>\n",
       "      <td>0.853129</td>\n",
       "      <td>0.624700</td>\n",
       "      <td>0.618463</td>\n",
       "      <td>47</td>\n",
       "      <td>19</td>\n",
       "      <td>19</td>\n",
       "      <td>0.899962</td>\n",
       "      <td>0.646008</td>\n",
       "      <td>0.642034</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.998192</td>\n",
       "      <td>{'adaboostclassifier__algorithm': 'SAMME', 'ad...</td>\n",
       "      <td>0.870971</td>\n",
       "      <td>0.452922</td>\n",
       "      <td>0.505737</td>\n",
       "      <td>23</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>0.907092</td>\n",
       "      <td>0.635742</td>\n",
       "      <td>0.611635</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.595501</td>\n",
       "      <td>{'adaboostclassifier__algorithm': 'SAMME', 'ad...</td>\n",
       "      <td>0.876305</td>\n",
       "      <td>0.345108</td>\n",
       "      <td>0.364207</td>\n",
       "      <td>19</td>\n",
       "      <td>58</td>\n",
       "      <td>57</td>\n",
       "      <td>0.912723</td>\n",
       "      <td>0.572345</td>\n",
       "      <td>0.495283</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>1.244599</td>\n",
       "      <td>{'adaboostclassifier__algorithm': 'SAMME', 'ad...</td>\n",
       "      <td>0.877462</td>\n",
       "      <td>0.395358</td>\n",
       "      <td>0.404046</td>\n",
       "      <td>18</td>\n",
       "      <td>56</td>\n",
       "      <td>55</td>\n",
       "      <td>0.915285</td>\n",
       "      <td>0.600325</td>\n",
       "      <td>0.529175</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>2.983380</td>\n",
       "      <td>{'adaboostclassifier__algorithm': 'SAMME', 'ad...</td>\n",
       "      <td>0.882171</td>\n",
       "      <td>0.422316</td>\n",
       "      <td>0.430255</td>\n",
       "      <td>6</td>\n",
       "      <td>46</td>\n",
       "      <td>45</td>\n",
       "      <td>0.924544</td>\n",
       "      <td>0.628788</td>\n",
       "      <td>0.571454</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.310666</td>\n",
       "      <td>{'adaboostclassifier__algorithm': 'SAMME', 'ad...</td>\n",
       "      <td>0.841200</td>\n",
       "      <td>0.659963</td>\n",
       "      <td>0.794567</td>\n",
       "      <td>51</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.844582</td>\n",
       "      <td>0.665962</td>\n",
       "      <td>0.799092</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>1.064104</td>\n",
       "      <td>{'adaboostclassifier__algorithm': 'SAMME', 'ad...</td>\n",
       "      <td>0.854994</td>\n",
       "      <td>0.443043</td>\n",
       "      <td>0.457003</td>\n",
       "      <td>41</td>\n",
       "      <td>26</td>\n",
       "      <td>27</td>\n",
       "      <td>0.899722</td>\n",
       "      <td>0.502770</td>\n",
       "      <td>0.508036</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0.631202</td>\n",
       "      <td>{'adaboostclassifier__algorithm': 'SAMME', 'ad...</td>\n",
       "      <td>0.873401</td>\n",
       "      <td>0.450757</td>\n",
       "      <td>0.496825</td>\n",
       "      <td>22</td>\n",
       "      <td>23</td>\n",
       "      <td>21</td>\n",
       "      <td>0.912250</td>\n",
       "      <td>0.635279</td>\n",
       "      <td>0.618973</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0.915525</td>\n",
       "      <td>{'adaboostclassifier__algorithm': 'SAMME', 'ad...</td>\n",
       "      <td>0.879570</td>\n",
       "      <td>0.420945</td>\n",
       "      <td>0.432352</td>\n",
       "      <td>14</td>\n",
       "      <td>50</td>\n",
       "      <td>42</td>\n",
       "      <td>0.915580</td>\n",
       "      <td>0.591105</td>\n",
       "      <td>0.517645</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0.710747</td>\n",
       "      <td>{'adaboostclassifier__algorithm': 'SAMME', 'ad...</td>\n",
       "      <td>0.879167</td>\n",
       "      <td>0.420333</td>\n",
       "      <td>0.438118</td>\n",
       "      <td>15</td>\n",
       "      <td>51</td>\n",
       "      <td>38</td>\n",
       "      <td>0.917729</td>\n",
       "      <td>0.634146</td>\n",
       "      <td>0.584731</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>1.534826</td>\n",
       "      <td>{'adaboostclassifier__algorithm': 'SAMME', 'ad...</td>\n",
       "      <td>0.880378</td>\n",
       "      <td>0.432121</td>\n",
       "      <td>0.451223</td>\n",
       "      <td>11</td>\n",
       "      <td>34</td>\n",
       "      <td>30</td>\n",
       "      <td>0.925568</td>\n",
       "      <td>0.650678</td>\n",
       "      <td>0.609015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>0.155387</td>\n",
       "      <td>{'adaboostclassifier__algorithm': 'SAMME.R', '...</td>\n",
       "      <td>0.841200</td>\n",
       "      <td>0.659963</td>\n",
       "      <td>0.794567</td>\n",
       "      <td>51</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.844582</td>\n",
       "      <td>0.665962</td>\n",
       "      <td>0.799092</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>0.455081</td>\n",
       "      <td>{'adaboostclassifier__algorithm': 'SAMME.R', '...</td>\n",
       "      <td>0.849464</td>\n",
       "      <td>0.655670</td>\n",
       "      <td>0.744252</td>\n",
       "      <td>50</td>\n",
       "      <td>12</td>\n",
       "      <td>12</td>\n",
       "      <td>0.851339</td>\n",
       "      <td>0.664337</td>\n",
       "      <td>0.750349</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>0.480885</td>\n",
       "      <td>{'adaboostclassifier__algorithm': 'SAMME.R', '...</td>\n",
       "      <td>0.855554</td>\n",
       "      <td>0.441291</td>\n",
       "      <td>0.451766</td>\n",
       "      <td>40</td>\n",
       "      <td>30</td>\n",
       "      <td>28</td>\n",
       "      <td>0.867952</td>\n",
       "      <td>0.642109</td>\n",
       "      <td>0.638539</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>0.849989</td>\n",
       "      <td>{'adaboostclassifier__algorithm': 'SAMME.R', '...</td>\n",
       "      <td>0.859790</td>\n",
       "      <td>0.442980</td>\n",
       "      <td>0.443903</td>\n",
       "      <td>34</td>\n",
       "      <td>27</td>\n",
       "      <td>33</td>\n",
       "      <td>0.903297</td>\n",
       "      <td>0.640915</td>\n",
       "      <td>0.622467</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>0.931538</td>\n",
       "      <td>{'adaboostclassifier__algorithm': 'SAMME.R', '...</td>\n",
       "      <td>0.864860</td>\n",
       "      <td>0.334578</td>\n",
       "      <td>0.308137</td>\n",
       "      <td>28</td>\n",
       "      <td>60</td>\n",
       "      <td>60</td>\n",
       "      <td>0.907138</td>\n",
       "      <td>0.581191</td>\n",
       "      <td>0.516597</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>1.963384</td>\n",
       "      <td>{'adaboostclassifier__algorithm': 'SAMME.R', '...</td>\n",
       "      <td>0.883087</td>\n",
       "      <td>0.417117</td>\n",
       "      <td>0.415057</td>\n",
       "      <td>4</td>\n",
       "      <td>53</td>\n",
       "      <td>53</td>\n",
       "      <td>0.922937</td>\n",
       "      <td>0.605198</td>\n",
       "      <td>0.533368</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>0.109503</td>\n",
       "      <td>{'adaboostclassifier__algorithm': 'SAMME.R', '...</td>\n",
       "      <td>0.841200</td>\n",
       "      <td>0.659963</td>\n",
       "      <td>0.794567</td>\n",
       "      <td>51</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.844582</td>\n",
       "      <td>0.665962</td>\n",
       "      <td>0.799092</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>0.252502</td>\n",
       "      <td>{'adaboostclassifier__algorithm': 'SAMME.R', '...</td>\n",
       "      <td>0.853972</td>\n",
       "      <td>0.439183</td>\n",
       "      <td>0.447574</td>\n",
       "      <td>44</td>\n",
       "      <td>32</td>\n",
       "      <td>31</td>\n",
       "      <td>0.890108</td>\n",
       "      <td>0.602435</td>\n",
       "      <td>0.570056</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>0.392494</td>\n",
       "      <td>{'adaboostclassifier__algorithm': 'SAMME.R', '...</td>\n",
       "      <td>0.865025</td>\n",
       "      <td>0.341528</td>\n",
       "      <td>0.335910</td>\n",
       "      <td>27</td>\n",
       "      <td>59</td>\n",
       "      <td>59</td>\n",
       "      <td>0.909961</td>\n",
       "      <td>0.564754</td>\n",
       "      <td>0.490915</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>0.568995</td>\n",
       "      <td>{'adaboostclassifier__algorithm': 'SAMME.R', '...</td>\n",
       "      <td>0.878162</td>\n",
       "      <td>0.423262</td>\n",
       "      <td>0.422395</td>\n",
       "      <td>17</td>\n",
       "      <td>43</td>\n",
       "      <td>48</td>\n",
       "      <td>0.917192</td>\n",
       "      <td>0.622853</td>\n",
       "      <td>0.565863</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>0.714894</td>\n",
       "      <td>{'adaboostclassifier__algorithm': 'SAMME.R', '...</td>\n",
       "      <td>0.880590</td>\n",
       "      <td>0.423816</td>\n",
       "      <td>0.420824</td>\n",
       "      <td>9</td>\n",
       "      <td>39</td>\n",
       "      <td>49</td>\n",
       "      <td>0.922842</td>\n",
       "      <td>0.616510</td>\n",
       "      <td>0.549441</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>1.652345</td>\n",
       "      <td>{'adaboostclassifier__algorithm': 'SAMME.R', '...</td>\n",
       "      <td>0.884374</td>\n",
       "      <td>0.422198</td>\n",
       "      <td>0.431829</td>\n",
       "      <td>3</td>\n",
       "      <td>48</td>\n",
       "      <td>43</td>\n",
       "      <td>0.927662</td>\n",
       "      <td>0.639455</td>\n",
       "      <td>0.583857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>0.102884</td>\n",
       "      <td>{'adaboostclassifier__algorithm': 'SAMME.R', '...</td>\n",
       "      <td>0.841200</td>\n",
       "      <td>0.659963</td>\n",
       "      <td>0.794567</td>\n",
       "      <td>51</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.844582</td>\n",
       "      <td>0.665962</td>\n",
       "      <td>0.799092</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>0.266515</td>\n",
       "      <td>{'adaboostclassifier__algorithm': 'SAMME.R', '...</td>\n",
       "      <td>0.853936</td>\n",
       "      <td>0.646981</td>\n",
       "      <td>0.676645</td>\n",
       "      <td>46</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>0.855970</td>\n",
       "      <td>0.656690</td>\n",
       "      <td>0.681691</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>0.412500</td>\n",
       "      <td>{'adaboostclassifier__algorithm': 'SAMME.R', '...</td>\n",
       "      <td>0.859616</td>\n",
       "      <td>0.442980</td>\n",
       "      <td>0.443903</td>\n",
       "      <td>35</td>\n",
       "      <td>27</td>\n",
       "      <td>33</td>\n",
       "      <td>0.903393</td>\n",
       "      <td>0.638795</td>\n",
       "      <td>0.616003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>0.693139</td>\n",
       "      <td>{'adaboostclassifier__algorithm': 'SAMME.R', '...</td>\n",
       "      <td>0.866126</td>\n",
       "      <td>0.423096</td>\n",
       "      <td>0.418204</td>\n",
       "      <td>26</td>\n",
       "      <td>44</td>\n",
       "      <td>51</td>\n",
       "      <td>0.910565</td>\n",
       "      <td>0.610835</td>\n",
       "      <td>0.553983</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>0.920443</td>\n",
       "      <td>{'adaboostclassifier__algorithm': 'SAMME.R', '...</td>\n",
       "      <td>0.874933</td>\n",
       "      <td>0.421383</td>\n",
       "      <td>0.412962</td>\n",
       "      <td>21</td>\n",
       "      <td>49</td>\n",
       "      <td>54</td>\n",
       "      <td>0.913495</td>\n",
       "      <td>0.595814</td>\n",
       "      <td>0.523235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>1.990230</td>\n",
       "      <td>{'adaboostclassifier__algorithm': 'SAMME.R', '...</td>\n",
       "      <td>0.885988</td>\n",
       "      <td>0.422663</td>\n",
       "      <td>0.433925</td>\n",
       "      <td>2</td>\n",
       "      <td>45</td>\n",
       "      <td>39</td>\n",
       "      <td>0.925080</td>\n",
       "      <td>0.628082</td>\n",
       "      <td>0.571104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>0.194256</td>\n",
       "      <td>{'adaboostclassifier__algorithm': 'SAMME.R', '...</td>\n",
       "      <td>0.841200</td>\n",
       "      <td>0.659963</td>\n",
       "      <td>0.794567</td>\n",
       "      <td>51</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.844582</td>\n",
       "      <td>0.665962</td>\n",
       "      <td>0.799092</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>0.403752</td>\n",
       "      <td>{'adaboostclassifier__algorithm': 'SAMME.R', '...</td>\n",
       "      <td>0.860810</td>\n",
       "      <td>0.442443</td>\n",
       "      <td>0.462767</td>\n",
       "      <td>32</td>\n",
       "      <td>29</td>\n",
       "      <td>26</td>\n",
       "      <td>0.902879</td>\n",
       "      <td>0.545554</td>\n",
       "      <td>0.474319</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>0.731514</td>\n",
       "      <td>{'adaboostclassifier__algorithm': 'SAMME.R', '...</td>\n",
       "      <td>0.878403</td>\n",
       "      <td>0.424421</td>\n",
       "      <td>0.430256</td>\n",
       "      <td>16</td>\n",
       "      <td>38</td>\n",
       "      <td>44</td>\n",
       "      <td>0.920777</td>\n",
       "      <td>0.606900</td>\n",
       "      <td>0.539483</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>0.704511</td>\n",
       "      <td>{'adaboostclassifier__algorithm': 'SAMME.R', '...</td>\n",
       "      <td>0.886102</td>\n",
       "      <td>0.426331</td>\n",
       "      <td>0.432877</td>\n",
       "      <td>1</td>\n",
       "      <td>37</td>\n",
       "      <td>41</td>\n",
       "      <td>0.924347</td>\n",
       "      <td>0.633775</td>\n",
       "      <td>0.578791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>1.044506</td>\n",
       "      <td>{'adaboostclassifier__algorithm': 'SAMME.R', '...</td>\n",
       "      <td>0.882417</td>\n",
       "      <td>0.429917</td>\n",
       "      <td>0.442836</td>\n",
       "      <td>5</td>\n",
       "      <td>36</td>\n",
       "      <td>36</td>\n",
       "      <td>0.926289</td>\n",
       "      <td>0.641037</td>\n",
       "      <td>0.592942</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>1.689334</td>\n",
       "      <td>{'adaboostclassifier__algorithm': 'SAMME.R', '...</td>\n",
       "      <td>0.868296</td>\n",
       "      <td>0.406926</td>\n",
       "      <td>0.419772</td>\n",
       "      <td>25</td>\n",
       "      <td>55</td>\n",
       "      <td>50</td>\n",
       "      <td>0.930508</td>\n",
       "      <td>0.645410</td>\n",
       "      <td>0.591020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>0.187504</td>\n",
       "      <td>{'adaboostclassifier__algorithm': 'SAMME.R', '...</td>\n",
       "      <td>0.841200</td>\n",
       "      <td>0.659963</td>\n",
       "      <td>0.794567</td>\n",
       "      <td>51</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.844582</td>\n",
       "      <td>0.665962</td>\n",
       "      <td>0.799092</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>0.497763</td>\n",
       "      <td>{'adaboostclassifier__algorithm': 'SAMME.R', '...</td>\n",
       "      <td>0.861746</td>\n",
       "      <td>0.423497</td>\n",
       "      <td>0.441784</td>\n",
       "      <td>31</td>\n",
       "      <td>41</td>\n",
       "      <td>37</td>\n",
       "      <td>0.906569</td>\n",
       "      <td>0.539067</td>\n",
       "      <td>0.449511</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>0.618909</td>\n",
       "      <td>{'adaboostclassifier__algorithm': 'SAMME.R', '...</td>\n",
       "      <td>0.881987</td>\n",
       "      <td>0.436396</td>\n",
       "      <td>0.447554</td>\n",
       "      <td>7</td>\n",
       "      <td>33</td>\n",
       "      <td>32</td>\n",
       "      <td>0.921767</td>\n",
       "      <td>0.616988</td>\n",
       "      <td>0.551537</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>0.939167</td>\n",
       "      <td>{'adaboostclassifier__algorithm': 'SAMME.R', '...</td>\n",
       "      <td>0.879781</td>\n",
       "      <td>0.419819</td>\n",
       "      <td>0.428159</td>\n",
       "      <td>13</td>\n",
       "      <td>52</td>\n",
       "      <td>46</td>\n",
       "      <td>0.924650</td>\n",
       "      <td>0.635618</td>\n",
       "      <td>0.582984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>0.881235</td>\n",
       "      <td>{'adaboostclassifier__algorithm': 'SAMME.R', '...</td>\n",
       "      <td>0.880056</td>\n",
       "      <td>0.430139</td>\n",
       "      <td>0.443884</td>\n",
       "      <td>12</td>\n",
       "      <td>35</td>\n",
       "      <td>35</td>\n",
       "      <td>0.926538</td>\n",
       "      <td>0.642299</td>\n",
       "      <td>0.590321</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>1.650498</td>\n",
       "      <td>{'adaboostclassifier__algorithm': 'SAMME.R', '...</td>\n",
       "      <td>0.864615</td>\n",
       "      <td>0.408012</td>\n",
       "      <td>0.423967</td>\n",
       "      <td>29</td>\n",
       "      <td>54</td>\n",
       "      <td>47</td>\n",
       "      <td>0.930903</td>\n",
       "      <td>0.649971</td>\n",
       "      <td>0.596960</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    mean_fit_time                                             params  \\\n",
       "0        0.210407  {'adaboostclassifier__algorithm': 'SAMME', 'ad...   \n",
       "1        0.404845  {'adaboostclassifier__algorithm': 'SAMME', 'ad...   \n",
       "2        0.408737  {'adaboostclassifier__algorithm': 'SAMME', 'ad...   \n",
       "3        0.565251  {'adaboostclassifier__algorithm': 'SAMME', 'ad...   \n",
       "4        0.779069  {'adaboostclassifier__algorithm': 'SAMME', 'ad...   \n",
       "5        2.144364  {'adaboostclassifier__algorithm': 'SAMME', 'ad...   \n",
       "6        0.191374  {'adaboostclassifier__algorithm': 'SAMME', 'ad...   \n",
       "7        0.460502  {'adaboostclassifier__algorithm': 'SAMME', 'ad...   \n",
       "8        0.486754  {'adaboostclassifier__algorithm': 'SAMME', 'ad...   \n",
       "9        0.561256  {'adaboostclassifier__algorithm': 'SAMME', 'ad...   \n",
       "10       0.777015  {'adaboostclassifier__algorithm': 'SAMME', 'ad...   \n",
       "11       1.944576  {'adaboostclassifier__algorithm': 'SAMME', 'ad...   \n",
       "12       0.187849  {'adaboostclassifier__algorithm': 'SAMME', 'ad...   \n",
       "13       0.329682  {'adaboostclassifier__algorithm': 'SAMME', 'ad...   \n",
       "14       0.404792  {'adaboostclassifier__algorithm': 'SAMME', 'ad...   \n",
       "15       0.608753  {'adaboostclassifier__algorithm': 'SAMME', 'ad...   \n",
       "16       1.189356  {'adaboostclassifier__algorithm': 'SAMME', 'ad...   \n",
       "17       2.157015  {'adaboostclassifier__algorithm': 'SAMME', 'ad...   \n",
       "18       0.162862  {'adaboostclassifier__algorithm': 'SAMME', 'ad...   \n",
       "19       0.638915  {'adaboostclassifier__algorithm': 'SAMME', 'ad...   \n",
       "20       0.998192  {'adaboostclassifier__algorithm': 'SAMME', 'ad...   \n",
       "21       0.595501  {'adaboostclassifier__algorithm': 'SAMME', 'ad...   \n",
       "22       1.244599  {'adaboostclassifier__algorithm': 'SAMME', 'ad...   \n",
       "23       2.983380  {'adaboostclassifier__algorithm': 'SAMME', 'ad...   \n",
       "24       0.310666  {'adaboostclassifier__algorithm': 'SAMME', 'ad...   \n",
       "25       1.064104  {'adaboostclassifier__algorithm': 'SAMME', 'ad...   \n",
       "26       0.631202  {'adaboostclassifier__algorithm': 'SAMME', 'ad...   \n",
       "27       0.915525  {'adaboostclassifier__algorithm': 'SAMME', 'ad...   \n",
       "28       0.710747  {'adaboostclassifier__algorithm': 'SAMME', 'ad...   \n",
       "29       1.534826  {'adaboostclassifier__algorithm': 'SAMME', 'ad...   \n",
       "30       0.155387  {'adaboostclassifier__algorithm': 'SAMME.R', '...   \n",
       "31       0.455081  {'adaboostclassifier__algorithm': 'SAMME.R', '...   \n",
       "32       0.480885  {'adaboostclassifier__algorithm': 'SAMME.R', '...   \n",
       "33       0.849989  {'adaboostclassifier__algorithm': 'SAMME.R', '...   \n",
       "34       0.931538  {'adaboostclassifier__algorithm': 'SAMME.R', '...   \n",
       "35       1.963384  {'adaboostclassifier__algorithm': 'SAMME.R', '...   \n",
       "36       0.109503  {'adaboostclassifier__algorithm': 'SAMME.R', '...   \n",
       "37       0.252502  {'adaboostclassifier__algorithm': 'SAMME.R', '...   \n",
       "38       0.392494  {'adaboostclassifier__algorithm': 'SAMME.R', '...   \n",
       "39       0.568995  {'adaboostclassifier__algorithm': 'SAMME.R', '...   \n",
       "40       0.714894  {'adaboostclassifier__algorithm': 'SAMME.R', '...   \n",
       "41       1.652345  {'adaboostclassifier__algorithm': 'SAMME.R', '...   \n",
       "42       0.102884  {'adaboostclassifier__algorithm': 'SAMME.R', '...   \n",
       "43       0.266515  {'adaboostclassifier__algorithm': 'SAMME.R', '...   \n",
       "44       0.412500  {'adaboostclassifier__algorithm': 'SAMME.R', '...   \n",
       "45       0.693139  {'adaboostclassifier__algorithm': 'SAMME.R', '...   \n",
       "46       0.920443  {'adaboostclassifier__algorithm': 'SAMME.R', '...   \n",
       "47       1.990230  {'adaboostclassifier__algorithm': 'SAMME.R', '...   \n",
       "48       0.194256  {'adaboostclassifier__algorithm': 'SAMME.R', '...   \n",
       "49       0.403752  {'adaboostclassifier__algorithm': 'SAMME.R', '...   \n",
       "50       0.731514  {'adaboostclassifier__algorithm': 'SAMME.R', '...   \n",
       "51       0.704511  {'adaboostclassifier__algorithm': 'SAMME.R', '...   \n",
       "52       1.044506  {'adaboostclassifier__algorithm': 'SAMME.R', '...   \n",
       "53       1.689334  {'adaboostclassifier__algorithm': 'SAMME.R', '...   \n",
       "54       0.187504  {'adaboostclassifier__algorithm': 'SAMME.R', '...   \n",
       "55       0.497763  {'adaboostclassifier__algorithm': 'SAMME.R', '...   \n",
       "56       0.618909  {'adaboostclassifier__algorithm': 'SAMME.R', '...   \n",
       "57       0.939167  {'adaboostclassifier__algorithm': 'SAMME.R', '...   \n",
       "58       0.881235  {'adaboostclassifier__algorithm': 'SAMME.R', '...   \n",
       "59       1.650498  {'adaboostclassifier__algorithm': 'SAMME.R', '...   \n",
       "\n",
       "    mean_test_AUC  mean_test_F_score  mean_test_Sensitivity  rank_test_AUC  \\\n",
       "0        0.841200           0.659963               0.794567             51   \n",
       "1        0.851425           0.657874               0.768890             49   \n",
       "2        0.853937           0.655670               0.744252             45   \n",
       "3        0.856433           0.639291               0.671390             39   \n",
       "4        0.856693           0.443687               0.465390             38   \n",
       "5        0.875720           0.423286               0.418204             20   \n",
       "6        0.841200           0.659963               0.794567             51   \n",
       "7        0.854494           0.629237               0.629468             42   \n",
       "8        0.858571           0.441291               0.451766             37   \n",
       "9        0.862219           0.450101               0.491064             30   \n",
       "10       0.869765           0.422243               0.403007             24   \n",
       "11       0.881393           0.423637               0.433400              8   \n",
       "12       0.841200           0.659963               0.794567             51   \n",
       "13       0.853127           0.655670               0.744252             48   \n",
       "14       0.854374           0.655670               0.744252             43   \n",
       "15       0.858815           0.451345               0.493688             36   \n",
       "16       0.860518           0.451267               0.473244             33   \n",
       "17       0.880423           0.345517               0.349534             10   \n",
       "18       0.841200           0.659963               0.794567             51   \n",
       "19       0.853129           0.624700               0.618463             47   \n",
       "20       0.870971           0.452922               0.505737             23   \n",
       "21       0.876305           0.345108               0.364207             19   \n",
       "22       0.877462           0.395358               0.404046             18   \n",
       "23       0.882171           0.422316               0.430255              6   \n",
       "24       0.841200           0.659963               0.794567             51   \n",
       "25       0.854994           0.443043               0.457003             41   \n",
       "26       0.873401           0.450757               0.496825             22   \n",
       "27       0.879570           0.420945               0.432352             14   \n",
       "28       0.879167           0.420333               0.438118             15   \n",
       "29       0.880378           0.432121               0.451223             11   \n",
       "30       0.841200           0.659963               0.794567             51   \n",
       "31       0.849464           0.655670               0.744252             50   \n",
       "32       0.855554           0.441291               0.451766             40   \n",
       "33       0.859790           0.442980               0.443903             34   \n",
       "34       0.864860           0.334578               0.308137             28   \n",
       "35       0.883087           0.417117               0.415057              4   \n",
       "36       0.841200           0.659963               0.794567             51   \n",
       "37       0.853972           0.439183               0.447574             44   \n",
       "38       0.865025           0.341528               0.335910             27   \n",
       "39       0.878162           0.423262               0.422395             17   \n",
       "40       0.880590           0.423816               0.420824              9   \n",
       "41       0.884374           0.422198               0.431829              3   \n",
       "42       0.841200           0.659963               0.794567             51   \n",
       "43       0.853936           0.646981               0.676645             46   \n",
       "44       0.859616           0.442980               0.443903             35   \n",
       "45       0.866126           0.423096               0.418204             26   \n",
       "46       0.874933           0.421383               0.412962             21   \n",
       "47       0.885988           0.422663               0.433925              2   \n",
       "48       0.841200           0.659963               0.794567             51   \n",
       "49       0.860810           0.442443               0.462767             32   \n",
       "50       0.878403           0.424421               0.430256             16   \n",
       "51       0.886102           0.426331               0.432877              1   \n",
       "52       0.882417           0.429917               0.442836              5   \n",
       "53       0.868296           0.406926               0.419772             25   \n",
       "54       0.841200           0.659963               0.794567             51   \n",
       "55       0.861746           0.423497               0.441784             31   \n",
       "56       0.881987           0.436396               0.447554              7   \n",
       "57       0.879781           0.419819               0.428159             13   \n",
       "58       0.880056           0.430139               0.443884             12   \n",
       "59       0.864615           0.408012               0.423967             29   \n",
       "\n",
       "    rank_test_F_score  rank_test_Sensitivity  mean_train_AUC  \\\n",
       "0                   1                      1        0.844582   \n",
       "1                  11                     11        0.852968   \n",
       "2                  12                     12        0.855969   \n",
       "3                  17                     17        0.858755   \n",
       "4                  25                     25        0.882185   \n",
       "5                  42                     51        0.909647   \n",
       "6                   1                      1        0.844582   \n",
       "7                  18                     18        0.856952   \n",
       "8                  30                     28        0.901920   \n",
       "9                  24                     23        0.906274   \n",
       "10                 47                     56        0.908882   \n",
       "11                 40                     40        0.917990   \n",
       "12                  1                      1        0.844582   \n",
       "13                 12                     12        0.854953   \n",
       "14                 12                     12        0.856960   \n",
       "15                 21                     22        0.891960   \n",
       "16                 22                     24        0.904527   \n",
       "17                 57                     58        0.913291   \n",
       "18                  1                      1        0.844582   \n",
       "19                 19                     19        0.899962   \n",
       "20                 20                     20        0.907092   \n",
       "21                 58                     57        0.912723   \n",
       "22                 56                     55        0.915285   \n",
       "23                 46                     45        0.924544   \n",
       "24                  1                      1        0.844582   \n",
       "25                 26                     27        0.899722   \n",
       "26                 23                     21        0.912250   \n",
       "27                 50                     42        0.915580   \n",
       "28                 51                     38        0.917729   \n",
       "29                 34                     30        0.925568   \n",
       "30                  1                      1        0.844582   \n",
       "31                 12                     12        0.851339   \n",
       "32                 30                     28        0.867952   \n",
       "33                 27                     33        0.903297   \n",
       "34                 60                     60        0.907138   \n",
       "35                 53                     53        0.922937   \n",
       "36                  1                      1        0.844582   \n",
       "37                 32                     31        0.890108   \n",
       "38                 59                     59        0.909961   \n",
       "39                 43                     48        0.917192   \n",
       "40                 39                     49        0.922842   \n",
       "41                 48                     43        0.927662   \n",
       "42                  1                      1        0.844582   \n",
       "43                 16                     16        0.855970   \n",
       "44                 27                     33        0.903393   \n",
       "45                 44                     51        0.910565   \n",
       "46                 49                     54        0.913495   \n",
       "47                 45                     39        0.925080   \n",
       "48                  1                      1        0.844582   \n",
       "49                 29                     26        0.902879   \n",
       "50                 38                     44        0.920777   \n",
       "51                 37                     41        0.924347   \n",
       "52                 36                     36        0.926289   \n",
       "53                 55                     50        0.930508   \n",
       "54                  1                      1        0.844582   \n",
       "55                 41                     37        0.906569   \n",
       "56                 33                     32        0.921767   \n",
       "57                 52                     46        0.924650   \n",
       "58                 35                     35        0.926538   \n",
       "59                 54                     47        0.930903   \n",
       "\n",
       "    mean_train_F_score  mean_train_Sensitivity  \n",
       "0             0.665962                0.799092  \n",
       "1             0.666585                0.776730  \n",
       "2             0.664336                0.750524  \n",
       "3             0.653211                0.695318  \n",
       "4             0.508378                0.534067  \n",
       "5             0.594287                0.525507  \n",
       "6             0.665962                0.799092  \n",
       "7             0.648421                0.653040  \n",
       "8             0.506505                0.525157  \n",
       "9             0.640532                0.624913  \n",
       "10            0.617763                0.571454  \n",
       "11            0.616437                0.557477  \n",
       "12            0.665962                0.799092  \n",
       "13            0.664336                0.750524  \n",
       "14            0.664336                0.750524  \n",
       "15            0.512983                0.538609  \n",
       "16            0.509098                0.525157  \n",
       "17            0.553363                0.467680  \n",
       "18            0.665962                0.799092  \n",
       "19            0.646008                0.642034  \n",
       "20            0.635742                0.611635  \n",
       "21            0.572345                0.495283  \n",
       "22            0.600325                0.529175  \n",
       "23            0.628788                0.571454  \n",
       "24            0.665962                0.799092  \n",
       "25            0.502770                0.508036  \n",
       "26            0.635279                0.618973  \n",
       "27            0.591105                0.517645  \n",
       "28            0.634146                0.584731  \n",
       "29            0.650678                0.609015  \n",
       "30            0.665962                0.799092  \n",
       "31            0.664337                0.750349  \n",
       "32            0.642109                0.638539  \n",
       "33            0.640915                0.622467  \n",
       "34            0.581191                0.516597  \n",
       "35            0.605198                0.533368  \n",
       "36            0.665962                0.799092  \n",
       "37            0.602435                0.570056  \n",
       "38            0.564754                0.490915  \n",
       "39            0.622853                0.565863  \n",
       "40            0.616510                0.549441  \n",
       "41            0.639455                0.583857  \n",
       "42            0.665962                0.799092  \n",
       "43            0.656690                0.681691  \n",
       "44            0.638795                0.616003  \n",
       "45            0.610835                0.553983  \n",
       "46            0.595814                0.523235  \n",
       "47            0.628082                0.571104  \n",
       "48            0.665962                0.799092  \n",
       "49            0.545554                0.474319  \n",
       "50            0.606900                0.539483  \n",
       "51            0.633775                0.578791  \n",
       "52            0.641037                0.592942  \n",
       "53            0.645410                0.591020  \n",
       "54            0.665962                0.799092  \n",
       "55            0.539067                0.449511  \n",
       "56            0.616988                0.551537  \n",
       "57            0.635618                0.582984  \n",
       "58            0.642299                0.590321  \n",
       "59            0.649971                0.596960  "
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "table_abc = make_table(data)\n",
    "table_abc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
